{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloanding third-party code for resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9123,
     "status": "ok",
     "timestamp": 1583988813702,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "wfePU8fqBh0p",
    "outputId": "fcab98cc-e13b-41d2-ccd5-f4839ed3e15b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-15 18:25:49--  https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5001 (4.9K) [text/plain]\r\n",
      "Saving to: ‘resnet.py’\r\n",
      "\r\n",
      "resnet.py           100%[===================>]   4.88K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2020-03-15 18:25:49 (38.9 MB/s) - ‘resnet.py’ saved [5001/5001]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading/uploading with kaggle kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37596,
     "status": "ok",
     "timestamp": 1583988842192,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "lLar-Or9BtDy",
    "outputId": "c595446b-16b8-408b-d1a8-169aa3232ec5"
   },
   "outputs": [],
   "source": [
    "def download_model(source_name, saving_name):\n",
    "  !cp \"../input/cinic10-models/{source_name}\" {saving_name}\n",
    "\n",
    "def upload_model(source_name, saving_name):\n",
    "    pass\n",
    "\n",
    "def upload_logs():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNcUuvbdubOV"
   },
   "outputs": [],
   "source": [
    "!cp -r '../input/cinic10/train' train\n",
    "!cp -r '../input/cinic10/test' test\n",
    "!cp -r '../input/cinic10/valid' valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libs importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDHAyQCTB0m7"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from resnet import resnet20, BasicBlock, _weights_init, resnet32, resnet56, resnet44, ResNet\n",
    "\n",
    "def resnet7():return ResNet(BasicBlock, [1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration of utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiMNJcDPB2lJ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "  \"\"\"Class for computing average values\n",
    "  \"\"\"    \n",
    "  def __init__(self):\n",
    "    \"\"\"Init class\n",
    "    \"\"\"      \n",
    "    self.sum_ = 0\n",
    "    self.count = 0\n",
    "  \n",
    "  def update(self, val, count=1):\n",
    "    \"\"\"Add new value to track\n",
    "    \n",
    "    Arguments:\n",
    "        val {float} -- new value\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        count {int} -- weigth of val (default: {1})\n",
    "    \"\"\"      \n",
    "    self.sum_ += val\n",
    "    self.count += count\n",
    "\n",
    "  def average(self):\n",
    "    \"\"\"return average value for given values\n",
    "    \"\"\"      \n",
    "    return self.sum_ / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2rud3U0B5Pu"
   },
   "outputs": [],
   "source": [
    "class TensorBoardLogger:\n",
    "    \"\"\"Class for logging into TensorBoard\n",
    "    \"\"\"    \n",
    "    def __init__(self, log_dir, dataset, net, experiment_name):\n",
    "        \"\"\"Init logger\n",
    "        \n",
    "        Arguments:\n",
    "            log_dir {string} -- log dir\n",
    "            dataset {string} -- name of dataset\n",
    "            experiment_name {string} -- name of experiment\n",
    "        \"\"\"        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        log_dir_full = os.path.join(log_dir, dataset, net, experiment_name, current_time)\n",
    "        self.writer = tf.summary.create_file_writer(log_dir_full)\n",
    "        self.step_ = 0\n",
    "        \n",
    "    def log_scalar(self, tag, value, step=None, description=None):\n",
    "        \"\"\"Log scalar\n",
    "        \n",
    "        Arguments:\n",
    "            tag {string} -- name of variable to log\n",
    "            value {float} -- value of variable\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            step {int} -- current epoch number (default: {None})\n",
    "            description {string} -- [description] (default: {None})\n",
    "        \"\"\"        \n",
    "        if step is None:\n",
    "            step = self.step_\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(tag, value, step=step, description=description)\n",
    "            \n",
    "    def step(self):\n",
    "        \"\"\"Increase epoch number by 1\n",
    "        \"\"\"        \n",
    "        self.step_+=1\n",
    "\n",
    "    def log_hparams(self, hparams):\n",
    "        \"\"\"log hparams\n",
    "        \n",
    "        Arguments:\n",
    "            hparams {dict} -- dict to log\n",
    "        \"\"\"      \n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(hparams)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewF2eWCOB7Pr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "dataset_name = \"cinic_aug_cached\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZyKuu77MVcV"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  imgs = [i[0] for i in batch]\n",
    "  labels = [i[1] for i in batch]\n",
    "  return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ph7_tHYAB9cN"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# augmentation and normaliztion for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "# only normalization for testing\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='train',\n",
    "                                            # transform=transform_train\n",
    "                                            )\n",
    "valset = torchvision.datasets.ImageFolder(root='valid', \n",
    "                                          # transform=transform_test\n",
    "                                          )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn\n",
    "                                          )\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn\n",
    "                                          )\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='test', \n",
    "                                          #  transform=transform_test\n",
    "                                           )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                         pin_memory=True, \n",
    "                                         collate_fn=collate_fn\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slWmMP1LCC9b"
   },
   "outputs": [],
   "source": [
    "def accuracy_minibatch(outputs, labels):\n",
    "  \"\"\"Compute accuracy for batch\n",
    "  \n",
    "  Arguments:\n",
    "      outputs {list or np.array or torch.Tensor} -- outputs from model (vectors of probabilities)\n",
    "      labels {list or np.array or torch.Tensor} -- labels (one number for each sample)\n",
    "  \n",
    "  Returns:\n",
    "      float -- accuracy for minibatch\n",
    "  \"\"\"  \n",
    "  if isinstance(outputs, torch.Tensor):\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "  if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "  \n",
    "  predict_= np.argmax(outputs, axis=1)\n",
    "  true_labels_= labels\n",
    "  micro_acc_score = accuracy_score(predict_, true_labels_)\n",
    "  return micro_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07DXQHlXCEa_"
   },
   "outputs": [],
   "source": [
    "def validate(net, testloader, logger=None, verbose=True, prename=\"val\",\n",
    "             cuda=True,\n",
    "             transform_tensor=transform_test,\n",
    "             transform_repeats=1\n",
    "             ):\n",
    "  \"\"\"Function for compute metrics on validation set\n",
    "  \n",
    "  Arguments:\n",
    "      net {torch net} -- model\n",
    "      testloader {DataLoader} -- set to validation\n",
    "      \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      prename {string} -- prename to name of metric (default: {\"val\"})\n",
    "  \n",
    "  Returns:\n",
    "      [floats] -- scores for computing metrics\n",
    "  \"\"\"  \n",
    "  # change net to evaluation mode\n",
    "  net.eval()\n",
    "  ce_loss_avg = AverageMeter()\n",
    "  accuracy_score_avg = AverageMeter()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  # evaluate dataset\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs]) for i in range(transform_repeats)]\n",
    "\n",
    "    current_batch_size = len(labels)\n",
    "\n",
    "    outputs = 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs += net(inputs_[i].cuda() if cuda else inputs_[i])\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    loss = criterion(outputs, labels).cpu().detach().numpy()\n",
    "    \n",
    "    micro_acc_score = accuracy_minibatch(outputs, labels)\n",
    "\n",
    "    accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "    ce_loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "\n",
    "  accuracy = accuracy_score_avg.average()\n",
    "  ce_loss = ce_loss_avg.average()\n",
    "  scores = {\n",
    "      \"%s_accuracy\"%prename: accuracy,\n",
    "      \"%s_overall_loss\"%prename: ce_loss,\n",
    "       }\n",
    "  \n",
    "  # log scores\n",
    "  for name, score in scores.items():\n",
    "    if logger:\n",
    "      logger.log_scalar(name, score)\n",
    "    if verbose:\n",
    "      print(name, score)\n",
    "  \n",
    "  if verbose:\n",
    "    print(\"__________________\")\n",
    "  # change net to training mode\n",
    "  net.train()\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rNl7qpSCGLk"
   },
   "outputs": [],
   "source": [
    "def train_distillation_cached(\n",
    "    net_student, \n",
    "    trainloader, \n",
    "    testloader, \n",
    "    logger=None,\n",
    "    cuda=True,\n",
    "    epoches=150,\n",
    "    verbose=True, \n",
    "    return_best=False,\n",
    "    init_lr=0.1,\n",
    "    temperature=1,\n",
    "    cos_alpha=0,\n",
    "    l_alpha=0,\n",
    "    p=2,\n",
    "    shuffle=True,\n",
    "    patience=5,\n",
    "    wd=1e-4,\n",
    "    transform_tensor=transform_train\n",
    "    ):\n",
    "  \"\"\"Training using knowledge distillation approach\n",
    "  \n",
    "  Arguments:\n",
    "      net_student {torch model} -- student model\n",
    "      trainloader {list} -- cached train set\n",
    "      testloader {DataLoader} -- test set\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      epoches {int} -- epochs to train (default: {150})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      return_best {bool} -- return best model (default: {False})\n",
    "      init_lr {float} -- initial learning rate (default: {0.1})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      cos_alpha {float} -- coefficeint of combining distillation (KL) and cosine disimilarity loss (default: {0})\n",
    "      shuffle {bool} -- shuffle dataset each epoch (default: {True})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      l_alpha {float} -- coefficeint of L^p loss in distillation loss (default: {0.0})\n",
    "      p {int} -- parametr for L^p loss (default: {2})\n",
    "  \n",
    "  Returns:\n",
    "      torch model -- best or last model\n",
    "  \"\"\"    \n",
    "  # change net to training mode\n",
    "  net_student.train()\n",
    "  net_teacher.eval()\n",
    "  # use gpu to train\n",
    "  net_student.cuda()\n",
    "\n",
    "  criterion_ce = nn.CrossEntropyLoss().cuda()\n",
    "  criterion_nll = nn.NLLLoss().cuda()\n",
    "  criterion_bce = nn.BCELoss().cuda() \n",
    "  criterion_kl = nn.KLDivLoss(reduction=\"batchmean\").cuda()\n",
    "  cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "  criterion_mse = nn.MSELoss()\n",
    "  criterion_mae = nn.L1Loss()\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "      net_student.parameters(), \n",
    "      lr=init_lr,\n",
    "      momentum=0.9,\n",
    "      weight_decay=wd\n",
    "      )\n",
    "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [80, 105, 125, 140])\n",
    "\n",
    "  validation_scores = []\n",
    "  os.makedirs(\"models\", exist_ok=True)\n",
    "  saving_path_template = \"models/model_epoch%s.dms\"\n",
    "\n",
    "  for epoch in range(epoches):  # loop over the dataset multiple times\n",
    "    saving_name = saving_path_template%epoch\n",
    "    \n",
    "    loss_avg = AverageMeter()\n",
    "    accuracy_score_avg = AverageMeter()\n",
    "    loss_kl_avg = AverageMeter()\n",
    "    loss_cos_dis_avg = AverageMeter()\n",
    "    loss_ce_avg = AverageMeter()\n",
    "\n",
    "    if shuffle:\n",
    "      np.random.shuffle(trainloader)\n",
    "\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_pil, out_teacher, labels = data\n",
    "        current_batch_size = len(out_teacher)\n",
    "\n",
    "        inputs = torch.stack([transform_tensor(j) for j in inputs_pil])\n",
    "        inputs, out_teacher = inputs.cuda(), out_teacher.cuda()\n",
    "\n",
    "        if cuda:\n",
    "          inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out_student = net_student(inputs)\n",
    "        soft_log_probs = F.log_softmax(out_student / temperature, dim=1)\n",
    "        soft_output = F.softmax(out_student / temperature, dim=1)\n",
    "        soft_targets = out_teacher#F.softmax(out_teacher / temperature, dim=1)\n",
    "        \n",
    "        # loss_bce = criterion_bce(F.sigmoid(out_student), F.sigmoid(out_teacher))\n",
    "        kl_loss = criterion_kl(soft_log_probs, soft_targets.detach())\n",
    "        cos_dis_loss =  (1 - cosine_similarity(out_student - torch.mean(out_student, dim=1, keepdim=True), out_teacher.detach() - torch.mean(out_teacher.detach(), dim=1, keepdim=True))).mean()\n",
    "        \n",
    "        \n",
    "        l_loss = (torch.abs(out_student - out_teacher)**p).mean()**(1/p)\n",
    "\n",
    "        loss = (1 - cos_alpha - l_alpha) * kl_loss + cos_alpha * cos_dis_loss + l_alpha * l_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        micro_acc_score = accuracy_minibatch(out_student, labels)\n",
    "\n",
    "        loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "        accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "        loss_kl_avg.update(kl_loss.item()*current_batch_size, current_batch_size)\n",
    "        loss_cos_dis_avg.update(cos_dis_loss.item()*current_batch_size, current_batch_size)\n",
    "        \n",
    "    if verbose:\n",
    "        print(saving_name)\n",
    "        print('overall loss {:.3}'.format(loss_avg.average()))\n",
    "        print('current lr {:.3e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        print(\"__________________\")\n",
    "    # clear memory \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    # save scores to take best model in the future\n",
    "    validation_score = validate(net_student, valloader, \n",
    "                                logger=logger, \n",
    "                                verbose=verbose, \n",
    "                                # compression_f=compression_f\n",
    "                                )\n",
    "    accuracy = validation_score['val_accuracy']\n",
    "    validation_scores.append(accuracy)\n",
    "    # save model\n",
    "    torch.save(net_student.state_dict(), saving_name)\n",
    "\n",
    "    if logger:\n",
    "        logger.log_scalar(\"overall_loss\", loss_avg.average())\n",
    "        logger.log_scalar(\"accuracy\", accuracy_score_avg.average())\n",
    "        logger.log_scalar(\"kl_loss\", loss_kl_avg.average())\n",
    "        logger.log_scalar(\"cos_dis_loss\", loss_cos_dis_avg.average())\n",
    "        logger.step()\n",
    "    # scheduler.step(loss_avg.average())\n",
    "    scheduler.step()\n",
    "    \n",
    "  best_epoch = np.argmax(validation_scores)\n",
    "  if return_best:\n",
    "    choosen_epoch = best_epoch\n",
    "  else:\n",
    "    choosen_epoch = epoch\n",
    "  if verbose:\n",
    "    print(\"choosen epoch:\", choosen_epoch, \", score:\", validation_scores[choosen_epoch])\n",
    "    print(\"best epoch:\", best_epoch, \", score:\", validation_scores[best_epoch])\n",
    "  model_name = saving_path_template%choosen_epoch\n",
    "  net_student.load_state_dict(torch.load(model_name))\n",
    "  return net_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4ttxWfsmRcT"
   },
   "outputs": [],
   "source": [
    "def cache_loader(net_teacher, loader, cuda=True,\n",
    "                 transform_tensor=transform_train,\n",
    "                 transform_repeats=4\n",
    "                 ):\n",
    "  \"\"\"Cache loader, to prevent computing teacher model output\n",
    "  \n",
    "  Arguments:\n",
    "      net_teacher {torch model} -- teacher model\n",
    "      loader {DataLoader} -- dataset to cache\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      cuda {bool} -- use cuda or not(default: {True})\n",
    "      transform_tensor {func} -- image transformation (default: {transform_train})\n",
    "      transform_repeats {int} -- amount of repeats (default: {int})\n",
    "  \n",
    "  Returns:\n",
    "      List -- List of (inputs, teacher model outputs)\n",
    "  \"\"\"    \n",
    "  net_teacher.eval()\n",
    "  cached = []\n",
    "  for inputs_pil, labels in loader:\n",
    "    labels = torch.tensor(labels)\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs_pil]) for i in range(transform_repeats)]\n",
    "\n",
    "    outputs = 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs += torch.softmax(net_teacher(inputs_[i].cuda() if cuda else inputs_[i]), dim=1)\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    cached.append([inputs_pil, outputs.cpu().detach(), labels.cpu().detach()])\n",
    "  return cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1078,
     "status": "ok",
     "timestamp": 1584006078526,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "VBug0SVkG4yj",
    "outputId": "a926c816-af9c-47bf-9ddf-7b32a2f59a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch0.dms\n",
      "overall loss 1.22\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48054444444444444\n",
      "val_overall_loss 1.4785727812449136\n",
      "__________________\n",
      "models/model_epoch1.dms\n",
      "overall loss 0.928\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5389888888888889\n",
      "val_overall_loss 1.2933208312352498\n",
      "__________________\n",
      "models/model_epoch2.dms\n",
      "overall loss 0.826\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5961888888888889\n",
      "val_overall_loss 1.1390091682857937\n",
      "__________________\n",
      "models/model_epoch3.dms\n",
      "overall loss 0.751\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6045555555555555\n",
      "val_overall_loss 1.0903941322114732\n",
      "__________________\n",
      "models/model_epoch4.dms\n",
      "overall loss 0.704\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6401888888888889\n",
      "val_overall_loss 1.020443856853909\n",
      "__________________\n",
      "models/model_epoch5.dms\n",
      "overall loss 0.668\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6532333333333333\n",
      "val_overall_loss 0.9688951449712118\n",
      "__________________\n",
      "models/model_epoch6.dms\n",
      "overall loss 0.643\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6694666666666667\n",
      "val_overall_loss 0.927489034790463\n",
      "__________________\n",
      "models/model_epoch7.dms\n",
      "overall loss 0.621\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6472222222222223\n",
      "val_overall_loss 0.9851590764787462\n",
      "__________________\n",
      "models/model_epoch8.dms\n",
      "overall loss 0.605\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6352111111111111\n",
      "val_overall_loss 1.0373583004845512\n",
      "__________________\n",
      "models/model_epoch9.dms\n",
      "overall loss 0.594\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6759444444444445\n",
      "val_overall_loss 0.9274865430831909\n",
      "__________________\n",
      "models/model_epoch10.dms\n",
      "overall loss 0.584\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6637888888888889\n",
      "val_overall_loss 0.9590319824430678\n",
      "__________________\n",
      "models/model_epoch11.dms\n",
      "overall loss 0.575\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6426777777777778\n",
      "val_overall_loss 1.0188923721101548\n",
      "__________________\n",
      "models/model_epoch12.dms\n",
      "overall loss 0.568\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6832333333333334\n",
      "val_overall_loss 0.8922992207209269\n",
      "__________________\n",
      "models/model_epoch13.dms\n",
      "overall loss 0.559\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6549444444444444\n",
      "val_overall_loss 0.9706007766564687\n",
      "__________________\n",
      "models/model_epoch14.dms\n",
      "overall loss 0.555\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6246111111111111\n",
      "val_overall_loss 1.0991380096912384\n",
      "__________________\n",
      "models/model_epoch15.dms\n",
      "overall loss 0.547\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6881777777777778\n",
      "val_overall_loss 0.8768826968934801\n",
      "__________________\n",
      "models/model_epoch16.dms\n",
      "overall loss 0.545\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6857333333333333\n",
      "val_overall_loss 0.888841700469123\n",
      "__________________\n",
      "models/model_epoch17.dms\n",
      "overall loss 0.543\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6955666666666667\n",
      "val_overall_loss 0.8639669835408529\n",
      "__________________\n",
      "models/model_epoch18.dms\n",
      "overall loss 0.536\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6684111111111111\n",
      "val_overall_loss 0.9296067433039348\n",
      "__________________\n",
      "models/model_epoch19.dms\n",
      "overall loss 0.533\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6724444444444444\n",
      "val_overall_loss 0.9243083123736912\n",
      "__________________\n",
      "models/model_epoch20.dms\n",
      "overall loss 0.529\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6705111111111111\n",
      "val_overall_loss 0.9391076418134902\n",
      "__________________\n",
      "models/model_epoch21.dms\n",
      "overall loss 0.528\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6819333333333333\n",
      "val_overall_loss 0.9056296350691053\n",
      "__________________\n",
      "models/model_epoch22.dms\n",
      "overall loss 0.525\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6684333333333333\n",
      "val_overall_loss 0.9465238565021091\n",
      "__________________\n",
      "models/model_epoch23.dms\n",
      "overall loss 0.523\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6882555555555555\n",
      "val_overall_loss 0.88080447040134\n",
      "__________________\n",
      "models/model_epoch24.dms\n",
      "overall loss 0.52\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6882\n",
      "val_overall_loss 0.8844632435056898\n",
      "__________________\n",
      "models/model_epoch25.dms\n",
      "overall loss 0.516\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6686\n",
      "val_overall_loss 0.9409012182447646\n",
      "__________________\n",
      "models/model_epoch26.dms\n",
      "overall loss 0.515\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6939\n",
      "val_overall_loss 0.8599407042397393\n",
      "__________________\n",
      "models/model_epoch27.dms\n",
      "overall loss 0.514\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6722333333333333\n",
      "val_overall_loss 0.9348357404179043\n",
      "__________________\n",
      "models/model_epoch28.dms\n",
      "overall loss 0.514\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7011333333333334\n",
      "val_overall_loss 0.8427172920438979\n",
      "__________________\n",
      "models/model_epoch29.dms\n",
      "overall loss 0.51\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6810888888888889\n",
      "val_overall_loss 0.9054903493245443\n",
      "__________________\n",
      "models/model_epoch30.dms\n",
      "overall loss 0.509\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6829111111111111\n",
      "val_overall_loss 0.9053958964453803\n",
      "__________________\n",
      "models/model_epoch31.dms\n",
      "overall loss 0.509\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6766666666666666\n",
      "val_overall_loss 0.9054452337053087\n",
      "__________________\n",
      "models/model_epoch32.dms\n",
      "overall loss 0.504\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6691\n",
      "val_overall_loss 0.9449243605295817\n",
      "__________________\n",
      "models/model_epoch33.dms\n",
      "overall loss 0.504\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6935333333333333\n",
      "val_overall_loss 0.8672401962969039\n",
      "__________________\n",
      "models/model_epoch34.dms\n",
      "overall loss 0.504\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6484111111111112\n",
      "val_overall_loss 1.002866965283288\n",
      "__________________\n",
      "models/model_epoch35.dms\n",
      "overall loss 0.502\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6939666666666666\n",
      "val_overall_loss 0.8691573767132229\n",
      "__________________\n",
      "models/model_epoch36.dms\n",
      "overall loss 0.499\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6969333333333333\n",
      "val_overall_loss 0.8593493736902873\n",
      "__________________\n",
      "models/model_epoch37.dms\n",
      "overall loss 0.5\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7\n",
      "val_overall_loss 0.8587723114225599\n",
      "__________________\n",
      "models/model_epoch38.dms\n",
      "overall loss 0.498\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6862444444444444\n",
      "val_overall_loss 0.8937897785027822\n",
      "__________________\n",
      "models/model_epoch39.dms\n",
      "overall loss 0.498\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6905555555555556\n",
      "val_overall_loss 0.8631435752444797\n",
      "__________________\n",
      "models/model_epoch40.dms\n",
      "overall loss 0.494\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6918333333333333\n",
      "val_overall_loss 0.8700216965887282\n",
      "__________________\n",
      "models/model_epoch41.dms\n",
      "overall loss 0.495\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6809555555555555\n",
      "val_overall_loss 0.9153055189980401\n",
      "__________________\n",
      "models/model_epoch42.dms\n",
      "overall loss 0.494\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6766777777777778\n",
      "val_overall_loss 0.9206622580952114\n",
      "__________________\n",
      "models/model_epoch43.dms\n",
      "overall loss 0.492\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7085\n",
      "val_overall_loss 0.8312435568915473\n",
      "__________________\n",
      "models/model_epoch44.dms\n",
      "overall loss 0.494\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6811555555555555\n",
      "val_overall_loss 0.9150356771892971\n",
      "__________________\n",
      "models/model_epoch45.dms\n",
      "overall loss 0.492\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6581111111111111\n",
      "val_overall_loss 0.9792193636576335\n",
      "__________________\n",
      "models/model_epoch46.dms\n",
      "overall loss 0.492\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7007\n",
      "val_overall_loss 0.8523861427519056\n",
      "__________________\n",
      "models/model_epoch47.dms\n",
      "overall loss 0.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6557555555555555\n",
      "val_overall_loss 0.9985581971910265\n",
      "__________________\n",
      "models/model_epoch48.dms\n",
      "overall loss 0.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6898111111111112\n",
      "val_overall_loss 0.8809160044564142\n",
      "__________________\n",
      "models/model_epoch49.dms\n",
      "overall loss 0.487\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6445444444444445\n",
      "val_overall_loss 1.0542909874598185\n",
      "__________________\n",
      "models/model_epoch50.dms\n",
      "overall loss 0.488\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6971111111111111\n",
      "val_overall_loss 0.8525542525715298\n",
      "__________________\n",
      "models/model_epoch51.dms\n",
      "overall loss 0.487\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6558555555555555\n",
      "val_overall_loss 0.9955866523530749\n",
      "__________________\n",
      "models/model_epoch52.dms\n",
      "overall loss 0.484\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6764888888888889\n",
      "val_overall_loss 0.913648640124003\n",
      "__________________\n",
      "models/model_epoch53.dms\n",
      "overall loss 0.487\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7030666666666666\n",
      "val_overall_loss 0.837193295372857\n",
      "__________________\n",
      "models/model_epoch54.dms\n",
      "overall loss 0.486\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6883777777777778\n",
      "val_overall_loss 0.8913955609639486\n",
      "__________________\n",
      "models/model_epoch55.dms\n",
      "overall loss 0.487\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6738777777777778\n",
      "val_overall_loss 0.9119019120746189\n",
      "__________________\n",
      "models/model_epoch56.dms\n",
      "overall loss 0.486\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6968666666666666\n",
      "val_overall_loss 0.8510463036007352\n",
      "__________________\n",
      "models/model_epoch57.dms\n",
      "overall loss 0.484\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6935444444444444\n",
      "val_overall_loss 0.8737903189129299\n",
      "__________________\n",
      "models/model_epoch58.dms\n",
      "overall loss 0.484\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7066555555555556\n",
      "val_overall_loss 0.837913034523858\n",
      "__________________\n",
      "models/model_epoch59.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6913555555555555\n",
      "val_overall_loss 0.8755718875673082\n",
      "__________________\n",
      "models/model_epoch60.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7020666666666666\n",
      "val_overall_loss 0.860058755853441\n",
      "__________________\n",
      "models/model_epoch61.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7138888888888889\n",
      "val_overall_loss 0.8071721207300822\n",
      "__________________\n",
      "models/model_epoch62.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6938\n",
      "val_overall_loss 0.8688933229870266\n",
      "__________________\n",
      "models/model_epoch63.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6668777777777778\n",
      "val_overall_loss 0.9627995874934726\n",
      "__________________\n",
      "models/model_epoch64.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7103111111111111\n",
      "val_overall_loss 0.8210863928900825\n",
      "__________________\n",
      "models/model_epoch65.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6918777777777778\n",
      "val_overall_loss 0.8784933401107788\n",
      "__________________\n",
      "models/model_epoch66.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6905777777777777\n",
      "val_overall_loss 0.8574098457548354\n",
      "__________________\n",
      "models/model_epoch67.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6925333333333333\n",
      "val_overall_loss 0.8707195998085869\n",
      "__________________\n",
      "models/model_epoch68.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7061555555555555\n",
      "val_overall_loss 0.8282769505182902\n",
      "__________________\n",
      "models/model_epoch69.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6593666666666667\n",
      "val_overall_loss 0.9675597330517239\n",
      "__________________\n",
      "models/model_epoch70.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6870111111111111\n",
      "val_overall_loss 0.8844256822162204\n",
      "__________________\n",
      "models/model_epoch71.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6984666666666667\n",
      "val_overall_loss 0.8493808613035414\n",
      "__________________\n",
      "models/model_epoch72.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6984333333333334\n",
      "val_overall_loss 0.860240416208903\n",
      "__________________\n",
      "models/model_epoch73.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6938333333333333\n",
      "val_overall_loss 0.879360008515252\n",
      "__________________\n",
      "models/model_epoch74.dms\n",
      "overall loss 0.473\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7152777777777778\n",
      "val_overall_loss 0.8021327637566461\n",
      "__________________\n",
      "models/model_epoch75.dms\n",
      "overall loss 0.476\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7063222222222222\n",
      "val_overall_loss 0.8348407135433621\n",
      "__________________\n",
      "models/model_epoch76.dms\n",
      "overall loss 0.474\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6948888888888889\n",
      "val_overall_loss 0.8755452418221368\n",
      "__________________\n",
      "models/model_epoch77.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6998222222222222\n",
      "val_overall_loss 0.8439663665559557\n",
      "__________________\n",
      "models/model_epoch78.dms\n",
      "overall loss 0.474\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6827222222222222\n",
      "val_overall_loss 0.8784084699418809\n",
      "__________________\n",
      "models/model_epoch79.dms\n",
      "overall loss 0.474\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6728\n",
      "val_overall_loss 0.9435003310733371\n",
      "__________________\n",
      "models/model_epoch80.dms\n",
      "overall loss 0.358\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7548111111111111\n",
      "val_overall_loss 0.693486627123091\n",
      "__________________\n",
      "models/model_epoch81.dms\n",
      "overall loss 0.332\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7544777777777778\n",
      "val_overall_loss 0.6912032688882616\n",
      "__________________\n",
      "models/model_epoch82.dms\n",
      "overall loss 0.321\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7594888888888889\n",
      "val_overall_loss 0.6811423344718085\n",
      "__________________\n",
      "models/model_epoch83.dms\n",
      "overall loss 0.313\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7591555555555556\n",
      "val_overall_loss 0.6818571546554565\n",
      "__________________\n",
      "models/model_epoch84.dms\n",
      "overall loss 0.31\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7586888888888889\n",
      "val_overall_loss 0.6811328199704488\n",
      "__________________\n",
      "models/model_epoch85.dms\n",
      "overall loss 0.305\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7570333333333333\n",
      "val_overall_loss 0.6886109675937229\n",
      "__________________\n",
      "models/model_epoch86.dms\n",
      "overall loss 0.301\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7605555555555555\n",
      "val_overall_loss 0.6767745424694485\n",
      "__________________\n",
      "models/model_epoch87.dms\n",
      "overall loss 0.296\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7605222222222222\n",
      "val_overall_loss 0.6809361917707655\n",
      "__________________\n",
      "models/model_epoch88.dms\n",
      "overall loss 0.295\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7625333333333333\n",
      "val_overall_loss 0.6762888465563456\n",
      "__________________\n",
      "models/model_epoch89.dms\n",
      "overall loss 0.291\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7594333333333333\n",
      "val_overall_loss 0.6867898308753967\n",
      "__________________\n",
      "models/model_epoch90.dms\n",
      "overall loss 0.289\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7601333333333333\n",
      "val_overall_loss 0.684213598256641\n",
      "__________________\n",
      "models/model_epoch91.dms\n",
      "overall loss 0.288\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7592\n",
      "val_overall_loss 0.687518926334381\n",
      "__________________\n",
      "models/model_epoch92.dms\n",
      "overall loss 0.284\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7609\n",
      "val_overall_loss 0.6817537116898431\n",
      "__________________\n",
      "models/model_epoch93.dms\n",
      "overall loss 0.284\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7529555555555556\n",
      "val_overall_loss 0.6992960358195834\n",
      "__________________\n",
      "models/model_epoch94.dms\n",
      "overall loss 0.283\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7611888888888889\n",
      "val_overall_loss 0.683566354560852\n",
      "__________________\n",
      "models/model_epoch95.dms\n",
      "overall loss 0.281\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7583444444444445\n",
      "val_overall_loss 0.691175907029046\n",
      "__________________\n",
      "models/model_epoch96.dms\n",
      "overall loss 0.28\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7578222222222222\n",
      "val_overall_loss 0.6885463287989299\n",
      "__________________\n",
      "models/model_epoch97.dms\n",
      "overall loss 0.278\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7602666666666666\n",
      "val_overall_loss 0.6839418479389614\n",
      "__________________\n",
      "models/model_epoch98.dms\n",
      "overall loss 0.276\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7602777777777778\n",
      "val_overall_loss 0.6812829939312405\n",
      "__________________\n",
      "models/model_epoch99.dms\n",
      "overall loss 0.276\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7566555555555555\n",
      "val_overall_loss 0.6952699919965533\n",
      "__________________\n",
      "models/model_epoch100.dms\n",
      "overall loss 0.275\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7593222222222222\n",
      "val_overall_loss 0.6867398921277788\n",
      "__________________\n",
      "models/model_epoch101.dms\n",
      "overall loss 0.276\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7587\n",
      "val_overall_loss 0.6865026618321737\n",
      "__________________\n",
      "models/model_epoch102.dms\n",
      "overall loss 0.275\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7579555555555556\n",
      "val_overall_loss 0.6922104489008586\n",
      "__________________\n",
      "models/model_epoch103.dms\n",
      "overall loss 0.273\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7535333333333334\n",
      "val_overall_loss 0.6993324480056763\n",
      "__________________\n",
      "models/model_epoch104.dms\n",
      "overall loss 0.272\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.7544444444444445\n",
      "val_overall_loss 0.7017334274186028\n",
      "__________________\n",
      "models/model_epoch105.dms\n",
      "overall loss 0.244\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7635666666666666\n",
      "val_overall_loss 0.676493834204144\n",
      "__________________\n",
      "models/model_epoch106.dms\n",
      "overall loss 0.24\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7641111111111111\n",
      "val_overall_loss 0.6732723104688856\n",
      "__________________\n",
      "models/model_epoch107.dms\n",
      "overall loss 0.239\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7639111111111111\n",
      "val_overall_loss 0.6739433936754863\n",
      "__________________\n",
      "models/model_epoch108.dms\n",
      "overall loss 0.238\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7632333333333333\n",
      "val_overall_loss 0.6766933572451274\n",
      "__________________\n",
      "models/model_epoch109.dms\n",
      "overall loss 0.236\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7625888888888889\n",
      "val_overall_loss 0.6782950364642673\n",
      "__________________\n",
      "models/model_epoch110.dms\n",
      "overall loss 0.235\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7650555555555556\n",
      "val_overall_loss 0.6747103472179836\n",
      "__________________\n",
      "models/model_epoch111.dms\n",
      "overall loss 0.235\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7634555555555556\n",
      "val_overall_loss 0.6763121833165486\n",
      "__________________\n",
      "models/model_epoch112.dms\n",
      "overall loss 0.234\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7635666666666666\n",
      "val_overall_loss 0.6757054734971788\n",
      "__________________\n",
      "models/model_epoch113.dms\n",
      "overall loss 0.234\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7647\n",
      "val_overall_loss 0.6744485814253489\n",
      "__________________\n",
      "models/model_epoch114.dms\n",
      "overall loss 0.232\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7646666666666667\n",
      "val_overall_loss 0.675131735504998\n",
      "__________________\n",
      "models/model_epoch115.dms\n",
      "overall loss 0.233\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7640777777777777\n",
      "val_overall_loss 0.674336331515842\n",
      "__________________\n",
      "models/model_epoch116.dms\n",
      "overall loss 0.232\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7640111111111111\n",
      "val_overall_loss 0.675522987318039\n",
      "__________________\n",
      "models/model_epoch117.dms\n",
      "overall loss 0.232\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7640111111111111\n",
      "val_overall_loss 0.6752016813490126\n",
      "__________________\n",
      "models/model_epoch118.dms\n",
      "overall loss 0.231\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7639777777777778\n",
      "val_overall_loss 0.6755459157096015\n",
      "__________________\n",
      "models/model_epoch119.dms\n",
      "overall loss 0.232\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7642333333333333\n",
      "val_overall_loss 0.674968268749449\n",
      "__________________\n",
      "models/model_epoch120.dms\n",
      "overall loss 0.231\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7641111111111111\n",
      "val_overall_loss 0.6750402264700995\n",
      "__________________\n",
      "models/model_epoch121.dms\n",
      "overall loss 0.23\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7626444444444445\n",
      "val_overall_loss 0.6786926719824473\n",
      "__________________\n",
      "models/model_epoch122.dms\n",
      "overall loss 0.23\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7640777777777777\n",
      "val_overall_loss 0.6764414431730906\n",
      "__________________\n",
      "models/model_epoch123.dms\n",
      "overall loss 0.229\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7629\n",
      "val_overall_loss 0.6792315381632911\n",
      "__________________\n",
      "models/model_epoch124.dms\n",
      "overall loss 0.229\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.7620555555555556\n",
      "val_overall_loss 0.67981469101376\n",
      "__________________\n",
      "models/model_epoch125.dms\n",
      "overall loss 0.226\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7632333333333333\n",
      "val_overall_loss 0.6765815328545041\n",
      "__________________\n",
      "models/model_epoch126.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7633\n",
      "val_overall_loss 0.6765857336256239\n",
      "__________________\n",
      "models/model_epoch127.dms\n",
      "overall loss 0.226\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7635777777777778\n",
      "val_overall_loss 0.6768666081958347\n",
      "__________________\n",
      "models/model_epoch128.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7639222222222222\n",
      "val_overall_loss 0.6752051088862949\n",
      "__________________\n",
      "models/model_epoch129.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7637666666666667\n",
      "val_overall_loss 0.6769885156737434\n",
      "__________________\n",
      "models/model_epoch130.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7635111111111111\n",
      "val_overall_loss 0.6763845940907797\n",
      "__________________\n",
      "models/model_epoch131.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7639111111111111\n",
      "val_overall_loss 0.6771829501999749\n",
      "__________________\n",
      "models/model_epoch132.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7640111111111111\n",
      "val_overall_loss 0.6764914122581482\n",
      "__________________\n",
      "models/model_epoch133.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7640888888888889\n",
      "val_overall_loss 0.6770261752340528\n",
      "__________________\n",
      "models/model_epoch134.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7640555555555556\n",
      "val_overall_loss 0.6767332449807061\n",
      "__________________\n",
      "models/model_epoch135.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7633888888888889\n",
      "val_overall_loss 0.6766917714966668\n",
      "__________________\n",
      "models/model_epoch136.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7625555555555555\n",
      "val_overall_loss 0.6809228793885973\n",
      "__________________\n",
      "models/model_epoch137.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7641666666666667\n",
      "val_overall_loss 0.6767009921391804\n",
      "__________________\n",
      "models/model_epoch138.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7638888888888888\n",
      "val_overall_loss 0.6767793474992116\n",
      "__________________\n",
      "models/model_epoch139.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.7639111111111111\n",
      "val_overall_loss 0.6778700037638347\n",
      "__________________\n",
      "models/model_epoch140.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7638111111111111\n",
      "val_overall_loss 0.6759995591057671\n",
      "__________________\n",
      "models/model_epoch141.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7637666666666667\n",
      "val_overall_loss 0.6760367640972137\n",
      "__________________\n",
      "models/model_epoch142.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7620333333333333\n",
      "val_overall_loss 0.6774982129202949\n",
      "__________________\n",
      "models/model_epoch143.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7633333333333333\n",
      "val_overall_loss 0.6756873292711046\n",
      "__________________\n",
      "models/model_epoch144.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7627222222222222\n",
      "val_overall_loss 0.6785125808080037\n",
      "__________________\n",
      "models/model_epoch145.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7643555555555556\n",
      "val_overall_loss 0.675074880917867\n",
      "__________________\n",
      "models/model_epoch146.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7638444444444444\n",
      "val_overall_loss 0.6765705183876886\n",
      "__________________\n",
      "models/model_epoch147.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7645888888888889\n",
      "val_overall_loss 0.6747642355706956\n",
      "__________________\n",
      "models/model_epoch148.dms\n",
      "overall loss 0.225\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7642\n",
      "val_overall_loss 0.6765493735525343\n",
      "__________________\n",
      "models/model_epoch149.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.7633888888888889\n",
      "val_overall_loss 0.6776031076272329\n",
      "__________________\n",
      "choosen epoch: 110 , score: 0.7650555555555556\n",
      "best epoch: 110 , score: 0.7650555555555556\n",
      "-----------------\n",
      "*****************\n",
      "resnet20_kl_soft_aug.pt\n",
      "test_accuracy 0.7629222222222222\n",
      "test_overall_loss 0.6802860571861267\n",
      "__________________\n",
      "val_accuracy 0.7650555555555556\n",
      "val_overall_loss 0.67471034722858\n",
      "__________________\n",
      "train_accuracy 0.8375666666666667\n",
      "train_overall_loss 0.4852195342275831\n",
      "__________________\n",
      "----------------\n",
      "test_accuracy 0.8219111111111111\n",
      "test_overall_loss 0.5648095791843203\n",
      "__________________\n",
      "val_accuracy 0.8259333333333333\n",
      "val_overall_loss 0.5549910774442884\n",
      "__________________\n",
      "train_accuracy 0.9212777777777778\n",
      "train_overall_loss 0.22153428062333\n",
      "__________________\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  for net_teacher, net_student, teacher_name, student_name in [\n",
    "                    (resnet20(), resnet7(), \"resnet20_classic.pt\", \"\"), \n",
    "                    ]:\n",
    "\n",
    "    epochs = 150\n",
    "    download_model(teacher_name, teacher_name)\n",
    "    state_dict_teacher = torch.load(teacher_name)\n",
    "    net_teacher.cuda().load_state_dict(state_dict_teacher)\n",
    "    \n",
    "    loader_cached = cache_loader(net_teacher, trainloader, transform_repeats=8)\n",
    "\n",
    "    experiment_name = teacher_name[:8]+\"_kl_soft_aug.pt\"\n",
    "    logger = TensorBoardLogger(\"logs\", dataset_name, \"resnet7\", experiment_name)\n",
    "    net_student = train_distillation_cached(\n",
    "                              net_student,\n",
    "                              loader_cached,\n",
    "                              valloader,\n",
    "                              epoches=epochs, \n",
    "                              init_lr=1e-1, \n",
    "                              logger=logger,\n",
    "                              return_best=True,\n",
    "                              cos_alpha=0.0,\n",
    "                              l_alpha=0.0,\n",
    "                              p=2,\n",
    "                              patience=5,\n",
    "                              wd=1e-4,\n",
    "                              temperature=1\n",
    "                              )\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"*****************\")\n",
    "    print(experiment_name)\n",
    "    score_test = validate(net_student, testloader, prename='test')\n",
    "    score_val = validate(net_student, valloader, prename='val')\n",
    "    score_train=validate(net_student, trainloader, prename='train')\n",
    "\n",
    "    print(\"----------------\")\n",
    "    score_teacher_test = validate(net_teacher, testloader, prename='test')\n",
    "    score_teacher_val = validate(net_teacher, valloader, prename='val')\n",
    "    score_teacher_train = validate(net_teacher, trainloader, prename='train')\n",
    "    print(\"----------------\")\n",
    "\n",
    "    hparams = {\"experiment_name\":experiment_name, \"teacher\":teacher_name, \"dataset\":dataset_name}\n",
    "    for key, value in score_val.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_test.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_train.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    \n",
    "    for key, value in score_teacher_test.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_val.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_train.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "\n",
    "    logger.log_hparams(hparams) \n",
    "\n",
    "    torch.save(net_student.state_dict(), experiment_name)\n",
    "\n",
    "    saving_path_template = \"models/model_epoch%s.dms\"\n",
    "    logger.step_=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving logs and remove extra files for kaggle kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf logs.tar.gz logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test train valid resnet.py models logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPBWsC5OS8rlaLdr0y6D6Kx",
   "mount_file_id": "14D6eHHLfNT2vf3HGVlL9cLS9qjY_7CL2",
   "name": "hyp_aug_cached_cinic10_distillation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
