{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloanding third-party code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "wfePU8fqBh0p",
    "outputId": "7baf31ca-4b9c-42bc-cb8e-0f88763827ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-15 22:07:35--  https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.244.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.244.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5001 (4,9K) [text/plain]\n",
      "Saving to: ‘resnet.py’\n",
      "\n",
      "resnet.py           100%[===================>]   4,88K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-15 22:07:35 (24,3 MB/s) - ‘resnet.py’ saved [5001/5001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading/uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "lLar-Or9BtDy",
    "outputId": "361d1082-8ac9-450f-ee55-ac7038d63658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# autorize in google dirve\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# download model from google drive\n",
    "def download_model(source_name, saving_name):\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp \"drive/My Drive/Colab Notebooks/Study/theasis/cifar100_models/{source_name}\" {saving_name}\n",
    "\n",
    "# upload model to google drive\n",
    "def upload_model(source_name, saving_name):\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp {source_name} \"drive/My Drive/Colab Notebooks/Study/theasis/cifar100_models/{saving_name}\" \n",
    "\n",
    "def upload_logs():\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp -r logs \"drive/My Drive/Colab Notebooks/Study/theasis/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TOcXRszTBup_",
    "outputId": "8f752d38-3928-4533-ff42-2668991d2d07"
   },
   "source": [
    "Libs importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDHAyQCTB0m7"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from resnet import BasicBlock, _weights_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xa7B59P1Do6I"
   },
   "outputs": [],
   "source": [
    "class ResNetModified(nn.Module):\n",
    "    def __init__(self, block, num_blocks, input_channels, num_classes=10):\n",
    "        super(ResNetModified, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vcl3BIJ3Dqcg"
   },
   "outputs": [],
   "source": [
    "def resnet7():return ResNetModified(BasicBlock, [1, 1, 1], 3, 100)\n",
    "def resnet20():return ResNetModified(BasicBlock, [3, 3, 3], 3, 100)\n",
    "def resnet32():return ResNetModified(BasicBlock, [5, 5, 5], 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration of utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiMNJcDPB2lJ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "  \"\"\"Class for computing average values\n",
    "  \"\"\"    \n",
    "  def __init__(self):\n",
    "    \"\"\"Init class\n",
    "    \"\"\"      \n",
    "    self.sum_ = 0\n",
    "    self.count = 0\n",
    "  \n",
    "  def update(self, val, count=1):\n",
    "    \"\"\"Add new value to track\n",
    "    \n",
    "    Arguments:\n",
    "        val {float} -- new value\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        count {int} -- weigth of val (default: {1})\n",
    "    \"\"\"      \n",
    "    self.sum_ += val\n",
    "    self.count += count\n",
    "\n",
    "  def average(self):\n",
    "    \"\"\"return average value for given values\n",
    "    \"\"\"      \n",
    "    return self.sum_ / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2rud3U0B5Pu"
   },
   "outputs": [],
   "source": [
    "class TensorBoardLogger:\n",
    "    \"\"\"Class for logging into TensorBoard\n",
    "    \"\"\"    \n",
    "    def __init__(self, log_dir, dataset, net, experiment_name):\n",
    "        \"\"\"Init logger\n",
    "        \n",
    "        Arguments:\n",
    "            log_dir {string} -- log dir\n",
    "            dataset {string} -- name of dataset\n",
    "            experiment_name {string} -- name of experiment\n",
    "        \"\"\"        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        log_dir_full = os.path.join(log_dir, dataset, net, experiment_name, current_time)\n",
    "        self.writer = tf.summary.create_file_writer(log_dir_full)\n",
    "        self.step_ = 0\n",
    "        \n",
    "    def log_scalar(self, tag, value, step=None, description=None):\n",
    "        \"\"\"Log scalar\n",
    "        \n",
    "        Arguments:\n",
    "            tag {string} -- name of variable to log\n",
    "            value {float} -- value of variable\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            step {int} -- current epoch number (default: {None})\n",
    "            description {string} -- [description] (default: {None})\n",
    "        \"\"\"        \n",
    "        if step is None:\n",
    "            step = self.step_\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(tag, value, step=step, description=description)\n",
    "            \n",
    "    def step(self):\n",
    "        \"\"\"Increase epoch number by 1\n",
    "        \"\"\"        \n",
    "        self.step_+=1\n",
    "\n",
    "    def log_hparams(self, hparams):\n",
    "        \"\"\"log hparams\n",
    "        \n",
    "        Arguments:\n",
    "            hparams {dict} -- dict to log\n",
    "        \"\"\"      \n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(hparams)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewF2eWCOB7Pr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_name = \"cifar100_cached\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "072aa660c2e04479ac07bd1f46f66772",
      "69ca822651aa4a72a61d451781003804",
      "47b5582999514e62a7405e20b5caf93d",
      "f965c0bd04b649e78dfb8aa87efffee4",
      "b26b6eee38f54c42addb108d3e32f275",
      "151037d5e3044a909047f2f127f5d00a",
      "ac7640b6c9a74a988262a366a3f80344",
      "a5dd88059b3b4b61bd78cb5dc449e9ee"
     ]
    },
    "colab_type": "code",
    "id": "ph7_tHYAB9cN",
    "outputId": "cc797c0c-ec57-444d-943c-70a481b5b8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# augmentation and normaliztion for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "    #  transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #  transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "# only normalization for testing\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "valset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform_test)\n",
    "# split trainvalset into val and train\n",
    "idx = np.arange(len(trainset))\n",
    "split = int(len(trainset)*0.15)\n",
    "np.random.seed(42) # set seed to reproduce given set\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[split:]\n",
    "val_idx = idx[:split]\n",
    "\n",
    "trainset = Subset(trainset, train_idx)\n",
    "valset = Subset(valset, val_idx)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          )\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                         pin_memory=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApgwwyiYB_Oy"
   },
   "outputs": [],
   "source": [
    "# check the first index, to check that trainval set splitted correctly\n",
    "assert val_idx[0]==33553, \"invalid val set\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 4 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slWmMP1LCC9b"
   },
   "outputs": [],
   "source": [
    "def accuracy_minibatch(outputs, labels):\n",
    "  \"\"\"Compute accuracy for batch\n",
    "  \n",
    "  Arguments:\n",
    "      outputs {list or np.array or torch.Tensor} -- outputs from model (vectors of probabilities)\n",
    "      labels {list or np.array or torch.Tensor} -- labels (one number for each sample)\n",
    "  \n",
    "  Returns:\n",
    "      float -- accuracy for minibatch\n",
    "  \"\"\"  \n",
    "  if isinstance(outputs, torch.Tensor):\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "  if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "  \n",
    "  predict_= np.argmax(outputs, axis=1)\n",
    "  true_labels_= labels\n",
    "  micro_acc_score = accuracy_score(predict_, true_labels_)\n",
    "  return micro_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07DXQHlXCEa_"
   },
   "outputs": [],
   "source": [
    "def validate(net, testloader, logger=None, compression_f=None, verbose=True, prename=\"val\"):\n",
    "  \"\"\"Function for compute metrics on validation set\n",
    "  \n",
    "  Arguments:\n",
    "      net {torch net} -- model\n",
    "      testloader {DataLoader} -- set to validation\n",
    "      \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      prename {string} -- prename to name of metric (default: {\"val\"})\n",
    "  \n",
    "  Returns:\n",
    "      [floats] -- scores for computing metrics\n",
    "  \"\"\"  \n",
    "  # change net to evaluation mode\n",
    "  net.eval()\n",
    "  ce_loss_avg = AverageMeter()\n",
    "  accuracy_score_avg = AverageMeter()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  # evaluate dataset\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    current_batch_size = len(labels)\n",
    "\n",
    "    if compression_f is not None:\n",
    "      inputs = compression_f(inputs)\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels).cpu().detach().numpy()\n",
    "    \n",
    "    micro_acc_score = accuracy_minibatch(outputs, labels)\n",
    "\n",
    "    accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "    ce_loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "\n",
    "  accuracy = accuracy_score_avg.average()\n",
    "  ce_loss = ce_loss_avg.average()\n",
    "  scores = {\n",
    "      \"%s_accuracy\"%prename: accuracy,\n",
    "      \"%s_overall_loss\"%prename: ce_loss,\n",
    "       }\n",
    "  \n",
    "  # log scores\n",
    "  for name, score in scores.items():\n",
    "    if logger:\n",
    "      logger.log_scalar(name, score)\n",
    "    if verbose:\n",
    "      print(name, score)\n",
    "  \n",
    "  if verbose:\n",
    "    print(\"__________________\")\n",
    "  # change net to training mode\n",
    "  net.train()\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4W9q_waCczor"
   },
   "outputs": [],
   "source": [
    "def train_distillation_cached(\n",
    "    net_student, \n",
    "    trainloader, \n",
    "    testloader, \n",
    "    logger=None,\n",
    "    compression_f=None, \n",
    "    epoches=150,\n",
    "    verbose=True, \n",
    "    return_best=False,\n",
    "    init_lr=0.1,\n",
    "    temperature=1,\n",
    "    cos_alpha=0,\n",
    "    l_alpha=0,\n",
    "    p=2,\n",
    "    shuffle=True,\n",
    "    patience=5,\n",
    "    wd=1e-4,\n",
    "    cs=False\n",
    "    ):\n",
    "  \"\"\"Training using knowledge distillation approach\n",
    "  \n",
    "  Arguments:\n",
    "      net_student {torch model} -- student model\n",
    "      trainloader {list} -- cached train set\n",
    "      testloader {DataLoader} -- test set\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      epoches {int} -- epochs to train (default: {150})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      return_best {bool} -- return best model (default: {False})\n",
    "      init_lr {float} -- initial learning rate (default: {0.1})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      cos_alpha {float} -- cooefficeint of cosine disimilarity loss in distillation loss (default: {0})\n",
    "      shuffle {bool} -- shuffle dataset each epoch (default: {True})\n",
    "      l_alpha {float} -- coefficeint of L^p loss in distillation loss (default: {0.0})\n",
    "      p {int} -- parametr for L^p loss (default: {2})\n",
    "  \n",
    "  Returns:\n",
    "      torch model -- best or last model\n",
    "  \"\"\"  \n",
    "  # change net to training mode\n",
    "  net_student.train()\n",
    "  net_teacher.eval()\n",
    "  # use gpu to train\n",
    "  net_student.cuda()\n",
    "\n",
    "  criterion_ce = nn.CrossEntropyLoss().cuda()\n",
    "  criterion_nll = nn.NLLLoss().cuda()\n",
    "  criterion_bce = nn.BCELoss().cuda() \n",
    "  criterion_kl = nn.KLDivLoss(reduction=\"batchmean\").cuda()\n",
    "  cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-8)\n",
    "  criterion_mse = nn.MSELoss()\n",
    "  criterion_mae = nn.L1Loss()\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "      net_student.parameters(), \n",
    "      lr=init_lr,\n",
    "      momentum=0.9,\n",
    "      weight_decay=wd\n",
    "      )\n",
    "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [80, 105, 125, 140])\n",
    "\n",
    "  validation_scores = []\n",
    "  os.makedirs(\"models\", exist_ok=True)\n",
    "  saving_path_template = \"models/model_epoch%s.dms\"\n",
    "\n",
    "  for epoch in range(epoches):  # loop over the dataset multiple times\n",
    "    saving_name = saving_path_template%epoch\n",
    "    \n",
    "    loss_avg = AverageMeter()\n",
    "    accuracy_score_avg = AverageMeter()\n",
    "    loss_kl_avg = AverageMeter()\n",
    "    loss_cos_dis_avg = AverageMeter()\n",
    "    loss_ce_avg = AverageMeter()\n",
    "\n",
    "    if shuffle:\n",
    "      np.random.shuffle(trainloader)\n",
    "\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, out_teacher, labels = data\n",
    "        current_batch_size = len(out_teacher)\n",
    "        inputs, out_teacher = inputs.cuda(), out_teacher.cuda()\n",
    "        # for supervision transfer\n",
    "        if compression_f:\n",
    "          inputs_compressed = compression_f(inputs).detach()\n",
    "        else:\n",
    "          inputs_compressed = inputs\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out_student = net_student(inputs_compressed)\n",
    "        soft_log_probs = F.log_softmax(out_student / temperature, dim=1)\n",
    "        soft_output = F.softmax(out_student / temperature, dim=1)\n",
    "        soft_targets = F.softmax(out_teacher / temperature, dim=1)\n",
    "        \n",
    "        loss_bce = criterion_bce(soft_output, soft_targets)\n",
    "        kl_loss = criterion_kl(soft_log_probs, soft_targets.detach())\n",
    "        cos_dis_loss =  (1 - cosine_similarity(out_student - torch.mean(out_student, dim=1, keepdim=True), out_teacher.detach() - torch.mean(out_teacher.detach(), dim=1, keepdim=True))).mean()\n",
    "               \n",
    "        l_loss = (torch.abs(out_student - out_teacher)**p).mean()**(1/p)\n",
    "\n",
    "        loss = (1 - cos_alpha - l_alpha) * kl_loss + cos_alpha * cos_dis_loss + l_alpha * l_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        micro_acc_score = accuracy_minibatch(out_student, labels)\n",
    "\n",
    "        loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "        accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "        loss_kl_avg.update(kl_loss.item()*current_batch_size, current_batch_size)\n",
    "        loss_cos_dis_avg.update(cos_dis_loss.item()*current_batch_size, current_batch_size)\n",
    "        # loss_ce_avg.update(loss_ce.item()*current_batch_size, current_batch_size)\n",
    "        \n",
    "    if verbose:\n",
    "        print(saving_name)\n",
    "        print('overall loss {:.3}'.format(loss_avg.average()))\n",
    "        print('current lr {:.3e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        print(\"__________________\")\n",
    "    # clear memory \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    # save scores to take best model in the future\n",
    "    validation_score = validate(net_student, valloader, \n",
    "                                logger=logger, \n",
    "                                verbose=verbose, \n",
    "                                compression_f=compression_f)\n",
    "    accuracy = validation_score['val_accuracy']\n",
    "    validation_scores.append(accuracy)\n",
    "    # save model\n",
    "    torch.save(net_student.state_dict(), saving_name)\n",
    "\n",
    "    if logger:\n",
    "        logger.log_scalar(\"overall_loss\", loss_avg.average())\n",
    "        logger.log_scalar(\"accuracy\", accuracy_score_avg.average())\n",
    "        logger.log_scalar(\"kl_loss\", loss_kl_avg.average())\n",
    "        logger.log_scalar(\"cos_dis_loss\", loss_cos_dis_avg.average())\n",
    "        logger.step()\n",
    "    # scheduler.step(loss_avg.average())\n",
    "    scheduler.step()\n",
    "    \n",
    "  best_epoch = np.argmax(validation_scores)\n",
    "  if return_best:\n",
    "    choosen_epoch = best_epoch\n",
    "  else:\n",
    "    choosen_epoch = epoch\n",
    "  if verbose:\n",
    "    print(\"choosen epoch:\", choosen_epoch, \", score:\", validation_scores[choosen_epoch])\n",
    "    print(\"best epoch:\", best_epoch, \", score:\", validation_scores[best_epoch])\n",
    "  model_name = saving_path_template%choosen_epoch\n",
    "  net_student.load_state_dict(torch.load(model_name))\n",
    "  return net_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk0eD3Y3c1jW"
   },
   "outputs": [],
   "source": [
    "def cache_loader(net_teacher, loader, cuda=True):\n",
    "  \"\"\"Cache loader, to prevent computing teacher model output\n",
    "  \n",
    "  Arguments:\n",
    "      net_teacher {torch model} -- teacher model\n",
    "      loader {DataLoader} -- dataset to cache\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      cuda {bool} -- use cuda or not(default: {True})\n",
    "  \n",
    "  Returns:\n",
    "      List -- List of (inputs, teacher model outputs)\n",
    "  \"\"\"  \n",
    "  net_teacher.eval()\n",
    "  cached = []\n",
    "  for inputs, labels in loader:\n",
    "    if cuda:\n",
    "      inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    outputs = net_teacher(inputs)\n",
    "    cached.append((inputs.cpu().detach(), outputs.cpu().detach(), labels.cpu().detach()))\n",
    "  return cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Z0F-J-qgc_Nu",
    "outputId": "013b8786-b551-4e7a-a3e1-4ee1776927ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch0.dms\n",
      "overall loss 3.75\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.1172\n",
      "val_overall_loss 3.706892124303182\n",
      "__________________\n",
      "models/model_epoch1.dms\n",
      "overall loss 3.2\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.17506666666666668\n",
      "val_overall_loss 3.5231893072764078\n",
      "__________________\n",
      "models/model_epoch2.dms\n",
      "overall loss 2.94\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.2613333333333333\n",
      "val_overall_loss 2.8897482893625894\n",
      "__________________\n",
      "models/model_epoch3.dms\n",
      "overall loss 2.79\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.2966666666666667\n",
      "val_overall_loss 2.6903975187937417\n",
      "__________________\n",
      "models/model_epoch4.dms\n",
      "overall loss 2.68\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.2813333333333333\n",
      "val_overall_loss 3.019278364562988\n",
      "__________________\n",
      "models/model_epoch5.dms\n",
      "overall loss 2.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.3198666666666667\n",
      "val_overall_loss 2.6744378072102863\n",
      "__________________\n",
      "models/model_epoch6.dms\n",
      "overall loss 2.54\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.3676\n",
      "val_overall_loss 2.45125986366272\n",
      "__________________\n",
      "models/model_epoch7.dms\n",
      "overall loss 2.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.38133333333333336\n",
      "val_overall_loss 2.3350198246002196\n",
      "__________________\n",
      "models/model_epoch8.dms\n",
      "overall loss 2.45\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.39\n",
      "val_overall_loss 2.2769910990397135\n",
      "__________________\n",
      "models/model_epoch9.dms\n",
      "overall loss 2.42\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4088\n",
      "val_overall_loss 2.161282701619466\n",
      "__________________\n",
      "models/model_epoch10.dms\n",
      "overall loss 2.39\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.3556\n",
      "val_overall_loss 2.6582429597218833\n",
      "__________________\n",
      "models/model_epoch11.dms\n",
      "overall loss 2.37\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4162666666666667\n",
      "val_overall_loss 2.237775761540731\n",
      "__________________\n",
      "models/model_epoch12.dms\n",
      "overall loss 2.35\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4126666666666667\n",
      "val_overall_loss 2.2444641717274982\n",
      "__________________\n",
      "models/model_epoch13.dms\n",
      "overall loss 2.34\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4125333333333333\n",
      "val_overall_loss 2.250974919637044\n",
      "__________________\n",
      "models/model_epoch14.dms\n",
      "overall loss 2.32\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4348\n",
      "val_overall_loss 2.127794528388977\n",
      "__________________\n",
      "models/model_epoch15.dms\n",
      "overall loss 2.31\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44253333333333333\n",
      "val_overall_loss 2.0806158217112225\n",
      "__________________\n",
      "models/model_epoch16.dms\n",
      "overall loss 2.3\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.40853333333333336\n",
      "val_overall_loss 2.2440659982681272\n",
      "__________________\n",
      "models/model_epoch17.dms\n",
      "overall loss 2.28\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4362666666666667\n",
      "val_overall_loss 2.109554073270162\n",
      "__________________\n",
      "models/model_epoch18.dms\n",
      "overall loss 2.27\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44666666666666666\n",
      "val_overall_loss 2.145099682235718\n",
      "__________________\n",
      "models/model_epoch19.dms\n",
      "overall loss 2.27\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44453333333333334\n",
      "val_overall_loss 2.1784443909962974\n",
      "__________________\n",
      "models/model_epoch20.dms\n",
      "overall loss 2.26\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4517333333333333\n",
      "val_overall_loss 2.0621300689379374\n",
      "__________________\n",
      "models/model_epoch21.dms\n",
      "overall loss 2.25\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4517333333333333\n",
      "val_overall_loss 2.0424895917892454\n",
      "__________________\n",
      "models/model_epoch22.dms\n",
      "overall loss 2.24\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4378666666666667\n",
      "val_overall_loss 2.132859889221191\n",
      "__________________\n",
      "models/model_epoch23.dms\n",
      "overall loss 2.24\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4461333333333333\n",
      "val_overall_loss 2.057195487276713\n",
      "__________________\n",
      "models/model_epoch24.dms\n",
      "overall loss 2.23\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.41413333333333335\n",
      "val_overall_loss 2.344930825805664\n",
      "__________________\n",
      "models/model_epoch25.dms\n",
      "overall loss 2.23\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4594666666666667\n",
      "val_overall_loss 2.0165768118540446\n",
      "__________________\n",
      "models/model_epoch26.dms\n",
      "overall loss 2.22\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.43733333333333335\n",
      "val_overall_loss 2.1540755297342935\n",
      "__________________\n",
      "models/model_epoch27.dms\n",
      "overall loss 2.22\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4336\n",
      "val_overall_loss 2.219301719156901\n",
      "__________________\n",
      "models/model_epoch28.dms\n",
      "overall loss 2.21\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45666666666666667\n",
      "val_overall_loss 2.022803931236267\n",
      "__________________\n",
      "models/model_epoch29.dms\n",
      "overall loss 2.21\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4576\n",
      "val_overall_loss 2.1184055925369263\n",
      "__________________\n",
      "models/model_epoch30.dms\n",
      "overall loss 2.21\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4496\n",
      "val_overall_loss 2.0557323656717936\n",
      "__________________\n",
      "models/model_epoch31.dms\n",
      "overall loss 2.21\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45866666666666667\n",
      "val_overall_loss 2.012432074610392\n",
      "__________________\n",
      "models/model_epoch32.dms\n",
      "overall loss 2.19\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4392\n",
      "val_overall_loss 2.118501690673828\n",
      "__________________\n",
      "models/model_epoch33.dms\n",
      "overall loss 2.2\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45493333333333336\n",
      "val_overall_loss 2.0849247689565025\n",
      "__________________\n",
      "models/model_epoch34.dms\n",
      "overall loss 2.19\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45\n",
      "val_overall_loss 2.0846037893931073\n",
      "__________________\n",
      "models/model_epoch35.dms\n",
      "overall loss 2.19\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44306666666666666\n",
      "val_overall_loss 2.0991091724395754\n",
      "__________________\n",
      "models/model_epoch36.dms\n",
      "overall loss 2.19\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.38106666666666666\n",
      "val_overall_loss 2.6258099919637043\n",
      "__________________\n",
      "models/model_epoch37.dms\n",
      "overall loss 2.19\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4597333333333333\n",
      "val_overall_loss 2.029743544514974\n",
      "__________________\n",
      "models/model_epoch38.dms\n",
      "overall loss 2.18\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45426666666666665\n",
      "val_overall_loss 2.071342555999756\n",
      "__________________\n",
      "models/model_epoch39.dms\n",
      "overall loss 2.18\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45813333333333334\n",
      "val_overall_loss 2.0587897246042886\n",
      "__________________\n",
      "models/model_epoch40.dms\n",
      "overall loss 2.18\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46013333333333334\n",
      "val_overall_loss 1.996167493502299\n",
      "__________________\n",
      "models/model_epoch41.dms\n",
      "overall loss 2.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4649333333333333\n",
      "val_overall_loss 1.9471211341222128\n",
      "__________________\n",
      "models/model_epoch42.dms\n",
      "overall loss 2.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4568\n",
      "val_overall_loss 2.027653867403666\n",
      "__________________\n",
      "models/model_epoch43.dms\n",
      "overall loss 2.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46986666666666665\n",
      "val_overall_loss 2.0140346008936563\n",
      "__________________\n",
      "models/model_epoch44.dms\n",
      "overall loss 2.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46546666666666664\n",
      "val_overall_loss 1.9932004126230876\n",
      "__________________\n",
      "models/model_epoch45.dms\n",
      "overall loss 2.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46626666666666666\n",
      "val_overall_loss 1.9840316416422525\n",
      "__________________\n",
      "models/model_epoch46.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4557333333333333\n",
      "val_overall_loss 2.0585389125823976\n",
      "__________________\n",
      "models/model_epoch47.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46746666666666664\n",
      "val_overall_loss 1.9867063323338827\n",
      "__________________\n",
      "models/model_epoch48.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46613333333333334\n",
      "val_overall_loss 1.9614108494440714\n",
      "__________________\n",
      "models/model_epoch49.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4456\n",
      "val_overall_loss 2.1055973472595215\n",
      "__________________\n",
      "models/model_epoch50.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4772\n",
      "val_overall_loss 1.9236602539698282\n",
      "__________________\n",
      "models/model_epoch51.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44693333333333335\n",
      "val_overall_loss 2.0796831033070884\n",
      "__________________\n",
      "models/model_epoch52.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47373333333333334\n",
      "val_overall_loss 1.9213604382832845\n",
      "__________________\n",
      "models/model_epoch53.dms\n",
      "overall loss 2.16\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4498666666666667\n",
      "val_overall_loss 2.2030108841578167\n",
      "__________________\n",
      "models/model_epoch54.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46373333333333333\n",
      "val_overall_loss 2.0176942956288655\n",
      "__________________\n",
      "models/model_epoch55.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4533333333333333\n",
      "val_overall_loss 2.1913797387441\n",
      "__________________\n",
      "models/model_epoch56.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48146666666666665\n",
      "val_overall_loss 1.9054294270833334\n",
      "__________________\n",
      "models/model_epoch57.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45893333333333336\n",
      "val_overall_loss 2.064429159164429\n",
      "__________________\n",
      "models/model_epoch58.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4744\n",
      "val_overall_loss 1.981643963623047\n",
      "__________________\n",
      "models/model_epoch59.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46453333333333335\n",
      "val_overall_loss 1.9790935576121012\n",
      "__________________\n",
      "models/model_epoch60.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4572\n",
      "val_overall_loss 2.0242686651865642\n",
      "__________________\n",
      "models/model_epoch61.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.466\n",
      "val_overall_loss 2.0769857975006105\n",
      "__________________\n",
      "models/model_epoch62.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44813333333333333\n",
      "val_overall_loss 2.2012142581939695\n",
      "__________________\n",
      "models/model_epoch63.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4746666666666667\n",
      "val_overall_loss 1.9190039704004924\n",
      "__________________\n",
      "models/model_epoch64.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45266666666666666\n",
      "val_overall_loss 2.1075208302815756\n",
      "__________________\n",
      "models/model_epoch65.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45106666666666667\n",
      "val_overall_loss 2.095464611180623\n",
      "__________________\n",
      "models/model_epoch66.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48586666666666667\n",
      "val_overall_loss 1.8783366970698039\n",
      "__________________\n",
      "models/model_epoch67.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47986666666666666\n",
      "val_overall_loss 1.9407368193944294\n",
      "__________________\n",
      "models/model_epoch68.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45893333333333336\n",
      "val_overall_loss 2.0565234219868977\n",
      "__________________\n",
      "models/model_epoch69.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4412\n",
      "val_overall_loss 2.1704582981109617\n",
      "__________________\n",
      "models/model_epoch70.dms\n",
      "overall loss 2.14\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47386666666666666\n",
      "val_overall_loss 1.967451013247172\n",
      "__________________\n",
      "models/model_epoch71.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4824\n",
      "val_overall_loss 1.9080323296229045\n",
      "__________________\n",
      "models/model_epoch72.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4712\n",
      "val_overall_loss 2.0032856280008953\n",
      "__________________\n",
      "models/model_epoch73.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.462\n",
      "val_overall_loss 2.016235480626424\n",
      "__________________\n",
      "models/model_epoch74.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4537333333333333\n",
      "val_overall_loss 2.0356094827016196\n",
      "__________________\n",
      "models/model_epoch75.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4613333333333333\n",
      "val_overall_loss 2.0888309089024863\n",
      "__________________\n",
      "models/model_epoch76.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4766666666666667\n",
      "val_overall_loss 1.9291856760660808\n",
      "__________________\n",
      "models/model_epoch77.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4673333333333333\n",
      "val_overall_loss 1.9902350699106852\n",
      "__________________\n",
      "models/model_epoch78.dms\n",
      "overall loss 2.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4669333333333333\n",
      "val_overall_loss 1.9848458788553873\n",
      "__________________\n",
      "models/model_epoch79.dms\n",
      "overall loss 2.12\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.472\n",
      "val_overall_loss 1.9891928248723347\n",
      "__________________\n",
      "models/model_epoch80.dms\n",
      "overall loss 1.99\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5264\n",
      "val_overall_loss 1.7149108793258667\n",
      "__________________\n",
      "models/model_epoch81.dms\n",
      "overall loss 1.98\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5298666666666667\n",
      "val_overall_loss 1.7035157853126526\n",
      "__________________\n",
      "models/model_epoch82.dms\n",
      "overall loss 1.97\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5296\n",
      "val_overall_loss 1.7049301193237305\n",
      "__________________\n",
      "models/model_epoch83.dms\n",
      "overall loss 1.97\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5288\n",
      "val_overall_loss 1.7083673553466796\n",
      "__________________\n",
      "models/model_epoch84.dms\n",
      "overall loss 1.96\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5277333333333334\n",
      "val_overall_loss 1.7071606753667197\n",
      "__________________\n",
      "models/model_epoch85.dms\n",
      "overall loss 1.96\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5286666666666666\n",
      "val_overall_loss 1.6981584409077963\n",
      "__________________\n",
      "models/model_epoch86.dms\n",
      "overall loss 1.96\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5313333333333333\n",
      "val_overall_loss 1.7002023403803508\n",
      "__________________\n",
      "models/model_epoch87.dms\n",
      "overall loss 1.96\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5310666666666667\n",
      "val_overall_loss 1.7056805705388387\n",
      "__________________\n",
      "models/model_epoch88.dms\n",
      "overall loss 1.96\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5338666666666667\n",
      "val_overall_loss 1.6875530363082887\n",
      "__________________\n",
      "models/model_epoch89.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.53\n",
      "val_overall_loss 1.6960647724787394\n",
      "__________________\n",
      "models/model_epoch90.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5313333333333333\n",
      "val_overall_loss 1.698426823679606\n",
      "__________________\n",
      "models/model_epoch91.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.53\n",
      "val_overall_loss 1.7068277913411458\n",
      "__________________\n",
      "models/model_epoch92.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5325333333333333\n",
      "val_overall_loss 1.6963737303415933\n",
      "__________________\n",
      "models/model_epoch93.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5337333333333333\n",
      "val_overall_loss 1.6927552546183269\n",
      "__________________\n",
      "models/model_epoch94.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5328\n",
      "val_overall_loss 1.69403529103597\n",
      "__________________\n",
      "models/model_epoch95.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5286666666666666\n",
      "val_overall_loss 1.7075073694229126\n",
      "__________________\n",
      "models/model_epoch96.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5318666666666667\n",
      "val_overall_loss 1.7017514722188314\n",
      "__________________\n",
      "models/model_epoch97.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5305333333333333\n",
      "val_overall_loss 1.704634360186259\n",
      "__________________\n",
      "models/model_epoch98.dms\n",
      "overall loss 1.95\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5305333333333333\n",
      "val_overall_loss 1.6905249598821004\n",
      "__________________\n",
      "models/model_epoch99.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5305333333333333\n",
      "val_overall_loss 1.714916693687439\n",
      "__________________\n",
      "models/model_epoch100.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5337333333333333\n",
      "val_overall_loss 1.694502595392863\n",
      "__________________\n",
      "models/model_epoch101.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.536\n",
      "val_overall_loss 1.7008091638247171\n",
      "__________________\n",
      "models/model_epoch102.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.532\n",
      "val_overall_loss 1.6999047410964965\n",
      "__________________\n",
      "models/model_epoch103.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5342666666666667\n",
      "val_overall_loss 1.691867974026998\n",
      "__________________\n",
      "models/model_epoch104.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5361333333333334\n",
      "val_overall_loss 1.6885376909891765\n",
      "__________________\n",
      "models/model_epoch105.dms\n",
      "overall loss 1.92\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5338666666666667\n",
      "val_overall_loss 1.6794766882578531\n",
      "__________________\n",
      "models/model_epoch106.dms\n",
      "overall loss 1.92\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5361333333333334\n",
      "val_overall_loss 1.6832455104827881\n",
      "__________________\n",
      "models/model_epoch107.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5356\n",
      "val_overall_loss 1.6846103947321573\n",
      "__________________\n",
      "models/model_epoch108.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5374666666666666\n",
      "val_overall_loss 1.6811563166300456\n",
      "__________________\n",
      "models/model_epoch109.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5373333333333333\n",
      "val_overall_loss 1.684902869796753\n",
      "__________________\n",
      "models/model_epoch110.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5377333333333333\n",
      "val_overall_loss 1.6804323600769042\n",
      "__________________\n",
      "models/model_epoch111.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5386666666666666\n",
      "val_overall_loss 1.676629458618164\n",
      "__________________\n",
      "models/model_epoch112.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5386666666666666\n",
      "val_overall_loss 1.677681189918518\n",
      "__________________\n",
      "models/model_epoch113.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5384\n",
      "val_overall_loss 1.678600338013967\n",
      "__________________\n",
      "models/model_epoch114.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5357333333333333\n",
      "val_overall_loss 1.6790926066716512\n",
      "__________________\n",
      "models/model_epoch115.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5394666666666666\n",
      "val_overall_loss 1.679781992594401\n",
      "__________________\n",
      "models/model_epoch116.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5373333333333333\n",
      "val_overall_loss 1.6821900924682618\n",
      "__________________\n",
      "models/model_epoch117.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5373333333333333\n",
      "val_overall_loss 1.6833624937057494\n",
      "__________________\n",
      "models/model_epoch118.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5377333333333333\n",
      "val_overall_loss 1.6806170700073242\n",
      "__________________\n",
      "models/model_epoch119.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5381333333333334\n",
      "val_overall_loss 1.6809393134435018\n",
      "__________________\n",
      "models/model_epoch120.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5372\n",
      "val_overall_loss 1.6803159532864889\n",
      "__________________\n",
      "models/model_epoch121.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5386666666666666\n",
      "val_overall_loss 1.6810269475301107\n",
      "__________________\n",
      "models/model_epoch122.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5382666666666667\n",
      "val_overall_loss 1.67718959051768\n",
      "__________________\n",
      "models/model_epoch123.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5384\n",
      "val_overall_loss 1.680389327430725\n",
      "__________________\n",
      "models/model_epoch124.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.5406666666666666\n",
      "val_overall_loss 1.6781138783772787\n",
      "__________________\n",
      "models/model_epoch125.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5369333333333334\n",
      "val_overall_loss 1.6795386596043904\n",
      "__________________\n",
      "models/model_epoch126.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5378666666666667\n",
      "val_overall_loss 1.6825784302393596\n",
      "__________________\n",
      "models/model_epoch127.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5370666666666667\n",
      "val_overall_loss 1.6823544362386067\n",
      "__________________\n",
      "models/model_epoch128.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5365333333333333\n",
      "val_overall_loss 1.6803449501037597\n",
      "__________________\n",
      "models/model_epoch129.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5368\n",
      "val_overall_loss 1.6779805576960245\n",
      "__________________\n",
      "models/model_epoch130.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.538\n",
      "val_overall_loss 1.6825903296788534\n",
      "__________________\n",
      "models/model_epoch131.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5381333333333334\n",
      "val_overall_loss 1.6799733479181926\n",
      "__________________\n",
      "models/model_epoch132.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5357333333333333\n",
      "val_overall_loss 1.6806649099985758\n",
      "__________________\n",
      "models/model_epoch133.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5384\n",
      "val_overall_loss 1.6793890754699707\n",
      "__________________\n",
      "models/model_epoch134.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5393333333333333\n",
      "val_overall_loss 1.6792623666127522\n",
      "__________________\n",
      "models/model_epoch135.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5365333333333333\n",
      "val_overall_loss 1.6818435028711956\n",
      "__________________\n",
      "models/model_epoch136.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5357333333333333\n",
      "val_overall_loss 1.684055135091146\n",
      "__________________\n",
      "models/model_epoch137.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5388\n",
      "val_overall_loss 1.6780184905370077\n",
      "__________________\n",
      "models/model_epoch138.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5368\n",
      "val_overall_loss 1.6793886092503865\n",
      "__________________\n",
      "models/model_epoch139.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.5374666666666666\n",
      "val_overall_loss 1.6830321517308553\n",
      "__________________\n",
      "models/model_epoch140.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5370666666666667\n",
      "val_overall_loss 1.6812893042882284\n",
      "__________________\n",
      "models/model_epoch141.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.538\n",
      "val_overall_loss 1.684859451421102\n",
      "__________________\n",
      "models/model_epoch142.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5381333333333334\n",
      "val_overall_loss 1.6806760884602865\n",
      "__________________\n",
      "models/model_epoch143.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5370666666666667\n",
      "val_overall_loss 1.678747787284851\n",
      "__________________\n",
      "models/model_epoch144.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5392\n",
      "val_overall_loss 1.6784133907953898\n",
      "__________________\n",
      "models/model_epoch145.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5402666666666667\n",
      "val_overall_loss 1.679733315785726\n",
      "__________________\n",
      "models/model_epoch146.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5404\n",
      "val_overall_loss 1.6796142725626628\n",
      "__________________\n",
      "models/model_epoch147.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5401333333333334\n",
      "val_overall_loss 1.6795259731292724\n",
      "__________________\n",
      "models/model_epoch148.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5382666666666667\n",
      "val_overall_loss 1.6807301217397055\n",
      "__________________\n",
      "models/model_epoch149.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.5402666666666667\n",
      "val_overall_loss 1.6796760014851888\n",
      "__________________\n",
      "choosen epoch: 124 , score: 0.5406666666666666\n",
      "best epoch: 124 , score: 0.5406666666666666\n",
      "-----------------\n",
      "*****************\n",
      "_l2.pt\n",
      "test_accuracy 0.5318\n",
      "test_overall_loss 1.679247689628601\n",
      "__________________\n",
      "val_accuracy 0.5406666666666666\n",
      "val_overall_loss 1.678113877105713\n",
      "__________________\n",
      "train_accuracy 0.5778823529411765\n",
      "train_overall_loss 1.4330436378030216\n",
      "__________________\n",
      "----------------\n",
      "test_accuracy 0.6697\n",
      "test_overall_loss 1.2315242038726806\n",
      "__________________\n",
      "val_accuracy 0.6758666666666666\n",
      "val_overall_loss 1.2068180729548137\n",
      "__________________\n",
      "train_accuracy 0.8110823529411765\n",
      "train_overall_loss 0.6240220233917236\n",
      "__________________\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  for net_teacher, net_student, teacher_name, student_name in [\n",
    "                    # (resnet20(), resnet7(), \"resnet20_classic.pt\", \"resnet7_distillation_resnet20_a09.pt\"), \n",
    "                    # (resnet32(), resnet7(), \"resnet32_classic.pt\", \"resnet7_distillation_resnet32_a09.pt\"), \n",
    "                    # (resnet56(), resnet7(), \"resnet56_classic.pt\", \"resnet7_distillation_resnet56_a1ca1.pt\"), \n",
    "                    (resnet20(), resnet7(), \"resnet20_classic.pt\", \"resnet7\"), \n",
    "                    # (resnet32(), resnet7(), \"resnet32_classic.pt\", \"resnet7_distillation_resnet32_.pt\"), \n",
    "                    # (resnet20(), resnet7(), \"resnet20_classic.pt\", \"resnet7_distillation_resnet20.pt\"), \n",
    "                    # (resnet32(), resnet7(), \"resnet32_classic.pt\", \"resnet7_distillation_resnet32.pt\"), \n",
    "                    # (resnet7(), resnet7(), \"resnet7_classic.pt\", \"resnet7_distillation_resnet7.pt\"), \n",
    "                    # (resnet44(), resnet7(), \"resnet44_classic.pt\", \"resnet7_distillation_resnet44.pt\"), \n",
    "                    # (resnet56(), resnet7(), \"resnet56_classic.pt\", \"resnet7_distillation_resnet56.pt\"), \n",
    "                    # (resnet44(), \"resnet44_classic.pt\"), \n",
    "                    # (resnet56(), \"resnet56_classic.pt\")\n",
    "                    ]:\n",
    "\n",
    "    epochs = 150\n",
    "    download_model(teacher_name, teacher_name)\n",
    "    state_dict_teacher = torch.load(teacher_name)\n",
    "    net_teacher.cuda().load_state_dict(state_dict_teacher)\n",
    "    loader_cached = cache_loader(net_teacher, trainloader)\n",
    "\n",
    "\n",
    "    experiment_name = student_name[8:-3]+\"_l2.pt\"\n",
    "    logger = TensorBoardLogger(\"logs\", dataset_name, student_name, experiment_name)\n",
    "    net_student = train_distillation_cached(\n",
    "                               net_student,\n",
    "                              loader_cached,\n",
    "                              valloader,\n",
    "                              epoches=epochs, \n",
    "                              init_lr=1e-1, \n",
    "                              logger=logger,\n",
    "                              return_best=True,\n",
    "                              cos_alpha=0.0,\n",
    "                              l_alpha=1.0,\n",
    "                              p=2,\n",
    "                              wd=1e-4,\n",
    "                              temperature=1\n",
    "                              )\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"*****************\")\n",
    "    print(experiment_name)\n",
    "    score_test = validate(net_student, testloader, prename='test')\n",
    "    score_val = validate(net_student, valloader, prename='val')\n",
    "    validate(net_student, trainloader, prename='train')\n",
    "\n",
    "    print(\"----------------\")\n",
    "    score_teacher_test = validate(net_teacher, testloader, prename='test')\n",
    "    score_teacher_val = validate(net_teacher, valloader, prename='val')\n",
    "    validate(net_teacher, trainloader, prename='train')\n",
    "    print(\"----------------\")\n",
    "\n",
    "    hparams = {\"experiment_name\":experiment_name, \"teacher\":teacher_name, \"dataset\":dataset_name}\n",
    "    for key, value in score_val.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_test.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    \n",
    "    for key, value in score_teacher_test.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_val.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "\n",
    "    logger.log_hparams(hparams) \n",
    "\n",
    "    torch.save(net_student.state_dict(), experiment_name)\n",
    "    # upload_model(experiment_name, experiment_name)\n",
    "\n",
    "    saving_path_template = \"models/model_epoch%s.dms\"\n",
    "    logger.step_=0\n",
    "    # for i in range(epochs):\n",
    "    #     state_dict_student = torch.load(saving_path_template%i)\n",
    "    #     net_student.cuda().load_state_dict(state_dict_student)\n",
    "    #     score_test = validate(net_student, testloader, prename='test', verbose=False)\n",
    "    #     score_val = validate(net_student, valloader, prename='val', verbose=False)\n",
    "    #     logger.log_scalar(\"accuracy/test\", score_test['test_accuracy'])\n",
    "    #     logger.log_scalar(\"accuracy/val\", score_val['val_accuracy'])\n",
    "    #     logger.step()\n",
    "    # upload_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEeojwlpF2px"
   },
   "outputs": [],
   "source": [
    "upload_logs()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hyp_cached_cifar100_distillation_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "072aa660c2e04479ac07bd1f46f66772": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47b5582999514e62a7405e20b5caf93d",
       "IPY_MODEL_f965c0bd04b649e78dfb8aa87efffee4"
      ],
      "layout": "IPY_MODEL_69ca822651aa4a72a61d451781003804"
     }
    },
    "151037d5e3044a909047f2f127f5d00a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47b5582999514e62a7405e20b5caf93d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_151037d5e3044a909047f2f127f5d00a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b26b6eee38f54c42addb108d3e32f275",
      "value": 1
     }
    },
    "69ca822651aa4a72a61d451781003804": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5dd88059b3b4b61bd78cb5dc449e9ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac7640b6c9a74a988262a366a3f80344": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b26b6eee38f54c42addb108d3e32f275": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f965c0bd04b649e78dfb8aa87efffee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5dd88059b3b4b61bd78cb5dc449e9ee",
      "placeholder": "​",
      "style": "IPY_MODEL_ac7640b6c9a74a988262a366a3f80344",
      "value": "169009152it [00:03, 42837639.69it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
