{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template for downloading/uploading. Because I used not cloud PC for cifar100 experiments, it has only 'pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "lLar-Or9BtDy",
    "outputId": "c5767d4a-6103-4dd4-8a82-b5b30d696d7e"
   },
   "outputs": [],
   "source": [
    "def download_model(source_name, saving_name):\n",
    "    pass\n",
    "\n",
    "def upload_model(source_name, saving_name):\n",
    "    pass\n",
    "\n",
    "def upload_logs():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libs importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDHAyQCTB0m7"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from resnet import resnet20, BasicBlock, _weights_init, resnet32, resnet56, resnet44, ResNet\n",
    "\n",
    "def resnet7():return ResNet(BasicBlock, [1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ungAuzjewjA-"
   },
   "outputs": [],
   "source": [
    "class ResNetModified(nn.Module):\n",
    "    def __init__(self, block, num_blocks, input_channels, num_classes=10):\n",
    "        super(ResNetModified, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def resnet7():return ResNetModified(BasicBlock, [1, 1, 1], 3, 100)\n",
    "def resnet20():return ResNetModified(BasicBlock, [3, 3, 3], 3, 100)\n",
    "def resnet32():return ResNetModified(BasicBlock, [5, 5, 5], 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration of utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiMNJcDPB2lJ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "  \"\"\"Class for computing average values\n",
    "  \"\"\"    \n",
    "  def __init__(self):\n",
    "    \"\"\"Init class\n",
    "    \"\"\"      \n",
    "    self.sum_ = 0\n",
    "    self.count = 0\n",
    "  \n",
    "  def update(self, val, count=1):\n",
    "    \"\"\"Add new value to track\n",
    "    \n",
    "    Arguments:\n",
    "        val {float} -- new value\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        count {int} -- weigth of val (default: {1})\n",
    "    \"\"\"      \n",
    "    self.sum_ += val\n",
    "    self.count += count\n",
    "\n",
    "  def average(self):\n",
    "    \"\"\"return average value for given values\n",
    "    \"\"\"      \n",
    "    return self.sum_ / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2rud3U0B5Pu"
   },
   "outputs": [],
   "source": [
    "class TensorBoardLogger:\n",
    "    \"\"\"Class for logging into TensorBoard\n",
    "    \"\"\"    \n",
    "    def __init__(self, log_dir, dataset, net, experiment_name):\n",
    "        \"\"\"Init logger\n",
    "        \n",
    "        Arguments:\n",
    "            log_dir {string} -- log dir\n",
    "            dataset {string} -- name of dataset\n",
    "            experiment_name {string} -- name of experiment\n",
    "        \"\"\"        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        log_dir_full = os.path.join(log_dir, dataset, net, experiment_name, current_time)\n",
    "        self.writer = tf.summary.create_file_writer(log_dir_full)\n",
    "        self.step_ = 0\n",
    "        \n",
    "    def log_scalar(self, tag, value, step=None, description=None):\n",
    "        \"\"\"Log scalar\n",
    "        \n",
    "        Arguments:\n",
    "            tag {string} -- name of variable to log\n",
    "            value {float} -- value of variable\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            step {int} -- current epoch number (default: {None})\n",
    "            description {string} -- [description] (default: {None})\n",
    "        \"\"\"        \n",
    "        if step is None:\n",
    "            step = self.step_\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(tag, value, step=step, description=description)\n",
    "            \n",
    "    def step(self):\n",
    "        \"\"\"Increase epoch number by 1\n",
    "        \"\"\"        \n",
    "        self.step_+=1\n",
    "\n",
    "    def log_hparams(self, hparams):\n",
    "        \"\"\"log hparams\n",
    "        \n",
    "        Arguments:\n",
    "            hparams {dict} -- dict to log\n",
    "        \"\"\"      \n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(hparams)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewF2eWCOB7Pr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset_name = \"cifar100_aug_cached\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZyKuu77MVcV"
   },
   "outputs": [],
   "source": [
    "# function for dataset\n",
    "def collate_fn(batch):\n",
    "  imgs = [i[0] for i in batch]\n",
    "  labels = [i[1] for i in batch]\n",
    "  return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "60fcdf474b22473b8e2338389826e794",
      "2940fc7f5b6442fdb4a1ea28e0ff786e",
      "0bc6f6b5e71d4ef2807d75b244d37861",
      "26dd588cfea8434591857828fe74f9ae",
      "6770bbe3c6134818af5f631ac7fe9c2c",
      "bed89e6622ee4040b097183259b7bb9e",
      "6646590a3af34633a99ec1ee16b6ac6a",
      "2a4db87f32904f4c9b6ce9b34d2c7d1f"
     ]
    },
    "colab_type": "code",
    "id": "ph7_tHYAB9cN",
    "outputId": "7da05bd2-44fe-4bdd-bad4-8e8f2ac83892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# augmentation and normaliztion for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "# only normalization for testing\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, \n",
    "                                        # transform=transform_train\n",
    "                                        )\n",
    "valset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True,\n",
    "                                      #  transform=transform_test\n",
    "                                      )\n",
    "# split trainvalset into val and train\n",
    "idx = np.arange(len(trainset))\n",
    "split = int(len(trainset)*0.15)\n",
    "np.random.seed(42) # set seed to reproduce given set\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[split:]\n",
    "val_idx = idx[:split]\n",
    "\n",
    "trainset = Subset(trainset, train_idx)\n",
    "valset = Subset(valset, val_idx)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn,\n",
    "                                          )\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn,\n",
    "                                          )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                      #  transform=transform_test\n",
    "                                       )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                         pin_memory=True, \n",
    "                                         collate_fn=collate_fn,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show dataset images\n",
    "for k, i in enumerate(trainset, 1):\n",
    "  plt.subplot(1, 5, k)\n",
    "  plt.imshow(i[0])\n",
    "  \n",
    "  if k==5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApgwwyiYB_Oy"
   },
   "outputs": [],
   "source": [
    "# check the first index, to check that trainval set splitted correctly\n",
    "assert val_idx[0]==33553, \"invalid val set\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slWmMP1LCC9b"
   },
   "outputs": [],
   "source": [
    "def accuracy_minibatch(outputs, labels):\n",
    "  \"\"\"Compute accuracy for batch\n",
    "  \n",
    "  Arguments:\n",
    "      outputs {list or np.array or torch.Tensor} -- outputs from model (vectors of probabilities)\n",
    "      labels {list or np.array or torch.Tensor} -- labels (one number for each sample)\n",
    "  \n",
    "  Returns:\n",
    "      float -- accuracy for minibatch\n",
    "  \"\"\"  \n",
    "  if isinstance(outputs, torch.Tensor):\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "  if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "  \n",
    "  predict_= np.argmax(outputs, axis=1)\n",
    "  true_labels_= labels\n",
    "  micro_acc_score = accuracy_score(predict_, true_labels_)\n",
    "  return micro_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07DXQHlXCEa_"
   },
   "outputs": [],
   "source": [
    "def validate(net, testloader, logger=None, verbose=True, prename=\"val\",\n",
    "             cuda=True,\n",
    "             transform_tensor=transform_test,\n",
    "             transform_repeats=1\n",
    "             ):\n",
    "  \"\"\"Function for compute metrics on validation set\n",
    "  \n",
    "  Arguments:\n",
    "      net {torch net} -- model\n",
    "      testloader {DataLoader} -- set to validation\n",
    "      \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      prename {string} -- prename to name of metric (default: {\"val\"})\n",
    "      cuda {bool} -- use cuda or not (default: {True})\n",
    "      transform_tensor {[type]} -- transformation for image (default: {transform_test})\n",
    "      transform_repeats {int} -- amount of repeats (default: {1})\n",
    "  \n",
    "  Returns:\n",
    "      [dict] -- scores for computing metrics\n",
    "  \"\"\"  \n",
    "  # change net to evaluation mode\n",
    "  net.eval()\n",
    "  ce_loss_avg = AverageMeter()\n",
    "  accuracy_score_avg = AverageMeter()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  # evaluate dataset\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs]) for i in range(transform_repeats)]\n",
    "\n",
    "    current_batch_size = len(labels)\n",
    "\n",
    "    outputs = 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs += net(inputs_[i].cuda() if cuda else inputs_[i])\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    loss = criterion(outputs, labels).cpu().detach().numpy()\n",
    "    \n",
    "    micro_acc_score = accuracy_minibatch(outputs, labels)\n",
    "\n",
    "    accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "    ce_loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "\n",
    "  accuracy = accuracy_score_avg.average()\n",
    "  ce_loss = ce_loss_avg.average()\n",
    "  scores = {\n",
    "      \"%s_accuracy\"%prename: accuracy,\n",
    "      \"%s_overall_loss\"%prename: ce_loss,\n",
    "       }\n",
    "  \n",
    "  # log scores\n",
    "  for name, score in scores.items():\n",
    "    if logger:\n",
    "      logger.log_scalar(name, score)\n",
    "    if verbose:\n",
    "      print(name, score)\n",
    "  \n",
    "  if verbose:\n",
    "    print(\"__________________\")\n",
    "  # change net to training mode\n",
    "  net.train()\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rNl7qpSCGLk"
   },
   "outputs": [],
   "source": [
    "def train_distillation_cached(\n",
    "    net_student, \n",
    "    trainloader, \n",
    "    testloader, \n",
    "    logger=None,\n",
    "    cuda=True,\n",
    "    epoches=150,\n",
    "    verbose=True, \n",
    "    return_best=False,\n",
    "    init_lr=0.1,\n",
    "    temperature=1,\n",
    "    cos_alpha=0,\n",
    "    l_alpha=0,\n",
    "    p=2,\n",
    "    shuffle=True,\n",
    "    wd=1e-4,\n",
    "    transform_tensor=transform_train\n",
    "    ):\n",
    "  \"\"\"Training using knowledge distillation approach\n",
    "  \n",
    "  Arguments:\n",
    "      net_student {torch model} -- student model\n",
    "      trainloader {list} -- cached train set\n",
    "      testloader {DataLoader} -- test set\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      epoches {int} -- epochs to train (default: {150})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      return_best {bool} -- return best model (default: {False})\n",
    "      init_lr {float} -- initial learning rate (default: {0.1})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      cos_alpha {float} -- coefficeint of combining distillation (KL) and cosine disimilarity loss (default: {0})\n",
    "      shuffle {bool} -- shuffle dataset each epoch (default: {True})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      l_alpha {float} -- coefficeint of L^p loss in distillation loss (default: {0.0})\n",
    "      p {int} -- parametr for L^p loss (default: {2})\n",
    "  \n",
    "  Returns:\n",
    "      torch model -- best or last model\n",
    "  \"\"\"  \n",
    "  # change net to training mode\n",
    "  net_student.train()\n",
    "  net_teacher.eval()\n",
    "  # use gpu to train\n",
    "  net_student.cuda()\n",
    "\n",
    "  criterion_ce = nn.CrossEntropyLoss().cuda()\n",
    "  criterion_nll = nn.NLLLoss().cuda()\n",
    "  criterion_bce = nn.BCELoss().cuda() \n",
    "  criterion_kl = nn.KLDivLoss(reduction=\"batchmean\").cuda()\n",
    "  cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "  criterion_mse = nn.MSELoss()\n",
    "  criterion_mae = nn.L1Loss()\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "      net_student.parameters(), \n",
    "      lr=init_lr,\n",
    "      momentum=0.9,\n",
    "      weight_decay=wd\n",
    "      )\n",
    "  # optimizer = torch.optim.Adam(\n",
    "  #     net_student.parameters(), )\n",
    "  # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, threshold=0.001, patience=patience, eps=1e-5)\n",
    "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [80, 105, 125, 140])\n",
    "\n",
    "  validation_scores = []\n",
    "  os.makedirs(\"models\", exist_ok=True)\n",
    "  saving_path_template = \"models/model_epoch%s.dms\"\n",
    "\n",
    "  for epoch in range(epoches):  # loop over the dataset multiple times\n",
    "    saving_name = saving_path_template%epoch\n",
    "    \n",
    "    loss_avg = AverageMeter()\n",
    "    accuracy_score_avg = AverageMeter()\n",
    "    loss_kl_avg = AverageMeter()\n",
    "    loss_cos_dis_avg = AverageMeter()\n",
    "    loss_ce_avg = AverageMeter()\n",
    "\n",
    "    if shuffle:\n",
    "      np.random.shuffle(trainloader)\n",
    "\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_pil, out_teacher, labels = data\n",
    "        current_batch_size = len(out_teacher)\n",
    "\n",
    "        inputs = torch.stack([transform_tensor(j) for j in inputs_pil])\n",
    "        inputs, out_teacher = inputs.cuda(), out_teacher.cuda()\n",
    "\n",
    "        if cuda:\n",
    "          inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out_student = net_student(inputs)\n",
    "        soft_log_probs = F.log_softmax(out_student / temperature, dim=1)\n",
    "        soft_output = F.softmax(out_student / temperature, dim=1)\n",
    "        soft_targets = out_teacher#F.softmax(out_teacher / temperature, dim=1)\n",
    "        \n",
    "        kl_loss = criterion_kl(soft_log_probs, soft_targets.detach())\n",
    "        cos_dis_loss =  (1 - cosine_similarity(out_student - torch.mean(out_student, dim=1, keepdim=True), out_teacher.detach() - torch.mean(out_teacher.detach(), dim=1, keepdim=True))).mean()\n",
    "        \n",
    "        l_loss = (torch.abs(out_student - out_teacher)**p).mean()**(1/p)\n",
    "\n",
    "        loss = (1 - cos_alpha - l_alpha) * kl_loss + cos_alpha * cos_dis_loss + l_alpha * l_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        micro_acc_score = accuracy_minibatch(out_student, labels)\n",
    "\n",
    "        loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "        accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "        loss_kl_avg.update(kl_loss.item()*current_batch_size, current_batch_size)\n",
    "        loss_cos_dis_avg.update(cos_dis_loss.item()*current_batch_size, current_batch_size)\n",
    "        # loss_ce_avg.update(loss_ce.item()*current_batch_size, current_batch_size)\n",
    "        \n",
    "    if verbose:\n",
    "        print(saving_name)\n",
    "        print('overall loss {:.3}'.format(loss_avg.average()))\n",
    "        print('current lr {:.3e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        print(\"__________________\")\n",
    "    # clear memory \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    # save scores to take best model in the future\n",
    "    validation_score = validate(net_student, valloader, \n",
    "                                logger=logger, \n",
    "                                verbose=verbose, \n",
    "                                )\n",
    "    accuracy = validation_score['val_accuracy']\n",
    "    validation_scores.append(accuracy)\n",
    "    # save model\n",
    "    torch.save(net_student.state_dict(), saving_name)\n",
    "\n",
    "    if logger:\n",
    "        logger.log_scalar(\"overall_loss\", loss_avg.average())\n",
    "        logger.log_scalar(\"accuracy\", accuracy_score_avg.average())\n",
    "        logger.log_scalar(\"kl_loss\", loss_kl_avg.average())\n",
    "        logger.log_scalar(\"cos_dis_loss\", loss_cos_dis_avg.average())\n",
    "        logger.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "  best_epoch = np.argmax(validation_scores)\n",
    "  if return_best:\n",
    "    choosen_epoch = best_epoch\n",
    "  else:\n",
    "    choosen_epoch = epoch\n",
    "  if verbose:\n",
    "    print(\"choosen epoch:\", choosen_epoch, \", score:\", validation_scores[choosen_epoch])\n",
    "    print(\"best epoch:\", best_epoch, \", score:\", validation_scores[best_epoch])\n",
    "  model_name = saving_path_template%choosen_epoch\n",
    "  net_student.load_state_dict(torch.load(model_name))\n",
    "  return net_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4ttxWfsmRcT"
   },
   "outputs": [],
   "source": [
    "def cache_loader(net_teacher, loader, cuda=True,\n",
    "                 transform_tensor=transform_train,\n",
    "                 transform_repeats=4\n",
    "                 ):\n",
    "  \"\"\"Cache loader, to prevent computing teacher model output\n",
    "  \n",
    "  Arguments:\n",
    "      net_teacher {torch model} -- teacher model\n",
    "      loader {DataLoader} -- dataset to cache\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      cuda {bool} -- use cuda or not(default: {True})\n",
    "      transform_tensor {func} -- image transformation (default: {transform_train})\n",
    "      transform_repeats {int} -- amount of repeats (default: {int})\n",
    "  \n",
    "  Returns:\n",
    "      List -- List of (inputs, teacher model outputs)\n",
    "  \"\"\"  \n",
    "  net_teacher.eval()\n",
    "  cached = []\n",
    "  for inputs_pil, labels in loader:\n",
    "    labels = torch.tensor(labels)\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs_pil]) for i in range(transform_repeats)]\n",
    "\n",
    "    outputs = 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs += F.softmax(net_teacher(inputs_[i].cuda() if cuda else inputs_[i]),dim=1)\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    cached.append([inputs_pil, outputs.cpu().detach(), labels.cpu().detach()])\n",
    "\n",
    "  return cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5m2TCqj52idV"
   },
   "outputs": [],
   "source": [
    "def validate_loader(loader):\n",
    "  accuracy_score_avg = AverageMeter()\n",
    "  for data in loader:\n",
    "    inputs_pil, out_teacher, labels = data\n",
    "\n",
    "    current_batch_size = len(labels)\n",
    "\n",
    "    micro_acc_score = accuracy_minibatch(out_teacher, labels)\n",
    "\n",
    "    accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "  print(accuracy_score_avg.average())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKPRopTGzt0C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch0.dms\n",
      "overall loss 2.93\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.13146666666666668\n",
      "val_overall_loss 3.686241738510132\n",
      "__________________\n",
      "models/model_epoch1.dms\n",
      "overall loss 2.26\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.188\n",
      "val_overall_loss 3.480246533584595\n",
      "__________________\n",
      "models/model_epoch2.dms\n",
      "overall loss 1.89\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.2596\n",
      "val_overall_loss 3.0644939549764\n",
      "__________________\n",
      "models/model_epoch3.dms\n",
      "overall loss 1.66\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.32053333333333334\n",
      "val_overall_loss 2.6408280564626057\n",
      "__________________\n",
      "models/model_epoch4.dms\n",
      "overall loss 1.5\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.3430666666666667\n",
      "val_overall_loss 2.7194862674713134\n",
      "__________________\n",
      "models/model_epoch5.dms\n",
      "overall loss 1.39\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.36093333333333333\n",
      "val_overall_loss 2.6138981811523436\n",
      "__________________\n",
      "models/model_epoch6.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.35746666666666665\n",
      "val_overall_loss 2.712812218221029\n",
      "__________________\n",
      "models/model_epoch7.dms\n",
      "overall loss 1.23\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.422\n",
      "val_overall_loss 2.236125768661499\n",
      "__________________\n",
      "models/model_epoch8.dms\n",
      "overall loss 1.17\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.39866666666666667\n",
      "val_overall_loss 2.3829593819300334\n",
      "__________________\n",
      "models/model_epoch9.dms\n",
      "overall loss 1.13\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4189333333333333\n",
      "val_overall_loss 2.2191313908894856\n",
      "__________________\n",
      "models/model_epoch10.dms\n",
      "overall loss 1.1\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.42773333333333335\n",
      "val_overall_loss 2.2333034318288165\n",
      "__________________\n",
      "models/model_epoch11.dms\n",
      "overall loss 1.06\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44253333333333333\n",
      "val_overall_loss 2.127769529469808\n",
      "__________________\n",
      "models/model_epoch12.dms\n",
      "overall loss 1.04\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4441333333333333\n",
      "val_overall_loss 2.1339015263875325\n",
      "__________________\n",
      "models/model_epoch13.dms\n",
      "overall loss 1.01\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4534666666666667\n",
      "val_overall_loss 2.100670695368449\n",
      "__________________\n",
      "models/model_epoch14.dms\n",
      "overall loss 0.993\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4652\n",
      "val_overall_loss 2.0427878841400147\n",
      "__________________\n",
      "models/model_epoch15.dms\n",
      "overall loss 0.978\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4609333333333333\n",
      "val_overall_loss 2.0538215816497805\n",
      "__________________\n",
      "models/model_epoch16.dms\n",
      "overall loss 0.961\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4550666666666667\n",
      "val_overall_loss 2.1182900027592977\n",
      "__________________\n",
      "models/model_epoch17.dms\n",
      "overall loss 0.947\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46\n",
      "val_overall_loss 2.129372072283427\n",
      "__________________\n",
      "models/model_epoch18.dms\n",
      "overall loss 0.936\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47013333333333335\n",
      "val_overall_loss 2.0440586343765257\n",
      "__________________\n",
      "models/model_epoch19.dms\n",
      "overall loss 0.923\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4688\n",
      "val_overall_loss 2.0937828437805175\n",
      "__________________\n",
      "models/model_epoch20.dms\n",
      "overall loss 0.909\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46653333333333336\n",
      "val_overall_loss 2.021036727523804\n",
      "__________________\n",
      "models/model_epoch21.dms\n",
      "overall loss 0.899\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4809333333333333\n",
      "val_overall_loss 1.9450989699045818\n",
      "__________________\n",
      "models/model_epoch22.dms\n",
      "overall loss 0.896\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48133333333333334\n",
      "val_overall_loss 1.9761970534006754\n",
      "__________________\n",
      "models/model_epoch23.dms\n",
      "overall loss 0.889\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4844\n",
      "val_overall_loss 1.941296323521932\n",
      "__________________\n",
      "models/model_epoch24.dms\n",
      "overall loss 0.884\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.46853333333333336\n",
      "val_overall_loss 2.068229305140177\n",
      "__________________\n",
      "models/model_epoch25.dms\n",
      "overall loss 0.874\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5028\n",
      "val_overall_loss 1.885660198020935\n",
      "__________________\n",
      "models/model_epoch26.dms\n",
      "overall loss 0.868\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4592\n",
      "val_overall_loss 2.0833714188893637\n",
      "__________________\n",
      "models/model_epoch27.dms\n",
      "overall loss 0.866\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.464\n",
      "val_overall_loss 2.04372157942454\n",
      "__________________\n",
      "models/model_epoch28.dms\n",
      "overall loss 0.852\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.496\n",
      "val_overall_loss 1.9031782204945882\n",
      "__________________\n",
      "models/model_epoch29.dms\n",
      "overall loss 0.854\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5016\n",
      "val_overall_loss 1.9063751977284749\n",
      "__________________\n",
      "models/model_epoch30.dms\n",
      "overall loss 0.849\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47733333333333333\n",
      "val_overall_loss 2.05000383866628\n",
      "__________________\n",
      "models/model_epoch31.dms\n",
      "overall loss 0.847\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5004\n",
      "val_overall_loss 1.9076223998387654\n",
      "__________________\n",
      "models/model_epoch32.dms\n",
      "overall loss 0.834\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4688\n",
      "val_overall_loss 2.131746025466919\n",
      "__________________\n",
      "models/model_epoch33.dms\n",
      "overall loss 0.838\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5050666666666667\n",
      "val_overall_loss 1.8892010551452636\n",
      "__________________\n",
      "models/model_epoch34.dms\n",
      "overall loss 0.84\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.45066666666666666\n",
      "val_overall_loss 2.172347640101115\n",
      "__________________\n",
      "models/model_epoch35.dms\n",
      "overall loss 0.833\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4364\n",
      "val_overall_loss 2.375443646621704\n",
      "__________________\n",
      "models/model_epoch36.dms\n",
      "overall loss 0.825\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5101333333333333\n",
      "val_overall_loss 1.863027087465922\n",
      "__________________\n",
      "models/model_epoch37.dms\n",
      "overall loss 0.824\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4942666666666667\n",
      "val_overall_loss 1.9059058113733927\n",
      "__________________\n",
      "models/model_epoch38.dms\n",
      "overall loss 0.824\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49306666666666665\n",
      "val_overall_loss 1.9428307909647624\n",
      "__________________\n",
      "models/model_epoch39.dms\n",
      "overall loss 0.816\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49466666666666664\n",
      "val_overall_loss 1.9660031775156657\n",
      "__________________\n",
      "models/model_epoch40.dms\n",
      "overall loss 0.818\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4912\n",
      "val_overall_loss 1.9767109802246094\n",
      "__________________\n",
      "models/model_epoch41.dms\n",
      "overall loss 0.813\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.504\n",
      "val_overall_loss 1.9091607748031616\n",
      "__________________\n",
      "models/model_epoch42.dms\n",
      "overall loss 0.811\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4749333333333333\n",
      "val_overall_loss 2.0544324696858722\n",
      "__________________\n",
      "models/model_epoch43.dms\n",
      "overall loss 0.809\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.44253333333333333\n",
      "val_overall_loss 2.224507238260905\n",
      "__________________\n",
      "models/model_epoch44.dms\n",
      "overall loss 0.806\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47933333333333333\n",
      "val_overall_loss 2.034769949467977\n",
      "__________________\n",
      "models/model_epoch45.dms\n",
      "overall loss 0.803\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.496\n",
      "val_overall_loss 1.9017178407033284\n",
      "__________________\n",
      "models/model_epoch46.dms\n",
      "overall loss 0.802\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49493333333333334\n",
      "val_overall_loss 1.923799968401591\n",
      "__________________\n",
      "models/model_epoch47.dms\n",
      "overall loss 0.798\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4673333333333333\n",
      "val_overall_loss 2.057554947980245\n",
      "__________________\n",
      "models/model_epoch48.dms\n",
      "overall loss 0.803\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4885333333333333\n",
      "val_overall_loss 1.9850089660644532\n",
      "__________________\n",
      "models/model_epoch49.dms\n",
      "overall loss 0.8\n",
      "current lr 1.000e-01\n",
      "__________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_accuracy 0.49173333333333336\n",
      "val_overall_loss 1.9752811030069988\n",
      "__________________\n",
      "models/model_epoch50.dms\n",
      "overall loss 0.793\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5081333333333333\n",
      "val_overall_loss 1.8645990374247232\n",
      "__________________\n",
      "models/model_epoch51.dms\n",
      "overall loss 0.795\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5058666666666667\n",
      "val_overall_loss 1.9029313154856364\n",
      "__________________\n",
      "models/model_epoch52.dms\n",
      "overall loss 0.797\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4573333333333333\n",
      "val_overall_loss 2.2536935240427654\n",
      "__________________\n",
      "models/model_epoch53.dms\n",
      "overall loss 0.788\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5158666666666667\n",
      "val_overall_loss 1.8235832098007203\n",
      "__________________\n",
      "models/model_epoch54.dms\n",
      "overall loss 0.788\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4898666666666667\n",
      "val_overall_loss 1.9756272556304932\n",
      "__________________\n",
      "models/model_epoch55.dms\n",
      "overall loss 0.79\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48973333333333335\n",
      "val_overall_loss 1.8900769229888916\n",
      "__________________\n",
      "models/model_epoch56.dms\n",
      "overall loss 0.786\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49893333333333334\n",
      "val_overall_loss 1.8895338417053222\n",
      "__________________\n",
      "models/model_epoch57.dms\n",
      "overall loss 0.79\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4736\n",
      "val_overall_loss 2.1127030803680418\n",
      "__________________\n",
      "models/model_epoch58.dms\n",
      "overall loss 0.778\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.47426666666666667\n",
      "val_overall_loss 2.0414290856679282\n",
      "__________________\n",
      "models/model_epoch59.dms\n",
      "overall loss 0.785\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49573333333333336\n",
      "val_overall_loss 1.923228976313273\n",
      "__________________\n",
      "models/model_epoch60.dms\n",
      "overall loss 0.785\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49293333333333333\n",
      "val_overall_loss 1.9427922958374024\n",
      "__________________\n",
      "models/model_epoch61.dms\n",
      "overall loss 0.776\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4862666666666667\n",
      "val_overall_loss 2.0118693364461264\n",
      "__________________\n",
      "models/model_epoch62.dms\n",
      "overall loss 0.781\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5150666666666667\n",
      "val_overall_loss 1.8387115803400675\n",
      "__________________\n",
      "models/model_epoch63.dms\n",
      "overall loss 0.774\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4829333333333333\n",
      "val_overall_loss 1.9667808446248372\n",
      "__________________\n",
      "models/model_epoch64.dms\n",
      "overall loss 0.774\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48346666666666666\n",
      "val_overall_loss 1.9882446404774983\n",
      "__________________\n",
      "models/model_epoch65.dms\n",
      "overall loss 0.776\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5182666666666667\n",
      "val_overall_loss 1.8396037517547608\n",
      "__________________\n",
      "models/model_epoch66.dms\n",
      "overall loss 0.773\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5029333333333333\n",
      "val_overall_loss 1.9193049900690715\n",
      "__________________\n",
      "models/model_epoch67.dms\n",
      "overall loss 0.771\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.48506666666666665\n",
      "val_overall_loss 1.9624730148951213\n",
      "__________________\n",
      "models/model_epoch68.dms\n",
      "overall loss 0.769\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49733333333333335\n",
      "val_overall_loss 1.882138682047526\n",
      "__________________\n",
      "models/model_epoch69.dms\n",
      "overall loss 0.772\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5013333333333333\n",
      "val_overall_loss 1.9847303969065349\n",
      "__________________\n",
      "models/model_epoch70.dms\n",
      "overall loss 0.769\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5062666666666666\n",
      "val_overall_loss 1.8918994490305583\n",
      "__________________\n",
      "models/model_epoch71.dms\n",
      "overall loss 0.77\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4961333333333333\n",
      "val_overall_loss 1.954240366744995\n",
      "__________________\n",
      "models/model_epoch72.dms\n",
      "overall loss 0.766\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4976\n",
      "val_overall_loss 1.9308048785527547\n",
      "__________________\n",
      "models/model_epoch73.dms\n",
      "overall loss 0.767\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4769333333333333\n",
      "val_overall_loss 2.03267860399882\n",
      "__________________\n",
      "models/model_epoch74.dms\n",
      "overall loss 0.761\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.49546666666666667\n",
      "val_overall_loss 1.9673592402140299\n",
      "__________________\n",
      "models/model_epoch75.dms\n",
      "overall loss 0.764\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5166666666666667\n",
      "val_overall_loss 1.866610471725464\n",
      "__________________\n",
      "models/model_epoch76.dms\n",
      "overall loss 0.762\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5133333333333333\n",
      "val_overall_loss 1.8192434293746949\n",
      "__________________\n",
      "models/model_epoch77.dms\n",
      "overall loss 0.767\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5154666666666666\n",
      "val_overall_loss 1.8457622254053752\n",
      "__________________\n",
      "models/model_epoch78.dms\n",
      "overall loss 0.764\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4912\n",
      "val_overall_loss 1.9312769877115885\n",
      "__________________\n",
      "models/model_epoch79.dms\n",
      "overall loss 0.755\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4978666666666667\n",
      "val_overall_loss 1.9256704173088073\n",
      "__________________\n",
      "models/model_epoch80.dms\n",
      "overall loss 0.592\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5856\n",
      "val_overall_loss 1.5211692431767783\n",
      "__________________\n",
      "models/model_epoch81.dms\n",
      "overall loss 0.564\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5885333333333334\n",
      "val_overall_loss 1.500411366335551\n",
      "__________________\n",
      "models/model_epoch82.dms\n",
      "overall loss 0.552\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5904\n",
      "val_overall_loss 1.5028795641581219\n",
      "__________________\n",
      "models/model_epoch83.dms\n",
      "overall loss 0.548\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5918666666666667\n",
      "val_overall_loss 1.488613809521993\n",
      "__________________\n",
      "models/model_epoch84.dms\n",
      "overall loss 0.541\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.594\n",
      "val_overall_loss 1.4878873862584432\n",
      "__________________\n",
      "models/model_epoch85.dms\n",
      "overall loss 0.539\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5937333333333333\n",
      "val_overall_loss 1.4921768971125284\n",
      "__________________\n",
      "models/model_epoch86.dms\n",
      "overall loss 0.535\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5961333333333333\n",
      "val_overall_loss 1.4862149397532145\n",
      "__________________\n",
      "models/model_epoch87.dms\n",
      "overall loss 0.53\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5934666666666667\n",
      "val_overall_loss 1.4879267996470134\n",
      "__________________\n",
      "models/model_epoch88.dms\n",
      "overall loss 0.529\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5969333333333333\n",
      "val_overall_loss 1.4793300865809123\n",
      "__________________\n",
      "models/model_epoch89.dms\n",
      "overall loss 0.525\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5970666666666666\n",
      "val_overall_loss 1.489362585957845\n",
      "__________________\n",
      "models/model_epoch90.dms\n",
      "overall loss 0.525\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.598\n",
      "val_overall_loss 1.477729288736979\n",
      "__________________\n",
      "models/model_epoch91.dms\n",
      "overall loss 0.523\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5949333333333333\n",
      "val_overall_loss 1.4861261055628459\n",
      "__________________\n",
      "models/model_epoch92.dms\n",
      "overall loss 0.522\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5953333333333334\n",
      "val_overall_loss 1.4779976332346598\n",
      "__________________\n",
      "models/model_epoch93.dms\n",
      "overall loss 0.52\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5989333333333333\n",
      "val_overall_loss 1.4718236329396566\n",
      "__________________\n",
      "models/model_epoch94.dms\n",
      "overall loss 0.517\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5928\n",
      "val_overall_loss 1.478251960102717\n",
      "__________________\n",
      "models/model_epoch95.dms\n",
      "overall loss 0.517\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5970666666666666\n",
      "val_overall_loss 1.4726358586629231\n",
      "__________________\n",
      "models/model_epoch96.dms\n",
      "overall loss 0.517\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5969333333333333\n",
      "val_overall_loss 1.4826879173278809\n",
      "__________________\n",
      "models/model_epoch97.dms\n",
      "overall loss 0.518\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5956\n",
      "val_overall_loss 1.478838102722168\n",
      "__________________\n",
      "models/model_epoch98.dms\n",
      "overall loss 0.516\n",
      "current lr 1.000e-02\n",
      "__________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_accuracy 0.6010666666666666\n",
      "val_overall_loss 1.470864688237508\n",
      "__________________\n",
      "models/model_epoch99.dms\n",
      "overall loss 0.517\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5981333333333333\n",
      "val_overall_loss 1.4751247268040975\n",
      "__________________\n",
      "models/model_epoch100.dms\n",
      "overall loss 0.516\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5945333333333334\n",
      "val_overall_loss 1.466208149210612\n",
      "__________________\n",
      "models/model_epoch101.dms\n",
      "overall loss 0.511\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5978666666666667\n",
      "val_overall_loss 1.4773006734848022\n",
      "__________________\n",
      "models/model_epoch102.dms\n",
      "overall loss 0.51\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5965333333333334\n",
      "val_overall_loss 1.4749180212656656\n",
      "__________________\n",
      "models/model_epoch103.dms\n",
      "overall loss 0.512\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5982666666666666\n",
      "val_overall_loss 1.4708130274454752\n",
      "__________________\n",
      "models/model_epoch104.dms\n",
      "overall loss 0.51\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.5994666666666667\n",
      "val_overall_loss 1.458570642344157\n",
      "__________________\n",
      "models/model_epoch105.dms\n",
      "overall loss 0.491\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6048\n",
      "val_overall_loss 1.445237059656779\n",
      "__________________\n",
      "models/model_epoch106.dms\n",
      "overall loss 0.485\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6026666666666667\n",
      "val_overall_loss 1.450442616780599\n",
      "__________________\n",
      "models/model_epoch107.dms\n",
      "overall loss 0.486\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6052\n",
      "val_overall_loss 1.4453793477376302\n",
      "__________________\n",
      "models/model_epoch108.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6037333333333333\n",
      "val_overall_loss 1.4439275818506876\n",
      "__________________\n",
      "models/model_epoch109.dms\n",
      "overall loss 0.484\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6065333333333334\n",
      "val_overall_loss 1.4437876663208007\n",
      "__________________\n",
      "models/model_epoch110.dms\n",
      "overall loss 0.484\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6037333333333333\n",
      "val_overall_loss 1.4496987455368042\n",
      "__________________\n",
      "models/model_epoch111.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6050666666666666\n",
      "val_overall_loss 1.443943736966451\n",
      "__________________\n",
      "models/model_epoch112.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6045333333333334\n",
      "val_overall_loss 1.4454554536819457\n",
      "__________________\n",
      "models/model_epoch113.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6053333333333333\n",
      "val_overall_loss 1.4440290244420368\n",
      "__________________\n",
      "models/model_epoch114.dms\n",
      "overall loss 0.481\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6057333333333333\n",
      "val_overall_loss 1.4460277321497599\n",
      "__________________\n",
      "models/model_epoch115.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6070666666666666\n",
      "val_overall_loss 1.440263995361328\n",
      "__________________\n",
      "models/model_epoch116.dms\n",
      "overall loss 0.482\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6056\n",
      "val_overall_loss 1.4409546137491862\n",
      "__________________\n",
      "models/model_epoch117.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6044\n",
      "val_overall_loss 1.446934058380127\n",
      "__________________\n",
      "models/model_epoch118.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6005333333333334\n",
      "val_overall_loss 1.451796442858378\n",
      "__________________\n",
      "models/model_epoch119.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.606\n",
      "val_overall_loss 1.4419982714335124\n",
      "__________________\n",
      "models/model_epoch120.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6041333333333333\n",
      "val_overall_loss 1.4445696127573648\n",
      "__________________\n",
      "models/model_epoch121.dms\n",
      "overall loss 0.483\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6050666666666666\n",
      "val_overall_loss 1.4459017740885416\n",
      "__________________\n",
      "models/model_epoch122.dms\n",
      "overall loss 0.482\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6084\n",
      "val_overall_loss 1.4415439877827962\n",
      "__________________\n",
      "models/model_epoch123.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6028\n",
      "val_overall_loss 1.4468271039962768\n",
      "__________________\n",
      "models/model_epoch124.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.6062666666666666\n",
      "val_overall_loss 1.4458845443089803\n",
      "__________________\n",
      "models/model_epoch125.dms\n",
      "overall loss 0.48\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6057333333333333\n",
      "val_overall_loss 1.4439791982014973\n",
      "__________________\n",
      "models/model_epoch126.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6056\n",
      "val_overall_loss 1.4445662939389547\n",
      "__________________\n",
      "models/model_epoch127.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6048\n",
      "val_overall_loss 1.4452446048100789\n",
      "__________________\n",
      "models/model_epoch128.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6053333333333333\n",
      "val_overall_loss 1.4392650007247925\n",
      "__________________\n",
      "models/model_epoch129.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.606\n",
      "val_overall_loss 1.444658538309733\n",
      "__________________\n",
      "models/model_epoch130.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6058666666666667\n",
      "val_overall_loss 1.4425613637924195\n",
      "__________________\n",
      "models/model_epoch131.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.606\n",
      "val_overall_loss 1.4422606023152669\n",
      "__________________\n",
      "models/model_epoch132.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6076\n",
      "val_overall_loss 1.4455094263712565\n",
      "__________________\n",
      "models/model_epoch133.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6068\n",
      "val_overall_loss 1.4453146556536356\n",
      "__________________\n",
      "models/model_epoch134.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6054666666666667\n",
      "val_overall_loss 1.4444605868021647\n",
      "__________________\n",
      "models/model_epoch135.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6074666666666667\n",
      "val_overall_loss 1.4426675689061483\n",
      "__________________\n",
      "models/model_epoch136.dms\n",
      "overall loss 0.476\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6061333333333333\n",
      "val_overall_loss 1.440490311686198\n",
      "__________________\n",
      "models/model_epoch137.dms\n",
      "overall loss 0.475\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6032\n",
      "val_overall_loss 1.44183057568868\n",
      "__________________\n",
      "models/model_epoch138.dms\n",
      "overall loss 0.476\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6057333333333333\n",
      "val_overall_loss 1.4422100528081259\n",
      "__________________\n",
      "models/model_epoch139.dms\n",
      "overall loss 0.478\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.6056\n",
      "val_overall_loss 1.4440540089289347\n",
      "__________________\n",
      "models/model_epoch140.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6082666666666666\n",
      "val_overall_loss 1.4405386355082195\n",
      "__________________\n",
      "models/model_epoch141.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6036\n",
      "val_overall_loss 1.4485989433924358\n",
      "__________________\n",
      "models/model_epoch142.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6069333333333333\n",
      "val_overall_loss 1.4386630602518717\n",
      "__________________\n",
      "models/model_epoch143.dms\n",
      "overall loss 0.479\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6073333333333333\n",
      "val_overall_loss 1.440779510498047\n",
      "__________________\n",
      "models/model_epoch144.dms\n",
      "overall loss 0.475\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6074666666666667\n",
      "val_overall_loss 1.4404404286384582\n",
      "__________________\n",
      "models/model_epoch145.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6068\n",
      "val_overall_loss 1.4438686639785767\n",
      "__________________\n",
      "models/model_epoch146.dms\n",
      "overall loss 0.476\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6052\n",
      "val_overall_loss 1.440758543777466\n",
      "__________________\n",
      "models/model_epoch147.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6061333333333333\n",
      "val_overall_loss 1.4412700709025066\n",
      "__________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch148.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6036\n",
      "val_overall_loss 1.4443852114359539\n",
      "__________________\n",
      "models/model_epoch149.dms\n",
      "overall loss 0.477\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.6046666666666667\n",
      "val_overall_loss 1.4421348145167032\n",
      "__________________\n",
      "choosen epoch: 122 , score: 0.6084\n",
      "best epoch: 122 , score: 0.6084\n",
      "-----------------\n",
      "*****************\n",
      "resnet20aug_kl_soft.pt\n",
      "test_accuracy 0.6027\n",
      "test_overall_loss 1.4309605567932129\n",
      "__________________\n",
      "val_accuracy 0.6084\n",
      "val_overall_loss 1.4415439599990845\n",
      "__________________\n",
      "train_accuracy 0.661435294117647\n",
      "train_overall_loss 1.219889970521366\n",
      "__________________\n",
      "----------------\n",
      "test_accuracy 0.6697\n",
      "test_overall_loss 1.2315243564605713\n",
      "__________________\n",
      "val_accuracy 0.6758666666666666\n",
      "val_overall_loss 1.2068181734720866\n",
      "__________________\n",
      "train_accuracy 0.8110823529411765\n",
      "train_overall_loss 0.6240220426671645\n",
      "__________________\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  for net_teacher, net_student, teacher_name, student_name in [\n",
    "                    (resnet20(), resnet7(), \"resnet20_classic.pt\", \"\"), \n",
    "                    ]:\n",
    "\n",
    "    epochs = 150\n",
    "    download_model(teacher_name, teacher_name)\n",
    "    state_dict_teacher = torch.load(teacher_name)\n",
    "    net_teacher.cuda().load_state_dict(state_dict_teacher)\n",
    "    loader_cached = cache_loader(net_teacher, trainloader, transform_repeats=8, transform_tensor=transform_train)\n",
    "\n",
    "    experiment_name = teacher_name[:8]+\"aug_kl_soft.pt\"\n",
    "    logger = TensorBoardLogger(\"logs\", dataset_name, \"resnet7\", experiment_name)\n",
    "    net_student = train_distillation_cached(\n",
    "                              net_student,\n",
    "                              loader_cached,\n",
    "                              valloader,\n",
    "                              epoches=epochs, \n",
    "                              init_lr=1e-1, \n",
    "                              logger=logger,\n",
    "                              return_best=True,\n",
    "                              cos_alpha=0.0,\n",
    "                              l_alpha=0.0,\n",
    "                              p=2,\n",
    "                              wd=1e-4,\n",
    "                              temperature=1, \n",
    "                              transform_tensor=transform_train\n",
    "                              )\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"*****************\")\n",
    "    print(experiment_name)\n",
    "    score_test = validate(net_student, testloader, prename='test')\n",
    "    score_val = validate(net_student, valloader, prename='val')\n",
    "    score_train=validate(net_student, trainloader, prename='train')\n",
    "\n",
    "    print(\"----------------\")\n",
    "    score_teacher_test = validate(net_teacher, testloader, prename='test')\n",
    "    score_teacher_val = validate(net_teacher, valloader, prename='val')\n",
    "    score_teacher_train = validate(net_teacher, trainloader, prename='train')\n",
    "    print(\"----------------\")\n",
    "\n",
    "    hparams = {\"experiment_name\":experiment_name, \"teacher\":teacher_name, \"dataset\":dataset_name}\n",
    "    for key, value in score_val.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_test.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_train.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    \n",
    "    for key, value in score_teacher_test.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_val.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_train.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "\n",
    "    logger.log_hparams(hparams) \n",
    "\n",
    "    torch.save(net_student.state_dict(), experiment_name)\n",
    "\n",
    "    saving_path_template = \"models/model_epoch%s.dms\"\n",
    "    logger.step_=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hyp_aug_cached_cifar100_distillation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bc6f6b5e71d4ef2807d75b244d37861": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bed89e6622ee4040b097183259b7bb9e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6770bbe3c6134818af5f631ac7fe9c2c",
      "value": 1
     }
    },
    "26dd588cfea8434591857828fe74f9ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a4db87f32904f4c9b6ce9b34d2c7d1f",
      "placeholder": "",
      "style": "IPY_MODEL_6646590a3af34633a99ec1ee16b6ac6a",
      "value": "169009152it [00:30, 14820600.67it/s]"
     }
    },
    "2940fc7f5b6442fdb4a1ea28e0ff786e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a4db87f32904f4c9b6ce9b34d2c7d1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60fcdf474b22473b8e2338389826e794": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bc6f6b5e71d4ef2807d75b244d37861",
       "IPY_MODEL_26dd588cfea8434591857828fe74f9ae"
      ],
      "layout": "IPY_MODEL_2940fc7f5b6442fdb4a1ea28e0ff786e"
     }
    },
    "6646590a3af34633a99ec1ee16b6ac6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6770bbe3c6134818af5f631ac7fe9c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bed89e6622ee4040b097183259b7bb9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
