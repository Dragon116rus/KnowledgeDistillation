{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloanding third-party code for resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3335,
     "status": "ok",
     "timestamp": 1584263614948,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "wfePU8fqBh0p",
    "outputId": "01bb1f26-234c-4b7f-b7d1-2c24599c457d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-15 09:13:32--  https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5001 (4.9K) [text/plain]\n",
      "Saving to: ‘resnet.py’\n",
      "\n",
      "\r",
      "resnet.py             0%[                    ]       0  --.-KB/s               \r",
      "resnet.py           100%[===================>]   4.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-03-15 09:13:33 (78.2 MB/s) - ‘resnet.py’ saved [5001/5001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/akamaster/pytorch_resnet_cifar10/d1872999394aa0c234e8d855e3c853eb061f7c06/resnet.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading/uploading with google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22393,
     "status": "ok",
     "timestamp": 1584263634021,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "lLar-Or9BtDy",
    "outputId": "271ab1e6-d1a4-4add-c557-2f87fc5d3085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# autorize in google dirve\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# download model from google drive\n",
    "def download_model(source_name, saving_name):\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp \"drive/My Drive/Colab Notebooks/Study/theasis/cifar_models/{source_name}\" {saving_name}\n",
    "\n",
    "# upload model to google drive\n",
    "def upload_model(source_name, saving_name):\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp {source_name} \"drive/My Drive/Colab Notebooks/Study/theasis/cifar_models/{saving_name}\" \n",
    "\n",
    "def upload_logs():\n",
    "  # drive.mount('/content/gdrive')\n",
    "  !cp -r logs \"drive/My Drive/Colab Notebooks/Study/theasis/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libs importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDHAyQCTB0m7"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "from torch.utils.data import Subset, ConcatDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from resnet import resnet20, BasicBlock, _weights_init, resnet32, resnet56, resnet44, ResNet\n",
    "\n",
    "def resnet7():return ResNet(BasicBlock, [1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration of utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiMNJcDPB2lJ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "  \"\"\"Class for computing average values\n",
    "  \"\"\"    \n",
    "  def __init__(self):\n",
    "    \"\"\"Init class\n",
    "    \"\"\"      \n",
    "    self.sum_ = 0\n",
    "    self.count = 0\n",
    "  \n",
    "  def update(self, val, count=1):\n",
    "    \"\"\"Add new value to track\n",
    "    \n",
    "    Arguments:\n",
    "        val {float} -- new value\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        count {int} -- weigth of val (default: {1})\n",
    "    \"\"\"      \n",
    "    self.sum_ += val\n",
    "    self.count += count\n",
    "\n",
    "  def average(self):\n",
    "    \"\"\"return average value for given values\n",
    "    \"\"\"      \n",
    "    return self.sum_ / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2rud3U0B5Pu"
   },
   "outputs": [],
   "source": [
    "class TensorBoardLogger:\n",
    "    \"\"\"Class for logging into TensorBoard\n",
    "    \"\"\"    \n",
    "    def __init__(self, log_dir, dataset, net, experiment_name):\n",
    "        \"\"\"Init logger\n",
    "        \n",
    "        Arguments:\n",
    "            log_dir {string} -- log dir\n",
    "            dataset {string} -- name of dataset\n",
    "            experiment_name {string} -- name of experiment\n",
    "        \"\"\"        \n",
    "        current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        log_dir_full = os.path.join(log_dir, dataset, net, experiment_name, current_time)\n",
    "        self.writer = tf.summary.create_file_writer(log_dir_full)\n",
    "        self.step_ = 0\n",
    "        \n",
    "    def log_scalar(self, tag, value, step=None, description=None):\n",
    "        \"\"\"Log scalar\n",
    "        \n",
    "        Arguments:\n",
    "            tag {string} -- name of variable to log\n",
    "            value {float} -- value of variable\n",
    "        \n",
    "        Keyword Arguments:\n",
    "            step {int} -- current epoch number (default: {None})\n",
    "            description {string} -- [description] (default: {None})\n",
    "        \"\"\"        \n",
    "        if step is None:\n",
    "            step = self.step_\n",
    "        with self.writer.as_default():\n",
    "            tf.summary.scalar(tag, value, step=step, description=description)\n",
    "            \n",
    "    def step(self):\n",
    "        \"\"\"Increase epoch number by 1\n",
    "        \"\"\"        \n",
    "        self.step_+=1\n",
    "\n",
    "    def log_hparams(self, hparams):\n",
    "        \"\"\"log hparams\n",
    "        \n",
    "        Arguments:\n",
    "            hparams {dict} -- dict to log\n",
    "        \"\"\"      \n",
    "        with self.writer.as_default():\n",
    "            hp.hparams(hparams)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewF2eWCOB7Pr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "dataset_name = \"cifar10_aug_cached\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZyKuu77MVcV"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  imgs = [i[0] for i in batch]\n",
    "  labels = [i[1] for i in batch]\n",
    "  return imgs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134,
     "referenced_widgets": [
      "d398f6070935495a8314505238b042f7",
      "13cef53133804635ad2f07e04baba93e",
      "766cbd23ae804d90a174ca95ac53df1d",
      "51cd58c32a814c879e0d0380f3be4745",
      "bfbaf5558fa24f0485c09a65780f0d41",
      "6d01613ce0f7494db52486586b5a49d3",
      "bc6078b935034cb19cf2281b3dc94bae",
      "5e8e71dac9af410db23235ca437dcb59"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41971,
     "status": "ok",
     "timestamp": 1584263653655,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "ph7_tHYAB9cN",
    "outputId": "4e46b29f-d4a3-4eac-f252-27b5730831c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# augmentation and normaliztion for training\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomCrop(32, 4),\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "# only normalization for testing\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     normalize\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, \n",
    "                                        # transform=transform_train\n",
    "                                        )\n",
    "valset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True,\n",
    "                                      #  transform=transform_test\n",
    "                                      )\n",
    "# split trainvalset into val and train\n",
    "idx = np.arange(len(trainset))\n",
    "split = int(len(trainset)*0.15)\n",
    "np.random.seed(42) # set seed to reproduce given set\n",
    "np.random.shuffle(idx)\n",
    "train_idx = idx[split:]\n",
    "val_idx = idx[:split]\n",
    "\n",
    "trainset = Subset(trainset, train_idx)\n",
    "valset = Subset(valset, val_idx)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn,\n",
    "                                          )\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2,\n",
    "                                          pin_memory=True, \n",
    "                                          collate_fn=collate_fn,\n",
    "                                          )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                      #  transform=transform_test\n",
    "                                       )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2,\n",
    "                                         pin_memory=True, \n",
    "                                         collate_fn=collate_fn,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42925,
     "status": "ok",
     "timestamp": 1584263654620,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "188pu9dgstt7",
    "outputId": "934fa2e6-77e1-412f-97aa-96333435db76"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show dataset images\n",
    "for k, i in enumerate(trainset, 1):\n",
    "  plt.subplot(1, 5, k)\n",
    "  plt.imshow(i[0])\n",
    "  \n",
    "  if k==5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApgwwyiYB_Oy"
   },
   "outputs": [],
   "source": [
    "# check the first index, to check that trainval set splitted correctly\n",
    "assert val_idx[0]==33553, \"invalid val set\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slWmMP1LCC9b"
   },
   "outputs": [],
   "source": [
    "def accuracy_minibatch(outputs, labels):\n",
    "  \"\"\"Compute accuracy for batch\n",
    "  \n",
    "  Arguments:\n",
    "      outputs {list or np.array or torch.Tensor} -- outputs from model (vectors of probabilities)\n",
    "      labels {list or np.array or torch.Tensor} -- labels (one number for each sample)\n",
    "  \n",
    "  Returns:\n",
    "      float -- accuracy for minibatch\n",
    "  \"\"\"  \n",
    "  if isinstance(outputs, torch.Tensor):\n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "  if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "  \n",
    "  predict_= np.argmax(outputs, axis=1)\n",
    "  true_labels_= labels\n",
    "  micro_acc_score = accuracy_score(predict_, true_labels_)\n",
    "  return micro_acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07DXQHlXCEa_"
   },
   "outputs": [],
   "source": [
    "def validate(net, testloader, logger=None, verbose=True, prename=\"val\",\n",
    "             cuda=True,\n",
    "             transform_tensor=transform_test,\n",
    "             transform_repeats=1\n",
    "             ):\n",
    "  \"\"\"Function for compute metrics on validation set\n",
    "  \n",
    "  Arguments:\n",
    "      net {torch net} -- model\n",
    "      testloader {DataLoader} -- set to validation\n",
    "      \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      prename {string} -- prename to name of metric (default: {\"val\"})\n",
    "      cuda {bool} -- use cuda or not (default: {True})\n",
    "      transform_tensor {[type]} -- transformation for image (default: {transform_test})\n",
    "      transform_repeats {int} -- amount of repeats (default: {1})\n",
    "  \n",
    "  Returns:\n",
    "      [dict] -- scores for computing metrics\n",
    "  \"\"\"   \n",
    "  # change net to evaluation mode\n",
    "  net.eval()\n",
    "  ce_loss_avg = AverageMeter()\n",
    "  accuracy_score_avg = AverageMeter()\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  # evaluate dataset\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs]) for i in range(transform_repeats)]\n",
    "\n",
    "    current_batch_size = len(labels)\n",
    "\n",
    "    outputs = 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs += net(inputs_[i].cuda() if cuda else inputs_[i])\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    loss = criterion(outputs, labels).cpu().detach().numpy()\n",
    "    \n",
    "    micro_acc_score = accuracy_minibatch(outputs, labels)\n",
    "\n",
    "    accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "    ce_loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "\n",
    "  accuracy = accuracy_score_avg.average()\n",
    "  ce_loss = ce_loss_avg.average()\n",
    "  scores = {\n",
    "      \"%s_accuracy\"%prename: accuracy,\n",
    "      \"%s_overall_loss\"%prename: ce_loss,\n",
    "       }\n",
    "  \n",
    "  # log scores\n",
    "  for name, score in scores.items():\n",
    "    if logger:\n",
    "      logger.log_scalar(name, score)\n",
    "    if verbose:\n",
    "      print(name, score)\n",
    "  \n",
    "  if verbose:\n",
    "    print(\"__________________\")\n",
    "  # change net to training mode\n",
    "  net.train()\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rNl7qpSCGLk"
   },
   "outputs": [],
   "source": [
    "def train_distillation_cached(\n",
    "    net_student, \n",
    "    trainloader, \n",
    "    testloader, \n",
    "    logger=None,\n",
    "    cuda=True,\n",
    "    epoches=150,\n",
    "    verbose=True, \n",
    "    return_best=False,\n",
    "    init_lr=0.1,\n",
    "    temperature=1,\n",
    "    cos_alpha=0,\n",
    "    l_alpha=0,\n",
    "    p=2,\n",
    "    shuffle=True,\n",
    "    wd=1e-4,\n",
    "    transform_tensor=transform_train\n",
    "    ):\n",
    "  \"\"\"Training using knowledge distillation approach\n",
    "  \n",
    "  Arguments:\n",
    "      net_student {torch model} -- student model\n",
    "      trainloader {list} -- cached train set\n",
    "      testloader {DataLoader} -- test set\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      logger {TensorBoardLogger} -- logger (default: {None})\n",
    "      compression_f {function} -- function to preprocess input (default: {None})\n",
    "      epoches {int} -- epochs to train (default: {150})\n",
    "      verbose {bool} -- show metrics (default: {True})\n",
    "      return_best {bool} -- return best model (default: {False})\n",
    "      init_lr {float} -- initial learning rate (default: {0.1})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      cos_alpha {float} -- coefficeint of combining distillation (KL) and cosine disimilarity loss (default: {0})\n",
    "      shuffle {bool} -- shuffle dataset each epoch (default: {True})\n",
    "      temperature {int} -- temperature (default: {1})\n",
    "      l_alpha {float} -- coefficeint of L^p loss in distillation loss (default: {0.0})\n",
    "      p {int} -- parametr for L^p loss (default: {2})\n",
    "  \n",
    "  Returns:\n",
    "      torch model -- best or last model\n",
    "  \"\"\"    \n",
    "  # change net to training mode\n",
    "  net_student.train()\n",
    "  net_teacher.eval()\n",
    "  # use gpu to train\n",
    "  net_student.cuda()\n",
    "\n",
    "  criterion_ce = nn.CrossEntropyLoss().cuda()\n",
    "  criterion_nll = nn.NLLLoss().cuda()\n",
    "  criterion_bce = nn.BCELoss().cuda() \n",
    "  criterion_kl = nn.KLDivLoss(reduction=\"batchmean\").cuda()\n",
    "  cosine_similarity = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "  criterion_mse = nn.MSELoss()\n",
    "  criterion_mae = nn.L1Loss()\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "      net_student.parameters(), \n",
    "      lr=init_lr,\n",
    "      momentum=0.9,\n",
    "      weight_decay=wd\n",
    "      )\n",
    "  scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [80, 105, 125, 140])\n",
    "\n",
    "  validation_scores = []\n",
    "  os.makedirs(\"models\", exist_ok=True)\n",
    "  saving_path_template = \"models/model_epoch%s.dms\"\n",
    "\n",
    "  for epoch in range(epoches):  # loop over the dataset multiple times\n",
    "    saving_name = saving_path_template%epoch\n",
    "    \n",
    "    loss_avg = AverageMeter()\n",
    "    accuracy_score_avg = AverageMeter()\n",
    "    loss_kl_avg = AverageMeter()\n",
    "    loss_cos_dis_avg = AverageMeter()\n",
    "    loss_ce_avg = AverageMeter()\n",
    "\n",
    "    if shuffle:\n",
    "      np.random.shuffle(trainloader)\n",
    "\n",
    "    for i, data in enumerate(trainloader, 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_pil, out_teacher, out_kl_teacher, labels = data\n",
    "        current_batch_size = len(out_teacher)\n",
    "\n",
    "        inputs = torch.stack([transform_tensor(j) for j in inputs_pil])\n",
    "        inputs, out_teacher, out_kl_teacher = inputs.cuda(), out_teacher.cuda(), out_kl_teacher.cuda()\n",
    "\n",
    "        if cuda:\n",
    "          inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        out_student = net_student(inputs)\n",
    "        soft_log_probs = F.log_softmax(out_student / temperature, dim=1)\n",
    "        soft_targets = out_kl_teacher\n",
    "        \n",
    "        # loss_bce = criterion_bce(F.sigmoid(out_student), F.sigmoid(out_teacher))\n",
    "        kl_loss = criterion_kl(soft_log_probs, soft_targets.detach())\n",
    "        cos_dis_loss =  (1 - cosine_similarity(out_student - torch.mean(out_student, dim=1, keepdim=True), out_teacher.detach() - torch.mean(out_teacher.detach(), dim=1, keepdim=True))).mean()\n",
    "        \n",
    "        l_loss = (torch.abs(out_student - out_teacher)**p).mean()**(1/p)\n",
    "\n",
    "        loss = (1 - cos_alpha - l_alpha) * kl_loss + cos_alpha * cos_dis_loss + l_alpha * l_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        micro_acc_score = accuracy_minibatch(out_student, labels)\n",
    "\n",
    "        loss_avg.update(loss.item()*current_batch_size, current_batch_size)\n",
    "        accuracy_score_avg.update(micro_acc_score*current_batch_size, current_batch_size)\n",
    "        loss_kl_avg.update(kl_loss.item()*current_batch_size, current_batch_size)\n",
    "        loss_cos_dis_avg.update(cos_dis_loss.item()*current_batch_size, current_batch_size)\n",
    "        \n",
    "    if verbose:\n",
    "        print(saving_name)\n",
    "        print('overall loss {:.3}'.format(loss_avg.average()))\n",
    "        print('current lr {:.3e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        print(\"__________________\")\n",
    "    # clear memory \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "    \n",
    "    # save scores to take best model in the future\n",
    "    validation_score = validate(net_student, valloader, \n",
    "                                logger=logger, \n",
    "                                verbose=verbose, \n",
    "                                # compression_f=compression_f\n",
    "                                )\n",
    "    accuracy = validation_score['val_accuracy']\n",
    "    validation_scores.append(accuracy)\n",
    "    # save model\n",
    "    torch.save(net_student.state_dict(), saving_name)\n",
    "\n",
    "    if logger:\n",
    "        logger.log_scalar(\"overall_loss\", loss_avg.average())\n",
    "        logger.log_scalar(\"accuracy\", accuracy_score_avg.average())\n",
    "        logger.log_scalar(\"kl_loss\", loss_kl_avg.average())\n",
    "        logger.log_scalar(\"cos_dis_loss\", loss_cos_dis_avg.average())\n",
    "        logger.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "  best_epoch = np.argmax(validation_scores)\n",
    "  if return_best:\n",
    "    choosen_epoch = best_epoch\n",
    "  else:\n",
    "    choosen_epoch = epoch\n",
    "  if verbose:\n",
    "    print(\"choosen epoch:\", choosen_epoch, \", score:\", validation_scores[choosen_epoch])\n",
    "    print(\"best epoch:\", best_epoch, \", score:\", validation_scores[best_epoch])\n",
    "  model_name = saving_path_template%choosen_epoch\n",
    "  net_student.load_state_dict(torch.load(model_name))\n",
    "  return net_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4ttxWfsmRcT"
   },
   "outputs": [],
   "source": [
    "def cache_loader(net_teacher, loader, cuda=True,\n",
    "                 transform_tensor=transform_train,\n",
    "                 transform_repeats=4\n",
    "                 ):\n",
    "  \"\"\"Cache loader, to prevent computing teacher model output\n",
    "  \n",
    "  Arguments:\n",
    "      net_teacher {torch model} -- teacher model\n",
    "      loader {DataLoader} -- dataset to cache\n",
    "  \n",
    "  Keyword Arguments:\n",
    "      cuda {bool} -- use cuda or not(default: {True})\n",
    "      transform_tensor {func} -- image transformation (default: {transform_train})\n",
    "      transform_repeats {int} -- amount of repeats (default: {int})\n",
    "  \n",
    "  Returns:\n",
    "      List -- List of (inputs, teacher model outputs)\n",
    "  \"\"\"  \n",
    "  net_teacher.eval()\n",
    "  cached = []\n",
    "  for inputs_pil, labels in loader:\n",
    "    labels = torch.tensor(labels)\n",
    "    if cuda:\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    inputs_ = [torch.stack([transform_tensor(j) for j in inputs_pil]) for i in range(transform_repeats)]\n",
    "\n",
    "    outputs_kl, outputs = 0, 0\n",
    "    for i in range(transform_repeats):\n",
    "        outputs_kl += torch.softmax(net_teacher(inputs_[i].cuda() if cuda else inputs_[i]), axis=1)\n",
    "        outputs += net_teacher(inputs_[i].cuda() if cuda else inputs_[i])\n",
    "    outputs_kl/=transform_repeats\n",
    "    outputs/=transform_repeats\n",
    "\n",
    "    cached.append([inputs_pil, outputs.cpu().detach(), outputs_kl.cpu().detach(), labels.cpu().detach()])\n",
    "  return cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3284549,
     "status": "ok",
     "timestamp": 1584189782511,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "VBug0SVkG4yj",
    "outputId": "f337ca51-d995-4c16-bec6-ec0d435b58ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch0.dms\n",
      "overall loss 3.45\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.4766666666666667\n",
      "val_overall_loss 1.6938858221054076\n",
      "__________________\n",
      "models/model_epoch1.dms\n",
      "overall loss 2.91\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5796\n",
      "val_overall_loss 1.4511996846516928\n",
      "__________________\n",
      "models/model_epoch2.dms\n",
      "overall loss 2.67\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6225333333333334\n",
      "val_overall_loss 1.4086370447794596\n",
      "__________________\n",
      "models/model_epoch3.dms\n",
      "overall loss 2.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6357333333333334\n",
      "val_overall_loss 1.6562584487279257\n",
      "__________________\n",
      "models/model_epoch4.dms\n",
      "overall loss 2.35\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6789333333333334\n",
      "val_overall_loss 1.3346600096384684\n",
      "__________________\n",
      "models/model_epoch5.dms\n",
      "overall loss 2.24\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7206666666666667\n",
      "val_overall_loss 1.1014805552800497\n",
      "__________________\n",
      "models/model_epoch6.dms\n",
      "overall loss 2.15\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7209333333333333\n",
      "val_overall_loss 1.1025460697333018\n",
      "__________________\n",
      "models/model_epoch7.dms\n",
      "overall loss 2.08\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7372\n",
      "val_overall_loss 1.1407208308537802\n",
      "__________________\n",
      "models/model_epoch8.dms\n",
      "overall loss 2.02\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7654666666666666\n",
      "val_overall_loss 0.9620886707941692\n",
      "__________________\n",
      "models/model_epoch9.dms\n",
      "overall loss 1.98\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7533333333333333\n",
      "val_overall_loss 0.9664910639762878\n",
      "__________________\n",
      "models/model_epoch10.dms\n",
      "overall loss 1.94\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7729333333333334\n",
      "val_overall_loss 0.9026936106999716\n",
      "__________________\n",
      "models/model_epoch11.dms\n",
      "overall loss 1.91\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7834666666666666\n",
      "val_overall_loss 0.8468522528648377\n",
      "__________________\n",
      "models/model_epoch12.dms\n",
      "overall loss 1.89\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7472\n",
      "val_overall_loss 1.116694867038727\n",
      "__________________\n",
      "models/model_epoch13.dms\n",
      "overall loss 1.86\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7968\n",
      "val_overall_loss 0.8072919223785401\n",
      "__________________\n",
      "models/model_epoch14.dms\n",
      "overall loss 1.85\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7634666666666666\n",
      "val_overall_loss 1.1522478098551432\n",
      "__________________\n",
      "models/model_epoch15.dms\n",
      "overall loss 1.83\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7814666666666666\n",
      "val_overall_loss 0.9125785179138184\n",
      "__________________\n",
      "models/model_epoch16.dms\n",
      "overall loss 1.81\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7892\n",
      "val_overall_loss 0.9341743359247844\n",
      "__________________\n",
      "models/model_epoch17.dms\n",
      "overall loss 1.79\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7648\n",
      "val_overall_loss 1.01193517742157\n",
      "__________________\n",
      "models/model_epoch18.dms\n",
      "overall loss 1.78\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.798\n",
      "val_overall_loss 0.8724081700960795\n",
      "__________________\n",
      "models/model_epoch19.dms\n",
      "overall loss 1.77\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7970666666666667\n",
      "val_overall_loss 0.8030215082804362\n",
      "__________________\n",
      "models/model_epoch20.dms\n",
      "overall loss 1.76\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8169333333333333\n",
      "val_overall_loss 0.7408433647791545\n",
      "__________________\n",
      "models/model_epoch21.dms\n",
      "overall loss 1.74\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7746666666666666\n",
      "val_overall_loss 1.022056222407023\n",
      "__________________\n",
      "models/model_epoch22.dms\n",
      "overall loss 1.75\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8114666666666667\n",
      "val_overall_loss 0.7255945968707402\n",
      "__________________\n",
      "models/model_epoch23.dms\n",
      "overall loss 1.73\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8024\n",
      "val_overall_loss 0.8135989238739013\n",
      "__________________\n",
      "models/model_epoch24.dms\n",
      "overall loss 1.72\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.806\n",
      "val_overall_loss 0.8012282819112142\n",
      "__________________\n",
      "models/model_epoch25.dms\n",
      "overall loss 1.71\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8056\n",
      "val_overall_loss 0.7850408537546794\n",
      "__________________\n",
      "models/model_epoch26.dms\n",
      "overall loss 1.71\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7918666666666667\n",
      "val_overall_loss 0.8415299159924189\n",
      "__________________\n",
      "models/model_epoch27.dms\n",
      "overall loss 1.71\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.826\n",
      "val_overall_loss 0.6992726093292236\n",
      "__________________\n",
      "models/model_epoch28.dms\n",
      "overall loss 1.7\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7849333333333334\n",
      "val_overall_loss 0.925945264339447\n",
      "__________________\n",
      "models/model_epoch29.dms\n",
      "overall loss 1.7\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8117333333333333\n",
      "val_overall_loss 0.7070928145090739\n",
      "__________________\n",
      "models/model_epoch30.dms\n",
      "overall loss 1.68\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7885333333333333\n",
      "val_overall_loss 0.8770284037828445\n",
      "__________________\n",
      "models/model_epoch31.dms\n",
      "overall loss 1.68\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.804\n",
      "val_overall_loss 0.8196735349655151\n",
      "__________________\n",
      "models/model_epoch32.dms\n",
      "overall loss 1.67\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8081333333333334\n",
      "val_overall_loss 0.7750080892880757\n",
      "__________________\n",
      "models/model_epoch33.dms\n",
      "overall loss 1.67\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8150666666666667\n",
      "val_overall_loss 0.7092906156857809\n",
      "__________________\n",
      "models/model_epoch34.dms\n",
      "overall loss 1.67\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8162666666666667\n",
      "val_overall_loss 0.7168517214457194\n",
      "__________________\n",
      "models/model_epoch35.dms\n",
      "overall loss 1.67\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8256\n",
      "val_overall_loss 0.690027392578125\n",
      "__________________\n",
      "models/model_epoch36.dms\n",
      "overall loss 1.66\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7761333333333333\n",
      "val_overall_loss 1.0188748779296875\n",
      "__________________\n",
      "models/model_epoch37.dms\n",
      "overall loss 1.66\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8108\n",
      "val_overall_loss 0.789044054889679\n",
      "__________________\n",
      "models/model_epoch38.dms\n",
      "overall loss 1.65\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8117333333333333\n",
      "val_overall_loss 0.7836124451001485\n",
      "__________________\n",
      "models/model_epoch39.dms\n",
      "overall loss 1.64\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7949333333333334\n",
      "val_overall_loss 0.9366991039911906\n",
      "__________________\n",
      "models/model_epoch40.dms\n",
      "overall loss 1.65\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7656\n",
      "val_overall_loss 1.0783368743896484\n",
      "__________________\n",
      "models/model_epoch41.dms\n",
      "overall loss 1.64\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8074666666666667\n",
      "val_overall_loss 0.8231442628860474\n",
      "__________________\n",
      "models/model_epoch42.dms\n",
      "overall loss 1.65\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8144\n",
      "val_overall_loss 0.7621632774670919\n",
      "__________________\n",
      "models/model_epoch43.dms\n",
      "overall loss 1.63\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8182666666666667\n",
      "val_overall_loss 0.7494588282426198\n",
      "__________________\n",
      "models/model_epoch44.dms\n",
      "overall loss 1.64\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8274666666666667\n",
      "val_overall_loss 0.6477094609578451\n",
      "__________________\n",
      "models/model_epoch45.dms\n",
      "overall loss 1.63\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8074666666666667\n",
      "val_overall_loss 0.8662178349812826\n",
      "__________________\n",
      "models/model_epoch46.dms\n",
      "overall loss 1.63\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8284\n",
      "val_overall_loss 0.6981001160939535\n",
      "__________________\n",
      "models/model_epoch47.dms\n",
      "overall loss 1.62\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8112\n",
      "val_overall_loss 0.8606238051096599\n",
      "__________________\n",
      "models/model_epoch48.dms\n",
      "overall loss 1.63\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8253333333333334\n",
      "val_overall_loss 0.7128908582528433\n",
      "__________________\n",
      "models/model_epoch49.dms\n",
      "overall loss 1.62\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8146666666666667\n",
      "val_overall_loss 0.7335517012914022\n",
      "__________________\n",
      "models/model_epoch50.dms\n",
      "overall loss 1.62\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7957333333333333\n",
      "val_overall_loss 0.9584859561920166\n",
      "__________________\n",
      "models/model_epoch51.dms\n",
      "overall loss 1.62\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8345333333333333\n",
      "val_overall_loss 0.6722091785430908\n",
      "__________________\n",
      "models/model_epoch52.dms\n",
      "overall loss 1.62\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8281333333333334\n",
      "val_overall_loss 0.6764469708442687\n",
      "__________________\n",
      "models/model_epoch53.dms\n",
      "overall loss 1.61\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8056\n",
      "val_overall_loss 0.7941031754811605\n",
      "__________________\n",
      "models/model_epoch54.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8236\n",
      "val_overall_loss 0.7183552900314331\n",
      "__________________\n",
      "models/model_epoch55.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7778666666666667\n",
      "val_overall_loss 1.1139142988840738\n",
      "__________________\n",
      "models/model_epoch56.dms\n",
      "overall loss 1.61\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8174666666666667\n",
      "val_overall_loss 0.762576035118103\n",
      "__________________\n",
      "models/model_epoch57.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7785333333333333\n",
      "val_overall_loss 1.032535278638204\n",
      "__________________\n",
      "models/model_epoch58.dms\n",
      "overall loss 1.61\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8301333333333333\n",
      "val_overall_loss 0.6572355067253113\n",
      "__________________\n",
      "models/model_epoch59.dms\n",
      "overall loss 1.61\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8029333333333334\n",
      "val_overall_loss 0.8052611442406973\n",
      "__________________\n",
      "models/model_epoch60.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8316\n",
      "val_overall_loss 0.6745236396153768\n",
      "__________________\n",
      "models/model_epoch61.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8252\n",
      "val_overall_loss 0.7079799294153849\n",
      "__________________\n",
      "models/model_epoch62.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.828\n",
      "val_overall_loss 0.7101760929743449\n",
      "__________________\n",
      "models/model_epoch63.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7932\n",
      "val_overall_loss 0.9300010894139608\n",
      "__________________\n",
      "models/model_epoch64.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8170666666666667\n",
      "val_overall_loss 0.7835943786938985\n",
      "__________________\n",
      "models/model_epoch65.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8170666666666667\n",
      "val_overall_loss 0.7640602616667748\n",
      "__________________\n",
      "models/model_epoch66.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7297333333333333\n",
      "val_overall_loss 1.2687240664164225\n",
      "__________________\n",
      "models/model_epoch67.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8076\n",
      "val_overall_loss 0.8464893103281657\n",
      "__________________\n",
      "models/model_epoch68.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7568\n",
      "val_overall_loss 1.096520350710551\n",
      "__________________\n",
      "models/model_epoch69.dms\n",
      "overall loss 1.6\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8217333333333333\n",
      "val_overall_loss 0.8107623929341634\n",
      "__________________\n",
      "models/model_epoch70.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7916\n",
      "val_overall_loss 0.9271067293167115\n",
      "__________________\n",
      "models/model_epoch71.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8348\n",
      "val_overall_loss 0.682590839767456\n",
      "__________________\n",
      "models/model_epoch72.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8157333333333333\n",
      "val_overall_loss 0.7781596682707469\n",
      "__________________\n",
      "models/model_epoch73.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8033333333333333\n",
      "val_overall_loss 0.8960665403982003\n",
      "__________________\n",
      "models/model_epoch74.dms\n",
      "overall loss 1.59\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8364\n",
      "val_overall_loss 0.6393259855906168\n",
      "__________________\n",
      "models/model_epoch75.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8121333333333334\n",
      "val_overall_loss 0.7655879757881164\n",
      "__________________\n",
      "models/model_epoch76.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8125333333333333\n",
      "val_overall_loss 0.7754781911849976\n",
      "__________________\n",
      "models/model_epoch77.dms\n",
      "overall loss 1.57\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8193333333333334\n",
      "val_overall_loss 0.7314711445490519\n",
      "__________________\n",
      "models/model_epoch78.dms\n",
      "overall loss 1.57\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8333333333333334\n",
      "val_overall_loss 0.6696593638737997\n",
      "__________________\n",
      "models/model_epoch79.dms\n",
      "overall loss 1.58\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8022666666666667\n",
      "val_overall_loss 0.8588088352203369\n",
      "__________________\n",
      "models/model_epoch80.dms\n",
      "overall loss 1.4\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8677333333333334\n",
      "val_overall_loss 0.5101596333821614\n",
      "__________________\n",
      "models/model_epoch81.dms\n",
      "overall loss 1.36\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8728\n",
      "val_overall_loss 0.4853343806584676\n",
      "__________________\n",
      "models/model_epoch82.dms\n",
      "overall loss 1.35\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8688\n",
      "val_overall_loss 0.501375381787618\n",
      "__________________\n",
      "models/model_epoch83.dms\n",
      "overall loss 1.34\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8718666666666667\n",
      "val_overall_loss 0.48925321804682415\n",
      "__________________\n",
      "models/model_epoch84.dms\n",
      "overall loss 1.33\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8704\n",
      "val_overall_loss 0.4974847583770752\n",
      "__________________\n",
      "models/model_epoch85.dms\n",
      "overall loss 1.33\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8701333333333333\n",
      "val_overall_loss 0.4948271701494853\n",
      "__________________\n",
      "models/model_epoch86.dms\n",
      "overall loss 1.32\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8737333333333334\n",
      "val_overall_loss 0.4761707043965658\n",
      "__________________\n",
      "models/model_epoch87.dms\n",
      "overall loss 1.32\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8741333333333333\n",
      "val_overall_loss 0.48671370503902434\n",
      "__________________\n",
      "models/model_epoch88.dms\n",
      "overall loss 1.32\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.87\n",
      "val_overall_loss 0.49306750818888345\n",
      "__________________\n",
      "models/model_epoch89.dms\n",
      "overall loss 1.32\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8766666666666667\n",
      "val_overall_loss 0.48657447900772094\n",
      "__________________\n",
      "models/model_epoch90.dms\n",
      "overall loss 1.32\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8770666666666667\n",
      "val_overall_loss 0.4667160165766875\n",
      "__________________\n",
      "models/model_epoch91.dms\n",
      "overall loss 1.31\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8756\n",
      "val_overall_loss 0.47696984736124676\n",
      "__________________\n",
      "models/model_epoch92.dms\n",
      "overall loss 1.31\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8754666666666666\n",
      "val_overall_loss 0.4761651779492696\n",
      "__________________\n",
      "models/model_epoch93.dms\n",
      "overall loss 1.31\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8752\n",
      "val_overall_loss 0.49608704675038656\n",
      "__________________\n",
      "models/model_epoch94.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8782666666666666\n",
      "val_overall_loss 0.4636159794489543\n",
      "__________________\n",
      "models/model_epoch95.dms\n",
      "overall loss 1.31\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8792\n",
      "val_overall_loss 0.4643430291811625\n",
      "__________________\n",
      "models/model_epoch96.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.876\n",
      "val_overall_loss 0.47373471660614014\n",
      "__________________\n",
      "models/model_epoch97.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8748\n",
      "val_overall_loss 0.48703407160416246\n",
      "__________________\n",
      "models/model_epoch98.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8781333333333333\n",
      "val_overall_loss 0.4766704295476278\n",
      "__________________\n",
      "models/model_epoch99.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8737333333333334\n",
      "val_overall_loss 0.48814196723302206\n",
      "__________________\n",
      "models/model_epoch100.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8776\n",
      "val_overall_loss 0.4714785597483317\n",
      "__________________\n",
      "models/model_epoch101.dms\n",
      "overall loss 1.29\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8770666666666667\n",
      "val_overall_loss 0.48086754795710246\n",
      "__________________\n",
      "models/model_epoch102.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8781333333333333\n",
      "val_overall_loss 0.47108508551915484\n",
      "__________________\n",
      "models/model_epoch103.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8812\n",
      "val_overall_loss 0.4581942830423514\n",
      "__________________\n",
      "models/model_epoch104.dms\n",
      "overall loss 1.3\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8789333333333333\n",
      "val_overall_loss 0.4749890945752462\n",
      "__________________\n",
      "models/model_epoch105.dms\n",
      "overall loss 1.27\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.882\n",
      "val_overall_loss 0.4561037057717641\n",
      "__________________\n",
      "models/model_epoch106.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8829333333333333\n",
      "val_overall_loss 0.45181235129038494\n",
      "__________________\n",
      "models/model_epoch107.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8834666666666666\n",
      "val_overall_loss 0.4504078728993734\n",
      "__________________\n",
      "models/model_epoch108.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8830666666666667\n",
      "val_overall_loss 0.45072608989079793\n",
      "__________________\n",
      "models/model_epoch109.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8825333333333333\n",
      "val_overall_loss 0.4519207716941834\n",
      "__________________\n",
      "models/model_epoch110.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.45489885374704997\n",
      "__________________\n",
      "models/model_epoch111.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.4487646378199259\n",
      "__________________\n",
      "models/model_epoch112.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8830666666666667\n",
      "val_overall_loss 0.45106529086828234\n",
      "__________________\n",
      "models/model_epoch113.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.882\n",
      "val_overall_loss 0.4519421426614126\n",
      "__________________\n",
      "models/model_epoch114.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8802666666666666\n",
      "val_overall_loss 0.4515479511251052\n",
      "__________________\n",
      "models/model_epoch115.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8817333333333334\n",
      "val_overall_loss 0.4545317894612749\n",
      "__________________\n",
      "models/model_epoch116.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8793333333333333\n",
      "val_overall_loss 0.4559273313442866\n",
      "__________________\n",
      "models/model_epoch117.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8832\n",
      "val_overall_loss 0.44903635991414387\n",
      "__________________\n",
      "models/model_epoch118.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8814666666666666\n",
      "val_overall_loss 0.45998853764534\n",
      "__________________\n",
      "models/model_epoch119.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8825333333333333\n",
      "val_overall_loss 0.4506576707204183\n",
      "__________________\n",
      "models/model_epoch120.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8813333333333333\n",
      "val_overall_loss 0.4538028849929571\n",
      "__________________\n",
      "models/model_epoch121.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8817333333333334\n",
      "val_overall_loss 0.44888407688116033\n",
      "__________________\n",
      "models/model_epoch122.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.882\n",
      "val_overall_loss 0.4551064831415812\n",
      "__________________\n",
      "models/model_epoch123.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8818666666666667\n",
      "val_overall_loss 0.45466357854207357\n",
      "__________________\n",
      "models/model_epoch124.dms\n",
      "overall loss 1.26\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.4528919893582662\n",
      "__________________\n",
      "models/model_epoch125.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8832\n",
      "val_overall_loss 0.4537421313603719\n",
      "__________________\n",
      "models/model_epoch126.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.4510834951400757\n",
      "__________________\n",
      "models/model_epoch127.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.44979322690963747\n",
      "__________________\n",
      "models/model_epoch128.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.882\n",
      "val_overall_loss 0.44988152766227724\n",
      "__________________\n",
      "models/model_epoch129.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.4485329137325287\n",
      "__________________\n",
      "models/model_epoch130.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8812\n",
      "val_overall_loss 0.45351187092463174\n",
      "__________________\n",
      "models/model_epoch131.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8813333333333333\n",
      "val_overall_loss 0.44948381996154785\n",
      "__________________\n",
      "models/model_epoch132.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8825333333333333\n",
      "val_overall_loss 0.44620674437681834\n",
      "__________________\n",
      "models/model_epoch133.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8816\n",
      "val_overall_loss 0.45294826153119405\n",
      "__________________\n",
      "models/model_epoch134.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8828\n",
      "val_overall_loss 0.4502267872810364\n",
      "__________________\n",
      "models/model_epoch135.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8817333333333334\n",
      "val_overall_loss 0.44985519084533054\n",
      "__________________\n",
      "models/model_epoch136.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8834666666666666\n",
      "val_overall_loss 0.4484784755706787\n",
      "__________________\n",
      "models/model_epoch137.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8822666666666666\n",
      "val_overall_loss 0.4540782161394755\n",
      "__________________\n",
      "models/model_epoch138.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.4471871932347616\n",
      "__________________\n",
      "models/model_epoch139.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8832\n",
      "val_overall_loss 0.44971545804341634\n",
      "__________________\n",
      "models/model_epoch140.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8796\n",
      "val_overall_loss 0.4607083359400431\n",
      "__________________\n",
      "models/model_epoch141.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8806666666666667\n",
      "val_overall_loss 0.4523185075124105\n",
      "__________________\n",
      "models/model_epoch142.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8821333333333333\n",
      "val_overall_loss 0.4540021801948547\n",
      "__________________\n",
      "models/model_epoch143.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8824\n",
      "val_overall_loss 0.4507945952574412\n",
      "__________________\n",
      "models/model_epoch144.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8830666666666667\n",
      "val_overall_loss 0.4498964143117269\n",
      "__________________\n",
      "models/model_epoch145.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8816\n",
      "val_overall_loss 0.45343566830158233\n",
      "__________________\n",
      "models/model_epoch146.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8828\n",
      "val_overall_loss 0.4481835514068293\n",
      "__________________\n",
      "models/model_epoch147.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8822666666666666\n",
      "val_overall_loss 0.4485289996504784\n",
      "__________________\n",
      "models/model_epoch148.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8829333333333333\n",
      "val_overall_loss 0.4450757629712423\n",
      "__________________\n",
      "models/model_epoch149.dms\n",
      "overall loss 1.25\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8825333333333333\n",
      "val_overall_loss 0.4536136510213216\n",
      "__________________\n",
      "choosen epoch: 107 , score: 0.8834666666666666\n",
      "best epoch: 107 , score: 0.8834666666666666\n",
      "-----------------\n",
      "*****************\n",
      "resnet20aug_rmse_kl.pt\n",
      "test_accuracy 0.8838\n",
      "test_overall_loss 0.45589289174079894\n",
      "__________________\n",
      "val_accuracy 0.8834666666666666\n",
      "val_overall_loss 0.4504078699827194\n",
      "__________________\n",
      "train_accuracy 0.9174588235294118\n",
      "train_overall_loss 0.2669013012268964\n",
      "__________________\n",
      "----------------\n",
      "test_accuracy 0.9135\n",
      "test_overall_loss 0.342149538898468\n",
      "__________________\n",
      "val_accuracy 0.918\n",
      "val_overall_loss 0.34367471370299657\n",
      "__________________\n",
      "train_accuracy 0.9966823529411765\n",
      "train_overall_loss 0.013359113076153924\n",
      "__________________\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  for net_teacher, net_student, teacher_name, student_name in [\n",
    "                    (resnet20(), resnet7(), \"resnet20_classic.pt\", \"\"), \n",
    "                    ]:\n",
    "\n",
    "    epochs = 150\n",
    "    download_model(teacher_name, teacher_name)\n",
    "    state_dict_teacher = torch.load(teacher_name)\n",
    "    net_teacher.cuda().load_state_dict(state_dict_teacher)\n",
    "    loader_cached = cache_loader(net_teacher, trainloader, transform_repeats=8, transform_tensor=transform_train)\n",
    "\n",
    "    experiment_name = teacher_name[:8]+\"aug_rmse_kl.pt\"\n",
    "    logger = TensorBoardLogger(\"logs\", dataset_name, \"resnet7\", experiment_name)\n",
    "    net_student = train_distillation_cached(\n",
    "                              net_student,\n",
    "                              loader_cached,\n",
    "                              valloader,\n",
    "                              epoches=epochs, \n",
    "                              init_lr=1e-1, \n",
    "                              logger=logger,\n",
    "                              return_best=True,\n",
    "                              cos_alpha=0.0,\n",
    "                              l_alpha=0.5,\n",
    "                              p=2,\n",
    "                              wd=1e-4,\n",
    "                              temperature=1, \n",
    "                              transform_tensor=transform_train\n",
    "                              )\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"*****************\")\n",
    "    print(experiment_name)\n",
    "    score_test = validate(net_student, testloader, prename='test')\n",
    "    score_val = validate(net_student, valloader, prename='val')\n",
    "    score_train=validate(net_student, trainloader, prename='train')\n",
    "\n",
    "    print(\"----------------\")\n",
    "    score_teacher_test = validate(net_teacher, testloader, prename='test')\n",
    "    score_teacher_val = validate(net_teacher, valloader, prename='val')\n",
    "    score_teacher_train = validate(net_teacher, trainloader, prename='train')\n",
    "    print(\"----------------\")\n",
    "\n",
    "    hparams = {\"experiment_name\":experiment_name, \"teacher\":teacher_name, \"dataset\":dataset_name}\n",
    "    for key, value in score_val.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_test.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_train.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    \n",
    "    for key, value in score_teacher_test.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_val.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_train.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "\n",
    "    logger.log_hparams(hparams) \n",
    "\n",
    "    torch.save(net_student.state_dict(), experiment_name)\n",
    "    # upload_model(experiment_name, experiment_name)\n",
    "\n",
    "    saving_path_template = \"models/model_epoch%s.dms\"\n",
    "    logger.step_=0\n",
    "    upload_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2283946,
     "status": "ok",
     "timestamp": 1584266046354,
     "user": {
      "displayName": "Артур Богданов",
      "photoUrl": "",
      "userId": "15687335591145153193"
     },
     "user_tz": -180
    },
    "id": "W6nZao71d4FR",
    "outputId": "b9ddff68-03dc-4534-a527-68c2dde657bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model_epoch0.dms\n",
      "overall loss 1.5\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.5304\n",
      "val_overall_loss 1.2690553342819213\n",
      "__________________\n",
      "models/model_epoch1.dms\n",
      "overall loss 1.08\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6132\n",
      "val_overall_loss 1.0784917231877644\n",
      "__________________\n",
      "models/model_epoch2.dms\n",
      "overall loss 0.93\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6514666666666666\n",
      "val_overall_loss 1.018153555393219\n",
      "__________________\n",
      "models/model_epoch3.dms\n",
      "overall loss 0.828\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.6788\n",
      "val_overall_loss 0.88627261206309\n",
      "__________________\n",
      "models/model_epoch4.dms\n",
      "overall loss 0.752\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7012\n",
      "val_overall_loss 0.8794489411354065\n",
      "__________________\n",
      "models/model_epoch5.dms\n",
      "overall loss 0.699\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7410666666666667\n",
      "val_overall_loss 0.7726789457162221\n",
      "__________________\n",
      "models/model_epoch6.dms\n",
      "overall loss 0.66\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7448\n",
      "val_overall_loss 0.7556809691270192\n",
      "__________________\n",
      "models/model_epoch7.dms\n",
      "overall loss 0.634\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.758\n",
      "val_overall_loss 0.7189117034276327\n",
      "__________________\n",
      "models/model_epoch8.dms\n",
      "overall loss 0.603\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7465333333333334\n",
      "val_overall_loss 0.7661048161029815\n",
      "__________________\n",
      "models/model_epoch9.dms\n",
      "overall loss 0.589\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7385333333333334\n",
      "val_overall_loss 0.7747193611462911\n",
      "__________________\n",
      "models/model_epoch10.dms\n",
      "overall loss 0.571\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7773333333333333\n",
      "val_overall_loss 0.6721708407402038\n",
      "__________________\n",
      "models/model_epoch11.dms\n",
      "overall loss 0.554\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7493333333333333\n",
      "val_overall_loss 0.7695157714684804\n",
      "__________________\n",
      "models/model_epoch12.dms\n",
      "overall loss 0.54\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7814666666666666\n",
      "val_overall_loss 0.6447074811776479\n",
      "__________________\n",
      "models/model_epoch13.dms\n",
      "overall loss 0.532\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7452\n",
      "val_overall_loss 0.7687562601248423\n",
      "__________________\n",
      "models/model_epoch14.dms\n",
      "overall loss 0.522\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7893333333333333\n",
      "val_overall_loss 0.6344055528004964\n",
      "__________________\n",
      "models/model_epoch15.dms\n",
      "overall loss 0.511\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7425333333333334\n",
      "val_overall_loss 0.825608113749822\n",
      "__________________\n",
      "models/model_epoch16.dms\n",
      "overall loss 0.511\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7576\n",
      "val_overall_loss 0.7591443321545919\n",
      "__________________\n",
      "models/model_epoch17.dms\n",
      "overall loss 0.502\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7417333333333334\n",
      "val_overall_loss 0.7818743029912313\n",
      "__________________\n",
      "models/model_epoch18.dms\n",
      "overall loss 0.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7849333333333334\n",
      "val_overall_loss 0.6449071383158366\n",
      "__________________\n",
      "models/model_epoch19.dms\n",
      "overall loss 0.49\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.784\n",
      "val_overall_loss 0.6622944647153218\n",
      "__________________\n",
      "models/model_epoch20.dms\n",
      "overall loss 0.482\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7696\n",
      "val_overall_loss 0.6772989480177561\n",
      "__________________\n",
      "models/model_epoch21.dms\n",
      "overall loss 0.481\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7676\n",
      "val_overall_loss 0.6861142796516418\n",
      "__________________\n",
      "models/model_epoch22.dms\n",
      "overall loss 0.474\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.742\n",
      "val_overall_loss 0.8183962410291036\n",
      "__________________\n",
      "models/model_epoch23.dms\n",
      "overall loss 0.472\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7929333333333334\n",
      "val_overall_loss 0.5972271959781646\n",
      "__________________\n",
      "models/model_epoch24.dms\n",
      "overall loss 0.466\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7924\n",
      "val_overall_loss 0.6178676902135213\n",
      "__________________\n",
      "models/model_epoch25.dms\n",
      "overall loss 0.463\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7826666666666666\n",
      "val_overall_loss 0.6520687352816263\n",
      "__________________\n",
      "models/model_epoch26.dms\n",
      "overall loss 0.456\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7934666666666667\n",
      "val_overall_loss 0.6250258563995361\n",
      "__________________\n",
      "models/model_epoch27.dms\n",
      "overall loss 0.46\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8106666666666666\n",
      "val_overall_loss 0.5675361379702886\n",
      "__________________\n",
      "models/model_epoch28.dms\n",
      "overall loss 0.458\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7997333333333333\n",
      "val_overall_loss 0.5787797657807668\n",
      "__________________\n",
      "models/model_epoch29.dms\n",
      "overall loss 0.454\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7917333333333333\n",
      "val_overall_loss 0.5995869701862335\n",
      "__________________\n",
      "models/model_epoch30.dms\n",
      "overall loss 0.453\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8198666666666666\n",
      "val_overall_loss 0.533625373617808\n",
      "__________________\n",
      "models/model_epoch31.dms\n",
      "overall loss 0.451\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7836\n",
      "val_overall_loss 0.6387925806681315\n",
      "__________________\n",
      "models/model_epoch32.dms\n",
      "overall loss 0.446\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8201333333333334\n",
      "val_overall_loss 0.5264108234723409\n",
      "__________________\n",
      "models/model_epoch33.dms\n",
      "overall loss 0.439\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8221333333333334\n",
      "val_overall_loss 0.5266610710461934\n",
      "__________________\n",
      "models/model_epoch34.dms\n",
      "overall loss 0.441\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8013333333333333\n",
      "val_overall_loss 0.5948495860417684\n",
      "__________________\n",
      "models/model_epoch35.dms\n",
      "overall loss 0.444\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7436\n",
      "val_overall_loss 0.804314271513621\n",
      "__________________\n",
      "models/model_epoch36.dms\n",
      "overall loss 0.441\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8144\n",
      "val_overall_loss 0.5618525786240895\n",
      "__________________\n",
      "models/model_epoch37.dms\n",
      "overall loss 0.436\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7794666666666666\n",
      "val_overall_loss 0.6863754021485646\n",
      "__________________\n",
      "models/model_epoch38.dms\n",
      "overall loss 0.434\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8188\n",
      "val_overall_loss 0.5601921568075816\n",
      "__________________\n",
      "models/model_epoch39.dms\n",
      "overall loss 0.431\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7829333333333334\n",
      "val_overall_loss 0.6861540049235026\n",
      "__________________\n",
      "models/model_epoch40.dms\n",
      "overall loss 0.431\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8194666666666667\n",
      "val_overall_loss 0.5347004799842835\n",
      "__________________\n",
      "models/model_epoch41.dms\n",
      "overall loss 0.434\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7968\n",
      "val_overall_loss 0.6042057684898376\n",
      "__________________\n",
      "models/model_epoch42.dms\n",
      "overall loss 0.427\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8069333333333333\n",
      "val_overall_loss 0.5774474943796793\n",
      "__________________\n",
      "models/model_epoch43.dms\n",
      "overall loss 0.424\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8114666666666667\n",
      "val_overall_loss 0.5581745615641276\n",
      "__________________\n",
      "models/model_epoch44.dms\n",
      "overall loss 0.422\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7704\n",
      "val_overall_loss 0.6706139319737753\n",
      "__________________\n",
      "models/model_epoch45.dms\n",
      "overall loss 0.428\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8225333333333333\n",
      "val_overall_loss 0.5345247323354085\n",
      "__________________\n",
      "models/model_epoch46.dms\n",
      "overall loss 0.424\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8045333333333333\n",
      "val_overall_loss 0.5714485073884328\n",
      "__________________\n",
      "models/model_epoch47.dms\n",
      "overall loss 0.414\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7986666666666666\n",
      "val_overall_loss 0.6100552175203959\n",
      "__________________\n",
      "models/model_epoch48.dms\n",
      "overall loss 0.424\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7561333333333333\n",
      "val_overall_loss 0.7465625439961752\n",
      "__________________\n",
      "models/model_epoch49.dms\n",
      "overall loss 0.422\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8082666666666667\n",
      "val_overall_loss 0.5578782590548197\n",
      "__________________\n",
      "models/model_epoch50.dms\n",
      "overall loss 0.421\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7890666666666667\n",
      "val_overall_loss 0.6425162822564443\n",
      "__________________\n",
      "models/model_epoch51.dms\n",
      "overall loss 0.422\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7874666666666666\n",
      "val_overall_loss 0.6429981524864833\n",
      "__________________\n",
      "models/model_epoch52.dms\n",
      "overall loss 0.416\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.77\n",
      "val_overall_loss 0.7387753067652384\n",
      "__________________\n",
      "models/model_epoch53.dms\n",
      "overall loss 0.417\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8058666666666666\n",
      "val_overall_loss 0.5874295127868653\n",
      "__________________\n",
      "models/model_epoch54.dms\n",
      "overall loss 0.413\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7568\n",
      "val_overall_loss 0.7685277325312296\n",
      "__________________\n",
      "models/model_epoch55.dms\n",
      "overall loss 0.419\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7973333333333333\n",
      "val_overall_loss 0.6064238089402517\n",
      "__________________\n",
      "models/model_epoch56.dms\n",
      "overall loss 0.413\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.77\n",
      "val_overall_loss 0.7270230827331543\n",
      "__________________\n",
      "models/model_epoch57.dms\n",
      "overall loss 0.413\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8266666666666667\n",
      "val_overall_loss 0.5124817919890086\n",
      "__________________\n",
      "models/model_epoch58.dms\n",
      "overall loss 0.415\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8005333333333333\n",
      "val_overall_loss 0.6089900360743205\n",
      "__________________\n",
      "models/model_epoch59.dms\n",
      "overall loss 0.418\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7984\n",
      "val_overall_loss 0.598447306950887\n",
      "__________________\n",
      "models/model_epoch60.dms\n",
      "overall loss 0.411\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7942666666666667\n",
      "val_overall_loss 0.6258836784998576\n",
      "__________________\n",
      "models/model_epoch61.dms\n",
      "overall loss 0.413\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7982666666666667\n",
      "val_overall_loss 0.6022806347211201\n",
      "__________________\n",
      "models/model_epoch62.dms\n",
      "overall loss 0.409\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7870666666666667\n",
      "val_overall_loss 0.6468708286762238\n",
      "__________________\n",
      "models/model_epoch63.dms\n",
      "overall loss 0.41\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7521333333333333\n",
      "val_overall_loss 0.8116296960512797\n",
      "__________________\n",
      "models/model_epoch64.dms\n",
      "overall loss 0.41\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8133333333333334\n",
      "val_overall_loss 0.5537996266047159\n",
      "__________________\n",
      "models/model_epoch65.dms\n",
      "overall loss 0.406\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7978666666666666\n",
      "val_overall_loss 0.6151317320982616\n",
      "__________________\n",
      "models/model_epoch66.dms\n",
      "overall loss 0.403\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7929333333333334\n",
      "val_overall_loss 0.6472037623405457\n",
      "__________________\n",
      "models/model_epoch67.dms\n",
      "overall loss 0.408\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7728\n",
      "val_overall_loss 0.6624627695401509\n",
      "__________________\n",
      "models/model_epoch68.dms\n",
      "overall loss 0.411\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7662666666666667\n",
      "val_overall_loss 0.7096532497962316\n",
      "__________________\n",
      "models/model_epoch69.dms\n",
      "overall loss 0.406\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7430666666666667\n",
      "val_overall_loss 0.866829692586263\n",
      "__________________\n",
      "models/model_epoch70.dms\n",
      "overall loss 0.412\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8229333333333333\n",
      "val_overall_loss 0.53612923467954\n",
      "__________________\n",
      "models/model_epoch71.dms\n",
      "overall loss 0.405\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8136\n",
      "val_overall_loss 0.5612372503916423\n",
      "__________________\n",
      "models/model_epoch72.dms\n",
      "overall loss 0.409\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7884\n",
      "val_overall_loss 0.6506685663223266\n",
      "__________________\n",
      "models/model_epoch73.dms\n",
      "overall loss 0.404\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8074666666666667\n",
      "val_overall_loss 0.5929502536098162\n",
      "__________________\n",
      "models/model_epoch74.dms\n",
      "overall loss 0.404\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8102666666666667\n",
      "val_overall_loss 0.5683541621843974\n",
      "__________________\n",
      "models/model_epoch75.dms\n",
      "overall loss 0.405\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7986666666666666\n",
      "val_overall_loss 0.6181003935496012\n",
      "__________________\n",
      "models/model_epoch76.dms\n",
      "overall loss 0.406\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8013333333333333\n",
      "val_overall_loss 0.596408831246694\n",
      "__________________\n",
      "models/model_epoch77.dms\n",
      "overall loss 0.406\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8330666666666666\n",
      "val_overall_loss 0.5037572038332622\n",
      "__________________\n",
      "models/model_epoch78.dms\n",
      "overall loss 0.399\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.7854666666666666\n",
      "val_overall_loss 0.6591962819099426\n",
      "__________________\n",
      "models/model_epoch79.dms\n",
      "overall loss 0.404\n",
      "current lr 1.000e-01\n",
      "__________________\n",
      "val_accuracy 0.8056\n",
      "val_overall_loss 0.5600565968354543\n",
      "__________________\n",
      "models/model_epoch80.dms\n",
      "overall loss 0.305\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8681333333333333\n",
      "val_overall_loss 0.39202543131113055\n",
      "__________________\n",
      "models/model_epoch81.dms\n",
      "overall loss 0.28\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.87\n",
      "val_overall_loss 0.38284903536637627\n",
      "__________________\n",
      "models/model_epoch82.dms\n",
      "overall loss 0.271\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8724\n",
      "val_overall_loss 0.38762809646924334\n",
      "__________________\n",
      "models/model_epoch83.dms\n",
      "overall loss 0.268\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8749333333333333\n",
      "val_overall_loss 0.38471751574675245\n",
      "__________________\n",
      "models/model_epoch84.dms\n",
      "overall loss 0.261\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8734666666666666\n",
      "val_overall_loss 0.3743209907531738\n",
      "__________________\n",
      "models/model_epoch85.dms\n",
      "overall loss 0.256\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8708\n",
      "val_overall_loss 0.3774794370810191\n",
      "__________________\n",
      "models/model_epoch86.dms\n",
      "overall loss 0.251\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8770666666666667\n",
      "val_overall_loss 0.3707275980869929\n",
      "__________________\n",
      "models/model_epoch87.dms\n",
      "overall loss 0.25\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8754666666666666\n",
      "val_overall_loss 0.3853092568735282\n",
      "__________________\n",
      "models/model_epoch88.dms\n",
      "overall loss 0.248\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8770666666666667\n",
      "val_overall_loss 0.3687385152856509\n",
      "__________________\n",
      "models/model_epoch89.dms\n",
      "overall loss 0.246\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8745333333333334\n",
      "val_overall_loss 0.38089211640357973\n",
      "__________________\n",
      "models/model_epoch90.dms\n",
      "overall loss 0.246\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8757333333333334\n",
      "val_overall_loss 0.37811714661916096\n",
      "__________________\n",
      "models/model_epoch91.dms\n",
      "overall loss 0.243\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8772\n",
      "val_overall_loss 0.37401657752990725\n",
      "__________________\n",
      "models/model_epoch92.dms\n",
      "overall loss 0.24\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8736\n",
      "val_overall_loss 0.3868288955609004\n",
      "__________________\n",
      "models/model_epoch93.dms\n",
      "overall loss 0.242\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.878\n",
      "val_overall_loss 0.3748022297859192\n",
      "__________________\n",
      "models/model_epoch94.dms\n",
      "overall loss 0.236\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8732\n",
      "val_overall_loss 0.3750485887209574\n",
      "__________________\n",
      "models/model_epoch95.dms\n",
      "overall loss 0.234\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8750666666666667\n",
      "val_overall_loss 0.38113633620738985\n",
      "__________________\n",
      "models/model_epoch96.dms\n",
      "overall loss 0.237\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8792\n",
      "val_overall_loss 0.36677415466308594\n",
      "__________________\n",
      "models/model_epoch97.dms\n",
      "overall loss 0.232\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8796\n",
      "val_overall_loss 0.37025542650222776\n",
      "__________________\n",
      "models/model_epoch98.dms\n",
      "overall loss 0.233\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8778666666666667\n",
      "val_overall_loss 0.37599556334813433\n",
      "__________________\n",
      "models/model_epoch99.dms\n",
      "overall loss 0.234\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.88\n",
      "val_overall_loss 0.3741576823870341\n",
      "__________________\n",
      "models/model_epoch100.dms\n",
      "overall loss 0.228\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.878\n",
      "val_overall_loss 0.37202279904683433\n",
      "__________________\n",
      "models/model_epoch101.dms\n",
      "overall loss 0.229\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8742666666666666\n",
      "val_overall_loss 0.3723037045796712\n",
      "__________________\n",
      "models/model_epoch102.dms\n",
      "overall loss 0.23\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8789333333333333\n",
      "val_overall_loss 0.37482253772417706\n",
      "__________________\n",
      "models/model_epoch103.dms\n",
      "overall loss 0.224\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8761333333333333\n",
      "val_overall_loss 0.38333440402348834\n",
      "__________________\n",
      "models/model_epoch104.dms\n",
      "overall loss 0.226\n",
      "current lr 1.000e-02\n",
      "__________________\n",
      "val_accuracy 0.8778666666666667\n",
      "val_overall_loss 0.37799883874456086\n",
      "__________________\n",
      "models/model_epoch105.dms\n",
      "overall loss 0.212\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.35997880204916\n",
      "__________________\n",
      "models/model_epoch106.dms\n",
      "overall loss 0.208\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.3590148485819499\n",
      "__________________\n",
      "models/model_epoch107.dms\n",
      "overall loss 0.21\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8838666666666667\n",
      "val_overall_loss 0.3559818566083908\n",
      "__________________\n",
      "models/model_epoch108.dms\n",
      "overall loss 0.207\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8828\n",
      "val_overall_loss 0.3567088860909144\n",
      "__________________\n",
      "models/model_epoch109.dms\n",
      "overall loss 0.206\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8828\n",
      "val_overall_loss 0.3562543534040451\n",
      "__________________\n",
      "models/model_epoch110.dms\n",
      "overall loss 0.207\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.884\n",
      "val_overall_loss 0.35477590007781984\n",
      "__________________\n",
      "models/model_epoch111.dms\n",
      "overall loss 0.208\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.3559654733657837\n",
      "__________________\n",
      "models/model_epoch112.dms\n",
      "overall loss 0.206\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8837333333333334\n",
      "val_overall_loss 0.35726118233998616\n",
      "__________________\n",
      "models/model_epoch113.dms\n",
      "overall loss 0.206\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8830666666666667\n",
      "val_overall_loss 0.35977916990816594\n",
      "__________________\n",
      "models/model_epoch114.dms\n",
      "overall loss 0.206\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8825333333333333\n",
      "val_overall_loss 0.3567245503703753\n",
      "__________________\n",
      "models/model_epoch115.dms\n",
      "overall loss 0.205\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8824\n",
      "val_overall_loss 0.35675049431920053\n",
      "__________________\n",
      "models/model_epoch116.dms\n",
      "overall loss 0.203\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8837333333333334\n",
      "val_overall_loss 0.35578846753438315\n",
      "__________________\n",
      "models/model_epoch117.dms\n",
      "overall loss 0.206\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8822666666666666\n",
      "val_overall_loss 0.35687759205500286\n",
      "__________________\n",
      "models/model_epoch118.dms\n",
      "overall loss 0.204\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8822666666666666\n",
      "val_overall_loss 0.35734448261260987\n",
      "__________________\n",
      "models/model_epoch119.dms\n",
      "overall loss 0.203\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8813333333333333\n",
      "val_overall_loss 0.357443293873469\n",
      "__________________\n",
      "models/model_epoch120.dms\n",
      "overall loss 0.203\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8808\n",
      "val_overall_loss 0.3584963174819946\n",
      "__________________\n",
      "models/model_epoch121.dms\n",
      "overall loss 0.203\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8836\n",
      "val_overall_loss 0.3558617606004079\n",
      "__________________\n",
      "models/model_epoch122.dms\n",
      "overall loss 0.204\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8844\n",
      "val_overall_loss 0.35587207635243734\n",
      "__________________\n",
      "models/model_epoch123.dms\n",
      "overall loss 0.202\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8850666666666667\n",
      "val_overall_loss 0.3544463068644206\n",
      "__________________\n",
      "models/model_epoch124.dms\n",
      "overall loss 0.202\n",
      "current lr 1.000e-03\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.35720064646303656\n",
      "__________________\n",
      "models/model_epoch125.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8830666666666667\n",
      "val_overall_loss 0.35583360443512596\n",
      "__________________\n",
      "models/model_epoch126.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.355565132133166\n",
      "__________________\n",
      "models/model_epoch127.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8842666666666666\n",
      "val_overall_loss 0.3546526184717814\n",
      "__________________\n",
      "models/model_epoch128.dms\n",
      "overall loss 0.199\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8850666666666667\n",
      "val_overall_loss 0.3561117781360944\n",
      "__________________\n",
      "models/model_epoch129.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8828\n",
      "val_overall_loss 0.35455490805705386\n",
      "__________________\n",
      "models/model_epoch130.dms\n",
      "overall loss 0.202\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8845333333333333\n",
      "val_overall_loss 0.35548351980845133\n",
      "__________________\n",
      "models/model_epoch131.dms\n",
      "overall loss 0.199\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8837333333333334\n",
      "val_overall_loss 0.35511221783955893\n",
      "__________________\n",
      "models/model_epoch132.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8844\n",
      "val_overall_loss 0.35622244111696877\n",
      "__________________\n",
      "models/model_epoch133.dms\n",
      "overall loss 0.198\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8842666666666666\n",
      "val_overall_loss 0.3563036590894063\n",
      "__________________\n",
      "models/model_epoch134.dms\n",
      "overall loss 0.199\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.35613579586346944\n",
      "__________________\n",
      "models/model_epoch135.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.3558717871983846\n",
      "__________________\n",
      "models/model_epoch136.dms\n",
      "overall loss 0.199\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8826666666666667\n",
      "val_overall_loss 0.3561560505072276\n",
      "__________________\n",
      "models/model_epoch137.dms\n",
      "overall loss 0.198\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8841333333333333\n",
      "val_overall_loss 0.35870749847888944\n",
      "__________________\n",
      "models/model_epoch138.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8836\n",
      "val_overall_loss 0.3546030838171641\n",
      "__________________\n",
      "models/model_epoch139.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-04\n",
      "__________________\n",
      "val_accuracy 0.8836\n",
      "val_overall_loss 0.35703498293558755\n",
      "__________________\n",
      "models/model_epoch140.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8837333333333334\n",
      "val_overall_loss 0.3580704086303711\n",
      "__________________\n",
      "models/model_epoch141.dms\n",
      "overall loss 0.202\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8824\n",
      "val_overall_loss 0.3563970806121826\n",
      "__________________\n",
      "models/model_epoch142.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8845333333333333\n",
      "val_overall_loss 0.3562523956934611\n",
      "__________________\n",
      "models/model_epoch143.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8836\n",
      "val_overall_loss 0.35686332861582437\n",
      "__________________\n",
      "models/model_epoch144.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.35470729835828146\n",
      "__________________\n",
      "models/model_epoch145.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8848\n",
      "val_overall_loss 0.355049354938666\n",
      "__________________\n",
      "models/model_epoch146.dms\n",
      "overall loss 0.2\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8842666666666666\n",
      "val_overall_loss 0.3560214487711589\n",
      "__________________\n",
      "models/model_epoch147.dms\n",
      "overall loss 0.199\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8832\n",
      "val_overall_loss 0.3554199888209502\n",
      "__________________\n",
      "models/model_epoch148.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8833333333333333\n",
      "val_overall_loss 0.35622952642440797\n",
      "__________________\n",
      "models/model_epoch149.dms\n",
      "overall loss 0.201\n",
      "current lr 1.000e-05\n",
      "__________________\n",
      "val_accuracy 0.8841333333333333\n",
      "val_overall_loss 0.3553150381565094\n",
      "__________________\n",
      "choosen epoch: 123 , score: 0.8850666666666667\n",
      "best epoch: 123 , score: 0.8850666666666667\n",
      "-----------------\n",
      "*****************\n",
      "resnet20aug_kl.pt\n",
      "test_accuracy 0.8781\n",
      "test_overall_loss 0.3619183002948761\n",
      "__________________\n",
      "val_accuracy 0.8850666666666667\n",
      "val_overall_loss 0.3544463109175364\n",
      "__________________\n",
      "train_accuracy 0.9267294117647059\n",
      "train_overall_loss 0.2128815917744356\n",
      "__________________\n",
      "----------------\n",
      "test_accuracy 0.9135\n",
      "test_overall_loss 0.34214952545166016\n",
      "__________________\n",
      "val_accuracy 0.918\n",
      "val_overall_loss 0.3436746369679769\n",
      "__________________\n",
      "train_accuracy 0.9966823529411765\n",
      "train_overall_loss 0.013359111724180334\n",
      "__________________\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "  for net_teacher, net_student, teacher_name, student_name in [\n",
    "                    (resnet20(), resnet7(), \"resnet20_classic.pt\", \"\"), \n",
    "                    ]:\n",
    "\n",
    "    epochs = 150\n",
    "    download_model(teacher_name, teacher_name)\n",
    "    state_dict_teacher = torch.load(teacher_name)\n",
    "    net_teacher.cuda().load_state_dict(state_dict_teacher)\n",
    "    loader_cached = cache_loader(net_teacher, trainloader, transform_repeats=8, transform_tensor=transform_train)\n",
    "\n",
    "    experiment_name = teacher_name[:8]+\"aug_kl.pt\"\n",
    "    logger = TensorBoardLogger(\"logs\", dataset_name, \"resnet7\", experiment_name)\n",
    "    net_student = train_distillation_cached(\n",
    "                              net_student,\n",
    "                              loader_cached,\n",
    "                              valloader,\n",
    "                              epoches=epochs, \n",
    "                              init_lr=1e-1, \n",
    "                              logger=logger,\n",
    "                              return_best=True,\n",
    "                              cos_alpha=0.0,\n",
    "                              l_alpha=0.0,\n",
    "                              p=2,\n",
    "                              wd=1e-4,\n",
    "                              temperature=1, \n",
    "                              transform_tensor=transform_train\n",
    "                              )\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print(\"*****************\")\n",
    "    print(experiment_name)\n",
    "    score_test = validate(net_student, testloader, prename='test')\n",
    "    score_val = validate(net_student, valloader, prename='val')\n",
    "    score_train=validate(net_student, trainloader, prename='train')\n",
    "\n",
    "    print(\"----------------\")\n",
    "    score_teacher_test = validate(net_teacher, testloader, prename='test')\n",
    "    score_teacher_val = validate(net_teacher, valloader, prename='val')\n",
    "    score_teacher_train = validate(net_teacher, trainloader, prename='train')\n",
    "    print(\"----------------\")\n",
    "\n",
    "    hparams = {\"experiment_name\":experiment_name, \"teacher\":teacher_name, \"dataset\":dataset_name}\n",
    "    for key, value in score_val.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_test.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    for key, value in score_train.items():\n",
    "      hparams[\"student/\"+key] = value\n",
    "    \n",
    "    for key, value in score_teacher_test.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_val.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "    for key, value in score_teacher_train.items():\n",
    "      hparams[\"teacher/\"+key] = value\n",
    "\n",
    "    logger.log_hparams(hparams) \n",
    "\n",
    "    torch.save(net_student.state_dict(), experiment_name)\n",
    "    # upload_model(experiment_name, experiment_name)\n",
    "\n",
    "    saving_path_template = \"models/model_epoch%s.dms\"\n",
    "    logger.step_=0\n",
    "    upload_logs()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNo7CaWuWAeMOsLLc/jfd9w",
   "collapsed_sections": [],
   "mount_file_id": "14D6eHHLfNT2vf3HGVlL9cLS9qjY_7CL2",
   "name": "aug_cached_cifar10_distillation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13cef53133804635ad2f07e04baba93e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51cd58c32a814c879e0d0380f3be4745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e8e71dac9af410db23235ca437dcb59",
      "placeholder": "​",
      "style": "IPY_MODEL_bc6078b935034cb19cf2281b3dc94bae",
      "value": "170500096it [00:03, 42981695.49it/s]"
     }
    },
    "5e8e71dac9af410db23235ca437dcb59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d01613ce0f7494db52486586b5a49d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "766cbd23ae804d90a174ca95ac53df1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d01613ce0f7494db52486586b5a49d3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bfbaf5558fa24f0485c09a65780f0d41",
      "value": 1
     }
    },
    "bc6078b935034cb19cf2281b3dc94bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfbaf5558fa24f0485c09a65780f0d41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d398f6070935495a8314505238b042f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_766cbd23ae804d90a174ca95ac53df1d",
       "IPY_MODEL_51cd58c32a814c879e0d0380f3be4745"
      ],
      "layout": "IPY_MODEL_13cef53133804635ad2f07e04baba93e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
